{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[2] Student on CIFAR10 Using FF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "imgZBevn_klO"
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "# !pip install --upgrade opencv-python==3.4.2.17\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.backend as K\n",
        "# import os\n",
        "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
        "# import keras.backend as K\n",
        "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from keras.initializers import RandomNormal\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from keras.utils import np_utils\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-DYwB8kiFk"
      },
      "source": [
        "nb_classes = 10\n",
        "batch_size = 128\n",
        "maxepoches = 250\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "def lr_scheduler(epoch):\n",
        "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e04yi6rW_qJg"
      },
      "source": [
        "#Loading and splitting the dataset into train, validation and test\n",
        "\n",
        "\n",
        "(X_Train, y_Train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
        "# convert y_train and y_test to categorical binary values \n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj_XM_dfmqnV",
        "outputId": "ac5a0bf9-7d8f-4f00-960b-8deb84052b90"
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "443_UL2p_qyQ"
      },
      "source": [
        "# Reshape them to batch_size, width,height,#channels\n",
        "X_train = X_train.reshape(40000, 32, 32, 3)\n",
        "X_val = X_val.reshape(10000, 32, 32, 3)\n",
        "X_test = X_test.reshape(10000, 32, 32, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize the values\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQn2hUFNVDY"
      },
      "source": [
        "init=RandomNormal(mean=0,stddev=0.02)\n",
        "input_shape = (32, 32, 3) # Input shape of each image\n",
        "weight_decay = 0.0005\n",
        "def build_model():\n",
        "    # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay), name='dense_1'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, name='dense_2'))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "teacher = build_model()\n",
        "\n",
        "sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "\n",
        "teacher.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4il80HMRFn"
      },
      "source": [
        "# teacher.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1,callbacks=[reduce_lr],validation_data=(X_val,Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8uZIWuQWKA"
      },
      "source": [
        "teacher.load_weights(\"Cifar10_Teacher.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBZO-MXLmml_",
        "outputId": "e50939c1-acc5-49e5-c358-b3ac99fdb8d5"
      },
      "source": [
        "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "loss, acc =teacher.evaluate(X_test, y_test, verbose=1)\n",
        "loss, acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 5s 8ms/step - loss: 0.8247 - accuracy: 0.8996\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.834343671798706, 0.8992000222206116)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPVxVj6L_sCz"
      },
      "source": [
        "#Collect the dense vector from the previous layer output and store it in a different model\n",
        "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhcEQ0Z-_scF"
      },
      "source": [
        "#Extracting dense representation from the teacher network\n",
        "train_dense = teacher_WO_Softmax.predict(X_train)\n",
        "val_dense = teacher_WO_Softmax.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG0WGCpM_suF"
      },
      "source": [
        "#Splitting the training dense vector among N students(in this case 2)\n",
        "s1Train=train_dense[:,:128]\n",
        "s2Train=train_dense[:,128:]\n",
        "\n",
        "\n",
        "s1Val=val_dense[:,:128]\n",
        "s2Val=val_dense[:,128:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKx8VcoJxwH0",
        "outputId": "839849d8-c09d-4de2-8f38-6bd693fd091a"
      },
      "source": [
        "def define_model(name):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3), name=name))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform',name='req'+name))\n",
        "\n",
        "    model.compile(optimizer='nadam', loss='mse', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "student1 = define_model('s1')\n",
        "student1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "s1 (Conv2D)                  (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                32784     \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "reqs1 (Dense)                (None, 128)               2176      \n",
            "=================================================================\n",
            "Total params: 321,968\n",
            "Trainable params: 321,968\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_42UFKHaZO"
      },
      "source": [
        "TCN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maTYDNAsa25e"
      },
      "source": [
        "# Testing with LR\n",
        "s1=define_model(\"s1\")\n",
        "s2=define_model(\"s2\")\n",
        "\n",
        "opt=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brw1esFta25f",
        "outputId": "4c9c5e19-b4a0-46b4-da0f-05d0aa11577b"
      },
      "source": [
        "s1.compile(loss='mse', optimizer=opt)\n",
        "s2.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "s1.fit(X_train,s1Train,\n",
        "          batch_size=256,\n",
        "          epochs=80,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s1Val))\n",
        "\n",
        "s2.fit(X_train,s2Train,\n",
        "          batch_size=256,\n",
        "          epochs=60,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s2Val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.7962 - val_loss: 1.6681\n",
            "Epoch 2/80\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 1.6461 - val_loss: 1.6434\n",
            "Epoch 3/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.6197 - val_loss: 1.6276\n",
            "Epoch 4/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.6028 - val_loss: 1.6036\n",
            "Epoch 5/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5849 - val_loss: 1.5745\n",
            "Epoch 6/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5526 - val_loss: 1.5469\n",
            "Epoch 7/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5339 - val_loss: 1.5263\n",
            "Epoch 8/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5194 - val_loss: 1.5074\n",
            "Epoch 9/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5039 - val_loss: 1.4930\n",
            "Epoch 10/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.4872 - val_loss: 1.4717\n",
            "Epoch 11/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.4661 - val_loss: 1.4569\n",
            "Epoch 12/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.4544 - val_loss: 1.4406\n",
            "Epoch 13/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.4427 - val_loss: 1.4341\n",
            "Epoch 14/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.4377 - val_loss: 1.4288\n",
            "Epoch 15/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.4299 - val_loss: 1.4069\n",
            "Epoch 16/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.4177 - val_loss: 1.3998\n",
            "Epoch 17/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.4019 - val_loss: 1.3816\n",
            "Epoch 18/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3982 - val_loss: 1.3679\n",
            "Epoch 19/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.3777 - val_loss: 1.3504\n",
            "Epoch 20/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3730 - val_loss: 1.3345\n",
            "Epoch 21/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.3561 - val_loss: 1.3260\n",
            "Epoch 22/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3520 - val_loss: 1.3123\n",
            "Epoch 23/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3358 - val_loss: 1.2965\n",
            "Epoch 24/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.3229 - val_loss: 1.2838\n",
            "Epoch 25/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3148 - val_loss: 1.2796\n",
            "Epoch 26/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3085 - val_loss: 1.2591\n",
            "Epoch 27/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.2982 - val_loss: 1.2481\n",
            "Epoch 28/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.2873 - val_loss: 1.2405\n",
            "Epoch 29/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.2810 - val_loss: 1.2298\n",
            "Epoch 30/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.2685 - val_loss: 1.2323\n",
            "Epoch 31/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2642 - val_loss: 1.2094\n",
            "Epoch 32/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.2554 - val_loss: 1.2033\n",
            "Epoch 33/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.2473 - val_loss: 1.1970\n",
            "Epoch 34/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.2426 - val_loss: 1.1847\n",
            "Epoch 35/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2320 - val_loss: 1.1799\n",
            "Epoch 36/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2253 - val_loss: 1.1765\n",
            "Epoch 37/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2177 - val_loss: 1.1610\n",
            "Epoch 38/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2085 - val_loss: 1.1524\n",
            "Epoch 39/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2016 - val_loss: 1.1525\n",
            "Epoch 40/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1994 - val_loss: 1.1346\n",
            "Epoch 41/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1926 - val_loss: 1.1335\n",
            "Epoch 42/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1890 - val_loss: 1.1351\n",
            "Epoch 43/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1821 - val_loss: 1.1206\n",
            "Epoch 44/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1787 - val_loss: 1.1157\n",
            "Epoch 45/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1686 - val_loss: 1.1117\n",
            "Epoch 46/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1668 - val_loss: 1.1193\n",
            "Epoch 47/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1656 - val_loss: 1.1035\n",
            "Epoch 48/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1578 - val_loss: 1.0967\n",
            "Epoch 49/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1559 - val_loss: 1.1034\n",
            "Epoch 50/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1529 - val_loss: 1.1025\n",
            "Epoch 51/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1500 - val_loss: 1.0865\n",
            "Epoch 52/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1471 - val_loss: 1.0842\n",
            "Epoch 53/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1387 - val_loss: 1.0771\n",
            "Epoch 54/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1387 - val_loss: 1.0722\n",
            "Epoch 55/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1352 - val_loss: 1.0687\n",
            "Epoch 56/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1319 - val_loss: 1.0645\n",
            "Epoch 57/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1254 - val_loss: 1.0586\n",
            "Epoch 58/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1251 - val_loss: 1.0641\n",
            "Epoch 59/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1175 - val_loss: 1.0552\n",
            "Epoch 60/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1148 - val_loss: 1.0525\n",
            "Epoch 61/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1115 - val_loss: 1.0520\n",
            "Epoch 62/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1107 - val_loss: 1.0505\n",
            "Epoch 63/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1101 - val_loss: 1.0443\n",
            "Epoch 64/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1035 - val_loss: 1.0491\n",
            "Epoch 65/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1040 - val_loss: 1.0407\n",
            "Epoch 66/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0977 - val_loss: 1.0452\n",
            "Epoch 67/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1022 - val_loss: 1.0381\n",
            "Epoch 68/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.0952 - val_loss: 1.0351\n",
            "Epoch 69/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0908 - val_loss: 1.0310\n",
            "Epoch 70/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0903 - val_loss: 1.0321\n",
            "Epoch 71/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0898 - val_loss: 1.0319\n",
            "Epoch 72/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0834 - val_loss: 1.0343\n",
            "Epoch 73/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0873 - val_loss: 1.0287\n",
            "Epoch 74/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0813 - val_loss: 1.0238\n",
            "Epoch 75/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.0855 - val_loss: 1.0291\n",
            "Epoch 76/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.0760 - val_loss: 1.0220\n",
            "Epoch 77/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0758 - val_loss: 1.0201\n",
            "Epoch 78/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0793 - val_loss: 1.0167\n",
            "Epoch 79/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.0774 - val_loss: 1.0218\n",
            "Epoch 80/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0733 - val_loss: 1.0162\n",
            "Epoch 1/60\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 2s 13ms/step - loss: 1.7805 - val_loss: 1.5798\n",
            "Epoch 2/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5718 - val_loss: 1.5690\n",
            "Epoch 3/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5566 - val_loss: 1.5614\n",
            "Epoch 4/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5492 - val_loss: 1.5553\n",
            "Epoch 5/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5428 - val_loss: 1.5503\n",
            "Epoch 6/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5445 - val_loss: 1.5459\n",
            "Epoch 7/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5421 - val_loss: 1.5421\n",
            "Epoch 8/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5369 - val_loss: 1.5388\n",
            "Epoch 9/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5314 - val_loss: 1.5357\n",
            "Epoch 10/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5250 - val_loss: 1.5330\n",
            "Epoch 11/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5242 - val_loss: 1.5306\n",
            "Epoch 12/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5235 - val_loss: 1.5284\n",
            "Epoch 13/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5233 - val_loss: 1.5264\n",
            "Epoch 14/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5193 - val_loss: 1.5245\n",
            "Epoch 15/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5169 - val_loss: 1.5229\n",
            "Epoch 16/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5127 - val_loss: 1.5214\n",
            "Epoch 17/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5135 - val_loss: 1.5200\n",
            "Epoch 18/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5134 - val_loss: 1.5187\n",
            "Epoch 19/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5059 - val_loss: 1.5176\n",
            "Epoch 20/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5106 - val_loss: 1.5166\n",
            "Epoch 21/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5069 - val_loss: 1.5157\n",
            "Epoch 22/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5048 - val_loss: 1.5149\n",
            "Epoch 23/60\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.5068 - val_loss: 1.5141\n",
            "Epoch 24/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5038 - val_loss: 1.5135\n",
            "Epoch 25/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5051 - val_loss: 1.5129\n",
            "Epoch 26/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5041 - val_loss: 1.5124\n",
            "Epoch 27/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5045 - val_loss: 1.5119\n",
            "Epoch 28/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5092 - val_loss: 1.5115\n",
            "Epoch 29/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5034 - val_loss: 1.5112\n",
            "Epoch 30/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5033 - val_loss: 1.5109\n",
            "Epoch 31/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5004 - val_loss: 1.5106\n",
            "Epoch 32/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5055 - val_loss: 1.5104\n",
            "Epoch 33/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.4985 - val_loss: 1.5102\n",
            "Epoch 34/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.4999 - val_loss: 1.5101\n",
            "Epoch 35/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.4999 - val_loss: 1.5100\n",
            "Epoch 36/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5013 - val_loss: 1.5099\n",
            "Epoch 37/60\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.5014 - val_loss: 1.5098\n",
            "Epoch 38/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5004 - val_loss: 1.5097\n",
            "Epoch 39/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5008 - val_loss: 1.5097\n",
            "Epoch 40/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5007 - val_loss: 1.5096\n",
            "Epoch 41/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5033 - val_loss: 1.5096\n",
            "Epoch 42/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5030 - val_loss: 1.5096\n",
            "Epoch 43/60\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5017 - val_loss: 1.5096\n",
            "Epoch 44/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5026 - val_loss: 1.5096\n",
            "Epoch 45/60\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.4971 - val_loss: 1.5096\n",
            "Epoch 46/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.4988 - val_loss: 1.5096\n",
            "Epoch 47/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5006 - val_loss: 1.5096\n",
            "Epoch 48/60\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.5000 - val_loss: 1.5096\n",
            "Epoch 49/60\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.5027 - val_loss: 1.5096\n",
            "Epoch 50/60\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.5002 - val_loss: 1.5096\n",
            "Epoch 51/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5006 - val_loss: 1.5095\n",
            "Epoch 52/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5009 - val_loss: 1.5095\n",
            "Epoch 53/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5003 - val_loss: 1.5095\n",
            "Epoch 54/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.4993 - val_loss: 1.5095\n",
            "Epoch 55/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5006 - val_loss: 1.5095\n",
            "Epoch 56/60\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.5056 - val_loss: 1.5095\n",
            "Epoch 57/60\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.4965 - val_loss: 1.5095\n",
            "Epoch 58/60\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.5028 - val_loss: 1.5095\n",
            "Epoch 59/60\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.5048 - val_loss: 1.5095\n",
            "Epoch 60/60\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.4974 - val_loss: 1.5028\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd294b64b00>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMTpeLnwINEn"
      },
      "source": [
        "o1=s1.get_layer(\"reqs1\").output\n",
        "o2=s2.get_layer(\"reqs2\").output\n",
        "\n",
        "output=tensorflow.keras.layers.concatenate([o1,o2])\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output) # For reguralization\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "\n",
        "mm2=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input], output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "mm2.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8bMaMg4LSpu",
        "outputId": "f7d52f3f-412d-4927-fd34-69341ee200a4"
      },
      "source": [
        "i=0\n",
        "for l in mm2.layers[:len(mm2.layers)-2]:\n",
        "    l.trainable=False\n",
        "#     print(l)\n",
        "\n",
        "mm2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0002),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Without finetune\n",
        "batch_size = 256\n",
        "mm2_history=mm2.fit([X_train,X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val,X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 1.6201 - accuracy: 0.5686 - val_loss: 0.7834 - val_accuracy: 0.7802\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.2023 - accuracy: 0.6631 - val_loss: 0.6932 - val_accuracy: 0.8002\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 1.0957 - accuracy: 0.6788 - val_loss: 0.6666 - val_accuracy: 0.8051\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0314 - accuracy: 0.6959 - val_loss: 0.6575 - val_accuracy: 0.8062\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.0121 - accuracy: 0.6998 - val_loss: 0.6527 - val_accuracy: 0.8048\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.9982 - accuracy: 0.7020 - val_loss: 0.6493 - val_accuracy: 0.8051\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.9764 - accuracy: 0.7078 - val_loss: 0.6444 - val_accuracy: 0.8048\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 0.9452 - accuracy: 0.7149 - val_loss: 0.6432 - val_accuracy: 0.8061\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.9324 - accuracy: 0.7158 - val_loss: 0.6400 - val_accuracy: 0.8059\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.9398 - accuracy: 0.7180 - val_loss: 0.6389 - val_accuracy: 0.8059\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8980 - accuracy: 0.7270 - val_loss: 0.6367 - val_accuracy: 0.8057\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.9032 - accuracy: 0.7241 - val_loss: 0.6357 - val_accuracy: 0.8056\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.9040 - accuracy: 0.7243 - val_loss: 0.6340 - val_accuracy: 0.8047\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 0.8909 - accuracy: 0.7273 - val_loss: 0.6311 - val_accuracy: 0.8052\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8842 - accuracy: 0.7293 - val_loss: 0.6312 - val_accuracy: 0.8048\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8678 - accuracy: 0.7341 - val_loss: 0.6311 - val_accuracy: 0.8045\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.8748 - accuracy: 0.7329 - val_loss: 0.6298 - val_accuracy: 0.8050\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 0.8777 - accuracy: 0.7270 - val_loss: 0.6283 - val_accuracy: 0.8057\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.8415 - accuracy: 0.7396 - val_loss: 0.6286 - val_accuracy: 0.8053\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8520 - accuracy: 0.7376 - val_loss: 0.6279 - val_accuracy: 0.8050\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.8480 - accuracy: 0.7380 - val_loss: 0.6288 - val_accuracy: 0.8049\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8475 - accuracy: 0.7380 - val_loss: 0.6280 - val_accuracy: 0.8044\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8494 - accuracy: 0.7384 - val_loss: 0.6257 - val_accuracy: 0.8049\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8433 - accuracy: 0.7384 - val_loss: 0.6256 - val_accuracy: 0.8045\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.8460 - accuracy: 0.7361 - val_loss: 0.6248 - val_accuracy: 0.8047\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 0.8323 - accuracy: 0.7425 - val_loss: 0.6254 - val_accuracy: 0.8057\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8349 - accuracy: 0.7426 - val_loss: 0.6248 - val_accuracy: 0.8056\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8229 - accuracy: 0.7461 - val_loss: 0.6252 - val_accuracy: 0.8058\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8388 - accuracy: 0.7416 - val_loss: 0.6244 - val_accuracy: 0.8053\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8213 - accuracy: 0.7447 - val_loss: 0.6233 - val_accuracy: 0.8054\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8305 - accuracy: 0.7439 - val_loss: 0.6246 - val_accuracy: 0.8051\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8188 - accuracy: 0.7445 - val_loss: 0.6230 - val_accuracy: 0.8047\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8193 - accuracy: 0.7495 - val_loss: 0.6247 - val_accuracy: 0.8056\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8122 - accuracy: 0.7488 - val_loss: 0.6230 - val_accuracy: 0.8050\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8131 - accuracy: 0.7487 - val_loss: 0.6226 - val_accuracy: 0.8048\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8256 - accuracy: 0.7468 - val_loss: 0.6233 - val_accuracy: 0.8038\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8231 - accuracy: 0.7461 - val_loss: 0.6219 - val_accuracy: 0.8054\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.7981 - accuracy: 0.7481 - val_loss: 0.6235 - val_accuracy: 0.8045\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.7993 - accuracy: 0.7503 - val_loss: 0.6221 - val_accuracy: 0.8050\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.8160 - accuracy: 0.7464 - val_loss: 0.6224 - val_accuracy: 0.8051\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 0.8109 - accuracy: 0.7504 - val_loss: 0.6220 - val_accuracy: 0.8045\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8106 - accuracy: 0.7496 - val_loss: 0.6223 - val_accuracy: 0.8050\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8110 - accuracy: 0.7497 - val_loss: 0.6244 - val_accuracy: 0.8037\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.8156 - accuracy: 0.7489 - val_loss: 0.6223 - val_accuracy: 0.8049\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8115 - accuracy: 0.7487 - val_loss: 0.6207 - val_accuracy: 0.8056\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8087 - accuracy: 0.7531 - val_loss: 0.6202 - val_accuracy: 0.8051\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8074 - accuracy: 0.7494 - val_loss: 0.6221 - val_accuracy: 0.8049\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.8009 - accuracy: 0.7531 - val_loss: 0.6213 - val_accuracy: 0.8044\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.8022 - accuracy: 0.7540 - val_loss: 0.6219 - val_accuracy: 0.8047\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.8032 - accuracy: 0.7516 - val_loss: 0.6231 - val_accuracy: 0.8045\n"
          ]
        }
      ]
    }
  ]
}