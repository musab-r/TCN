{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "imgZBevn_klO"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# !pip install --upgrade opencv-python==3.4.2.17\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "# import os\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "v0-DYwB8kiFk"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "batch_size = 128\n",
    "maxepoches = 250\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5338,
     "status": "ok",
     "timestamp": 1615396128353,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "e04yi6rW_qJg",
    "outputId": "4674c6eb-b8bf-45ef-c180-42e9e51b71f2"
   },
   "outputs": [],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "\n",
    "\n",
    "(X_Train, y_Train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "# convert y_train and y_test to categorical binary values \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3607,
     "status": "ok",
     "timestamp": 1615396128355,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "Lj_XM_dfmqnV",
    "outputId": "ac5a0bf9-7d8f-4f00-960b-8deb84052b90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "443_UL2p_qyQ"
   },
   "outputs": [],
   "source": [
    "# Reshape them to batch_size, width,height,#channels\n",
    "X_train = X_train.reshape(40000, 32, 32, 3)\n",
    "X_val = X_val.reshape(10000, 32, 32, 3)\n",
    "X_test = X_test.reshape(10000, 32, 32, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5aQn2hUFNVDY"
   },
   "outputs": [],
   "source": [
    "init=RandomNormal(mean=0,stddev=0.02)\n",
    "input_shape = (32, 32, 3) # Input shape of each image\n",
    "weight_decay = 0.0005\n",
    "def build_model():\n",
    "    # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay), name='dense_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, name='dense_2'))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "teacher = build_model()\n",
    "\n",
    "sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "\n",
    "teacher.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mp4il80HMRFn"
   },
   "outputs": [],
   "source": [
    "# teacher.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1,callbacks=[reduce_lr],validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JU8uZIWuQWKA"
   },
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Cifar10_Teacher.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37294,
     "status": "ok",
     "timestamp": 1615396192908,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "zBZO-MXLmml_",
    "outputId": "e50939c1-acc5-49e5-c358-b3ac99fdb8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.8247 - accuracy: 0.8996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.834343671798706, 0.8992000222206116)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "loss, acc =teacher.evaluate(X_test, y_test, verbose=1)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bPVxVj6L_sCz"
   },
   "outputs": [],
   "source": [
    "#Collect the dense vector from the previous layer output and store it in a different model\n",
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GhcEQ0Z-_scF"
   },
   "outputs": [],
   "source": [
    "#Extracting dense representation from the teacher network\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)\n",
    "val_dense = teacher_WO_Softmax.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XG0WGCpM_suF"
   },
   "outputs": [],
   "source": [
    "#Splitting the training dense vector among N students(in this case 2)\n",
    "s1Train=train_dense[:,:64]\n",
    "s2Train=train_dense[:,64:128]\n",
    "s3Train=train_dense[:,128:192]\n",
    "s4Train=train_dense[:,192:256]\n",
    "\n",
    "s1Val=val_dense[:,:64]\n",
    "s2Val=val_dense[:,64:128]\n",
    "s3Val=val_dense[:,128:192]\n",
    "s4Val=val_dense[:,192:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MKx8VcoJxwH0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "s1 (Conv2D)                  (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                32784     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reqs1 (Dense)                (None, 64)                1088      \n",
      "=================================================================\n",
      "Total params: 320,880\n",
      "Trainable params: 320,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model(name):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3), name=name))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform',name='req'+name))\n",
    "\n",
    "    model.compile(optimizer='nadam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "student1 = define_model('s1')\n",
    "student1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bY_42UFKHaZO"
   },
   "source": [
    "TCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with LR\n",
    "s1=define_model(\"s1\")\n",
    "s2=define_model(\"s2\")\n",
    "s3=define_model(\"s3\")\n",
    "s4=define_model(\"s4\")\n",
    "\n",
    "opt=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "157/157 [==============================] - 3s 15ms/step - loss: 1.7822 - val_loss: 1.6569\n",
      "Epoch 2/80\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.6473 - val_loss: 1.6235\n",
      "Epoch 3/80\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.6114 - val_loss: 1.6001\n",
      "Epoch 4/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5845 - val_loss: 1.5294\n",
      "Epoch 5/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5239 - val_loss: 1.4756\n",
      "Epoch 6/80\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.4934 - val_loss: 1.4499\n",
      "Epoch 7/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.4732 - val_loss: 1.4413\n",
      "Epoch 8/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.4643 - val_loss: 1.4281\n",
      "Epoch 9/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.4519 - val_loss: 1.4093\n",
      "Epoch 10/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.4391 - val_loss: 1.3939\n",
      "Epoch 11/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.4257 - val_loss: 1.3777\n",
      "Epoch 12/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.4191 - val_loss: 1.3676\n",
      "Epoch 13/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.4010 - val_loss: 1.3521\n",
      "Epoch 14/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.3917 - val_loss: 1.3432\n",
      "Epoch 15/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3909 - val_loss: 1.3357\n",
      "Epoch 16/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3716 - val_loss: 1.3112\n",
      "Epoch 17/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3611 - val_loss: 1.2982\n",
      "Epoch 18/80\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3519 - val_loss: 1.2805\n",
      "Epoch 19/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.3348 - val_loss: 1.2667\n",
      "Epoch 20/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3241 - val_loss: 1.2545\n",
      "Epoch 21/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.3071 - val_loss: 1.2452\n",
      "Epoch 22/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.2990 - val_loss: 1.2327\n",
      "Epoch 23/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.2931 - val_loss: 1.2231\n",
      "Epoch 24/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.2816 - val_loss: 1.2094\n",
      "Epoch 25/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.2737 - val_loss: 1.1985\n",
      "Epoch 26/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.2580 - val_loss: 1.1884\n",
      "Epoch 27/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.2579 - val_loss: 1.1766\n",
      "Epoch 28/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.2423 - val_loss: 1.1708\n",
      "Epoch 29/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2296 - val_loss: 1.1584\n",
      "Epoch 30/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.2281 - val_loss: 1.1486\n",
      "Epoch 31/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.2239 - val_loss: 1.1439\n",
      "Epoch 32/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.2143 - val_loss: 1.1305\n",
      "Epoch 33/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.2097 - val_loss: 1.1240\n",
      "Epoch 34/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1993 - val_loss: 1.1307\n",
      "Epoch 35/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1995 - val_loss: 1.1217\n",
      "Epoch 36/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1875 - val_loss: 1.1063\n",
      "Epoch 37/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.1857 - val_loss: 1.1044\n",
      "Epoch 38/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1782 - val_loss: 1.0980\n",
      "Epoch 39/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1689 - val_loss: 1.0883\n",
      "Epoch 40/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1639 - val_loss: 1.0933\n",
      "Epoch 41/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1540 - val_loss: 1.0791\n",
      "Epoch 42/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1568 - val_loss: 1.0767\n",
      "Epoch 43/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1499 - val_loss: 1.0778\n",
      "Epoch 44/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1456 - val_loss: 1.0604\n",
      "Epoch 45/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1413 - val_loss: 1.0607\n",
      "Epoch 46/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1323 - val_loss: 1.0526\n",
      "Epoch 47/80\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.1263 - val_loss: 1.0549\n",
      "Epoch 48/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1285 - val_loss: 1.0504\n",
      "Epoch 49/80\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1200 - val_loss: 1.0508\n",
      "Epoch 50/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1213 - val_loss: 1.0465\n",
      "Epoch 51/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1164 - val_loss: 1.0399\n",
      "Epoch 52/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1138 - val_loss: 1.0402\n",
      "Epoch 53/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1066 - val_loss: 1.0354\n",
      "Epoch 54/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1095 - val_loss: 1.0415\n",
      "Epoch 55/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1067 - val_loss: 1.0322\n",
      "Epoch 56/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0976 - val_loss: 1.0270\n",
      "Epoch 57/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0961 - val_loss: 1.0334\n",
      "Epoch 58/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0940 - val_loss: 1.0237\n",
      "Epoch 59/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0951 - val_loss: 1.0214\n",
      "Epoch 60/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0890 - val_loss: 1.0179\n",
      "Epoch 61/80\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.0840 - val_loss: 1.0080\n",
      "Epoch 62/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0819 - val_loss: 1.0093\n",
      "Epoch 63/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0801 - val_loss: 1.0073\n",
      "Epoch 64/80\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0768 - val_loss: 1.0118\n",
      "Epoch 65/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0742 - val_loss: 1.0037\n",
      "Epoch 66/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0682 - val_loss: 1.0039\n",
      "Epoch 67/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0677 - val_loss: 0.9979\n",
      "Epoch 68/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0636 - val_loss: 0.9952\n",
      "Epoch 69/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0668 - val_loss: 0.9977\n",
      "Epoch 70/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0588 - val_loss: 0.9988\n",
      "Epoch 71/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0567 - val_loss: 0.9889\n",
      "Epoch 72/80\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0543 - val_loss: 0.9968\n",
      "Epoch 73/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0573 - val_loss: 0.9949\n",
      "Epoch 74/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0511 - val_loss: 0.9884\n",
      "Epoch 75/80\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.0511 - val_loss: 0.9891\n",
      "Epoch 76/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0501 - val_loss: 0.9922\n",
      "Epoch 77/80\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.0498 - val_loss: 0.9831\n",
      "Epoch 78/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0510 - val_loss: 0.9861\n",
      "Epoch 79/80\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0485 - val_loss: 0.9849\n",
      "Epoch 80/80\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0471 - val_loss: 0.9794\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 15ms/step - loss: 1.7894 - val_loss: 1.6262\n",
      "Epoch 2/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.6197 - val_loss: 1.6158\n",
      "Epoch 3/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.6151 - val_loss: 1.6084\n",
      "Epoch 4/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.6073 - val_loss: 1.6026\n",
      "Epoch 5/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.6062 - val_loss: 1.5977\n",
      "Epoch 6/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.6007 - val_loss: 1.5935\n",
      "Epoch 7/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5935 - val_loss: 1.5898\n",
      "Epoch 8/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5884 - val_loss: 1.5866\n",
      "Epoch 9/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5879 - val_loss: 1.5837\n",
      "Epoch 10/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5802 - val_loss: 1.5810\n",
      "Epoch 11/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5838 - val_loss: 1.5787\n",
      "Epoch 12/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5758 - val_loss: 1.5765\n",
      "Epoch 13/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5745 - val_loss: 1.5746\n",
      "Epoch 14/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5790 - val_loss: 1.5729\n",
      "Epoch 15/60\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.5711 - val_loss: 1.5713\n",
      "Epoch 16/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5687 - val_loss: 1.5698\n",
      "Epoch 17/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5679 - val_loss: 1.5685\n",
      "Epoch 18/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5683 - val_loss: 1.5673\n",
      "Epoch 19/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5661 - val_loss: 1.5663\n",
      "Epoch 20/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5718 - val_loss: 1.5653\n",
      "Epoch 21/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5634 - val_loss: 1.5645\n",
      "Epoch 22/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5644 - val_loss: 1.5637\n",
      "Epoch 23/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5599 - val_loss: 1.5630\n",
      "Epoch 24/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.5641 - val_loss: 1.5624\n",
      "Epoch 25/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5689 - val_loss: 1.5619\n",
      "Epoch 26/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5666 - val_loss: 1.5614\n",
      "Epoch 27/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5605 - val_loss: 1.5610\n",
      "Epoch 28/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5656 - val_loss: 1.5607\n",
      "Epoch 29/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5615 - val_loss: 1.5604\n",
      "Epoch 30/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5570 - val_loss: 1.5601\n",
      "Epoch 31/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5641 - val_loss: 1.5599\n",
      "Epoch 32/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5571 - val_loss: 1.5597\n",
      "Epoch 33/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5604 - val_loss: 1.5595\n",
      "Epoch 34/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5642 - val_loss: 1.5594\n",
      "Epoch 35/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5589 - val_loss: 1.5593\n",
      "Epoch 36/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5623 - val_loss: 1.5592\n",
      "Epoch 37/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.5650 - val_loss: 1.5592\n",
      "Epoch 38/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5566 - val_loss: 1.5591\n",
      "Epoch 39/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5605 - val_loss: 1.5591\n",
      "Epoch 40/60\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.5618 - val_loss: 1.5591\n",
      "Epoch 41/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5628 - val_loss: 1.5590\n",
      "Epoch 42/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5654 - val_loss: 1.5590\n",
      "Epoch 43/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5594 - val_loss: 1.5590\n",
      "Epoch 44/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.5634 - val_loss: 1.5590\n",
      "Epoch 45/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5585 - val_loss: 1.5590\n",
      "Epoch 46/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5580 - val_loss: 1.5590\n",
      "Epoch 47/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5651 - val_loss: 1.5590\n",
      "Epoch 48/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5639 - val_loss: 1.5590\n",
      "Epoch 49/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5544 - val_loss: 1.5590\n",
      "Epoch 50/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5564 - val_loss: 1.5590\n",
      "Epoch 51/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5652 - val_loss: 1.5590\n",
      "Epoch 52/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.5644 - val_loss: 1.5590\n",
      "Epoch 53/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5622 - val_loss: 1.5590\n",
      "Epoch 54/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5666 - val_loss: 1.5590\n",
      "Epoch 55/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5624 - val_loss: 1.5590\n",
      "Epoch 56/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.5568 - val_loss: 1.5590\n",
      "Epoch 57/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.5587 - val_loss: 1.5590\n",
      "Epoch 58/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5571 - val_loss: 1.5590\n",
      "Epoch 59/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.5614 - val_loss: 1.5590\n",
      "Epoch 60/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.5554 - val_loss: 1.5590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff82c280ef0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.compile(loss='mse', optimizer=opt)\n",
    "s2.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "s1.fit(X_train,s1Train,\n",
    "          batch_size=256,\n",
    "          epochs=80,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val,s1Val))\n",
    "\n",
    "s2.fit(X_train,s2Train,\n",
    "          batch_size=256,\n",
    "          epochs=60,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val,s2Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76533,
     "status": "ok",
     "timestamp": 1615397271851,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "tbiMHpxnHbd_",
    "outputId": "e017a372-0165-417b-fce6-f77671de9dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "157/157 [==============================] - 3s 15ms/step - loss: 1.6634 - val_loss: 1.5417\n",
      "Epoch 2/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.5129 - val_loss: 1.4931\n",
      "Epoch 3/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.4880 - val_loss: 1.4725\n",
      "Epoch 4/70\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.4699 - val_loss: 1.4423\n",
      "Epoch 5/70\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.4584 - val_loss: 1.4268\n",
      "Epoch 6/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.4426 - val_loss: 1.4239\n",
      "Epoch 7/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.4409 - val_loss: 1.4158\n",
      "Epoch 8/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.4271 - val_loss: 1.4051\n",
      "Epoch 9/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.4176 - val_loss: 1.3831\n",
      "Epoch 10/70\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.4005 - val_loss: 1.3551\n",
      "Epoch 11/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.3787 - val_loss: 1.3406\n",
      "Epoch 12/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3659 - val_loss: 1.3267\n",
      "Epoch 13/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.3535 - val_loss: 1.3120\n",
      "Epoch 14/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3338 - val_loss: 1.2929\n",
      "Epoch 15/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3253 - val_loss: 1.2775\n",
      "Epoch 16/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.3133 - val_loss: 1.2682\n",
      "Epoch 17/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2951 - val_loss: 1.2529\n",
      "Epoch 18/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.2829 - val_loss: 1.2252\n",
      "Epoch 19/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2698 - val_loss: 1.2085\n",
      "Epoch 20/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2535 - val_loss: 1.1926\n",
      "Epoch 21/70\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.2366 - val_loss: 1.1761\n",
      "Epoch 22/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.2294 - val_loss: 1.1727\n",
      "Epoch 23/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2160 - val_loss: 1.1512\n",
      "Epoch 24/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2026 - val_loss: 1.1510\n",
      "Epoch 25/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.1982 - val_loss: 1.1362\n",
      "Epoch 26/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1869 - val_loss: 1.1259\n",
      "Epoch 27/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1802 - val_loss: 1.1156\n",
      "Epoch 28/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1751 - val_loss: 1.1128\n",
      "Epoch 29/70\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.1666 - val_loss: 1.0990\n",
      "Epoch 30/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1569 - val_loss: 1.0988\n",
      "Epoch 31/70\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.1559 - val_loss: 1.0904\n",
      "Epoch 32/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1472 - val_loss: 1.0862\n",
      "Epoch 33/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1395 - val_loss: 1.0764\n",
      "Epoch 34/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1348 - val_loss: 1.0774\n",
      "Epoch 35/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1314 - val_loss: 1.0817\n",
      "Epoch 36/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.1237 - val_loss: 1.0620\n",
      "Epoch 37/70\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.1176 - val_loss: 1.0544\n",
      "Epoch 38/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1124 - val_loss: 1.0499\n",
      "Epoch 39/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1090 - val_loss: 1.0469\n",
      "Epoch 40/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1006 - val_loss: 1.0397\n",
      "Epoch 41/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0993 - val_loss: 1.0349\n",
      "Epoch 42/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0981 - val_loss: 1.0313\n",
      "Epoch 43/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0886 - val_loss: 1.0216\n",
      "Epoch 44/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0881 - val_loss: 1.0196\n",
      "Epoch 45/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0798 - val_loss: 1.0198\n",
      "Epoch 46/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0783 - val_loss: 1.0103\n",
      "Epoch 47/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0733 - val_loss: 1.0095\n",
      "Epoch 48/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0706 - val_loss: 1.0095\n",
      "Epoch 49/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0661 - val_loss: 1.0038\n",
      "Epoch 50/70\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 1.0594 - val_loss: 0.9943\n",
      "Epoch 51/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0560 - val_loss: 0.9926\n",
      "Epoch 52/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0569 - val_loss: 0.9937\n",
      "Epoch 53/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0540 - val_loss: 0.9844\n",
      "Epoch 54/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0483 - val_loss: 0.9824\n",
      "Epoch 55/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0423 - val_loss: 0.9898\n",
      "Epoch 56/70\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.0470 - val_loss: 0.9775\n",
      "Epoch 57/70\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0389 - val_loss: 0.9754\n",
      "Epoch 58/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0396 - val_loss: 0.9725\n",
      "Epoch 59/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0364 - val_loss: 0.9710\n",
      "Epoch 60/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0337 - val_loss: 0.9689\n",
      "Epoch 61/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0324 - val_loss: 0.9703\n",
      "Epoch 62/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0245 - val_loss: 0.9660\n",
      "Epoch 63/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0259 - val_loss: 0.9589\n",
      "Epoch 64/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0233 - val_loss: 0.9658\n",
      "Epoch 65/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0197 - val_loss: 0.9601\n",
      "Epoch 66/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0234 - val_loss: 0.9590\n",
      "Epoch 67/70\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0146 - val_loss: 0.9621\n",
      "Epoch 68/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0160 - val_loss: 0.9534\n",
      "Epoch 69/70\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0129 - val_loss: 0.9505\n",
      "Epoch 70/70\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0166 - val_loss: 0.9486\n",
      "Epoch 1/60\n",
      "157/157 [==============================] - 3s 15ms/step - loss: 1.5174 - val_loss: 1.4200\n",
      "Epoch 2/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.4137 - val_loss: 1.3971\n",
      "Epoch 3/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.3941 - val_loss: 1.3741\n",
      "Epoch 4/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3784 - val_loss: 1.3591\n",
      "Epoch 5/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3667 - val_loss: 1.3502\n",
      "Epoch 6/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3547 - val_loss: 1.3350\n",
      "Epoch 7/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3371 - val_loss: 1.3205\n",
      "Epoch 8/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3378 - val_loss: 1.3163\n",
      "Epoch 9/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3288 - val_loss: 1.3056\n",
      "Epoch 10/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3231 - val_loss: 1.3036\n",
      "Epoch 11/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 14ms/step - loss: 1.3211 - val_loss: 1.3004\n",
      "Epoch 12/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3129 - val_loss: 1.2888\n",
      "Epoch 13/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.3085 - val_loss: 1.2856\n",
      "Epoch 14/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3087 - val_loss: 1.2805\n",
      "Epoch 15/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.3011 - val_loss: 1.2769\n",
      "Epoch 16/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2918 - val_loss: 1.2717\n",
      "Epoch 17/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.2915 - val_loss: 1.2543\n",
      "Epoch 18/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.2722 - val_loss: 1.2335\n",
      "Epoch 19/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.2618 - val_loss: 1.2236\n",
      "Epoch 20/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.2529 - val_loss: 1.2095\n",
      "Epoch 21/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2349 - val_loss: 1.1863\n",
      "Epoch 22/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.2201 - val_loss: 1.1663\n",
      "Epoch 23/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.2009 - val_loss: 1.1453\n",
      "Epoch 24/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1895 - val_loss: 1.1387\n",
      "Epoch 25/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1820 - val_loss: 1.1265\n",
      "Epoch 26/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.1739 - val_loss: 1.1141\n",
      "Epoch 27/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.1646 - val_loss: 1.1018\n",
      "Epoch 28/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1570 - val_loss: 1.0999\n",
      "Epoch 29/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.1472 - val_loss: 1.0909\n",
      "Epoch 30/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.1446 - val_loss: 1.0853\n",
      "Epoch 31/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1351 - val_loss: 1.0716\n",
      "Epoch 32/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1300 - val_loss: 1.0651\n",
      "Epoch 33/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1251 - val_loss: 1.0661\n",
      "Epoch 34/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1209 - val_loss: 1.0535\n",
      "Epoch 35/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.1151 - val_loss: 1.0532\n",
      "Epoch 36/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.1090 - val_loss: 1.0416\n",
      "Epoch 37/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1057 - val_loss: 1.0431\n",
      "Epoch 38/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1021 - val_loss: 1.0411\n",
      "Epoch 39/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.1016 - val_loss: 1.0280\n",
      "Epoch 40/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.1014 - val_loss: 1.0330\n",
      "Epoch 41/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0943 - val_loss: 1.0219\n",
      "Epoch 42/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.0919 - val_loss: 1.0156\n",
      "Epoch 43/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0922 - val_loss: 1.0117\n",
      "Epoch 44/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0811 - val_loss: 1.0048\n",
      "Epoch 45/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0779 - val_loss: 0.9990\n",
      "Epoch 46/60\n",
      "157/157 [==============================] - 2s 13ms/step - loss: 1.0693 - val_loss: 0.9900\n",
      "Epoch 47/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0677 - val_loss: 0.9885\n",
      "Epoch 48/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0650 - val_loss: 0.9881\n",
      "Epoch 49/60\n",
      "157/157 [==============================] - 2s 14ms/step - loss: 1.0574 - val_loss: 0.9780\n",
      "Epoch 50/60\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.0513 - val_loss: 0.9750\n",
      "Epoch 51/60\n",
      "157/157 [==============================] - 2s 16ms/step - loss: 1.0431 - val_loss: 0.9660\n",
      "Epoch 52/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0420 - val_loss: 0.9647\n",
      "Epoch 53/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0356 - val_loss: 0.9562\n",
      "Epoch 54/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0293 - val_loss: 0.9560\n",
      "Epoch 55/60\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 1.0269 - val_loss: 0.9492\n",
      "Epoch 56/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0256 - val_loss: 0.9465\n",
      "Epoch 57/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0189 - val_loss: 0.9434\n",
      "Epoch 58/60\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.0142 - val_loss: 0.9347\n",
      "Epoch 59/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0118 - val_loss: 0.9262\n",
      "Epoch 60/60\n",
      "157/157 [==============================] - 2s 15ms/step - loss: 1.0073 - val_loss: 0.9261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff96f2812b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.compile(loss='mse', optimizer=opt)\n",
    "s4.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "s3.fit(X_train,s3Train,\n",
    "          batch_size=256,\n",
    "          epochs=70,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val,s3Val))\n",
    "\n",
    "s4.fit(X_train,s4Train,\n",
    "          batch_size=256,\n",
    "          epochs=60,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val,s4Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mMTpeLnwINEn"
   },
   "outputs": [],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "o2=s2.get_layer(\"reqs2\").output\n",
    "o3=s3.get_layer(\"reqs3\").output\n",
    "o4=s4.get_layer(\"reqs4\").output\n",
    "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4])\n",
    "\n",
    "output=Activation('relu')(output)\n",
    "output2=Dropout(0.5)(output) # For reguralization\n",
    "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
    "\n",
    "mm4=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input,\n",
    "           s3.get_layer(\"s3\").input,s4.get_layer(\"s4\").input], output3)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()\n",
    "mm4.get_layer('d1').set_weights(my_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102421,
     "status": "ok",
     "timestamp": 1615397435107,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "q8bMaMg4LSpu",
    "outputId": "f7d52f3f-412d-4927-fd34-69341ee200a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 4s 23ms/step - loss: 0.9913 - accuracy: 0.7471 - val_loss: 0.7647 - val_accuracy: 0.8104\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.7192 - accuracy: 0.8060 - val_loss: 0.6967 - val_accuracy: 0.8192\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.6643 - accuracy: 0.8211 - val_loss: 0.6739 - val_accuracy: 0.8208\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.6479 - accuracy: 0.8212 - val_loss: 0.6600 - val_accuracy: 0.8220\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.6364 - accuracy: 0.8214 - val_loss: 0.6491 - val_accuracy: 0.8224\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5985 - accuracy: 0.8325 - val_loss: 0.6433 - val_accuracy: 0.8213\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.6152 - accuracy: 0.8231 - val_loss: 0.6360 - val_accuracy: 0.8218\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5931 - accuracy: 0.8305 - val_loss: 0.6286 - val_accuracy: 0.8214\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5943 - accuracy: 0.8275 - val_loss: 0.6229 - val_accuracy: 0.8216\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5735 - accuracy: 0.8330 - val_loss: 0.6169 - val_accuracy: 0.8224\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5605 - accuracy: 0.8363 - val_loss: 0.6121 - val_accuracy: 0.8221\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5672 - accuracy: 0.8323 - val_loss: 0.6075 - val_accuracy: 0.8220\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5537 - accuracy: 0.8371 - val_loss: 0.6054 - val_accuracy: 0.8223\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5463 - accuracy: 0.8387 - val_loss: 0.6021 - val_accuracy: 0.8216\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.5546 - accuracy: 0.8361 - val_loss: 0.5990 - val_accuracy: 0.8219\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5541 - accuracy: 0.8372 - val_loss: 0.5969 - val_accuracy: 0.8219\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5451 - accuracy: 0.8405 - val_loss: 0.5940 - val_accuracy: 0.8217\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5476 - accuracy: 0.8391 - val_loss: 0.5921 - val_accuracy: 0.8221\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5297 - accuracy: 0.8397 - val_loss: 0.5892 - val_accuracy: 0.8221\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5221 - accuracy: 0.8433 - val_loss: 0.5867 - val_accuracy: 0.8224\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5297 - accuracy: 0.8438 - val_loss: 0.5866 - val_accuracy: 0.8216\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5326 - accuracy: 0.8435 - val_loss: 0.5849 - val_accuracy: 0.8219\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.5302 - accuracy: 0.8436 - val_loss: 0.5818 - val_accuracy: 0.8217\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.5322 - accuracy: 0.8410 - val_loss: 0.5797 - val_accuracy: 0.8226\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5164 - accuracy: 0.8480 - val_loss: 0.5796 - val_accuracy: 0.8215\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.5151 - accuracy: 0.8454 - val_loss: 0.5776 - val_accuracy: 0.8224\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5117 - accuracy: 0.8474 - val_loss: 0.5768 - val_accuracy: 0.8215\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.5119 - accuracy: 0.8475 - val_loss: 0.5753 - val_accuracy: 0.8219\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5184 - accuracy: 0.8433 - val_loss: 0.5742 - val_accuracy: 0.8225\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5087 - accuracy: 0.8481 - val_loss: 0.5743 - val_accuracy: 0.8216\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5002 - accuracy: 0.8488 - val_loss: 0.5741 - val_accuracy: 0.8219\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5053 - accuracy: 0.8479 - val_loss: 0.5730 - val_accuracy: 0.8219\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5025 - accuracy: 0.8500 - val_loss: 0.5715 - val_accuracy: 0.8228\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.5129 - accuracy: 0.8479 - val_loss: 0.5717 - val_accuracy: 0.8214\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4986 - accuracy: 0.8511 - val_loss: 0.5711 - val_accuracy: 0.8214\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5098 - accuracy: 0.8450 - val_loss: 0.5709 - val_accuracy: 0.8217\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4995 - accuracy: 0.8476 - val_loss: 0.5685 - val_accuracy: 0.8228\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4909 - accuracy: 0.8515 - val_loss: 0.5698 - val_accuracy: 0.8224\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5016 - accuracy: 0.8494 - val_loss: 0.5690 - val_accuracy: 0.8217\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.5128 - accuracy: 0.8475 - val_loss: 0.5666 - val_accuracy: 0.8224\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4964 - accuracy: 0.8513 - val_loss: 0.5690 - val_accuracy: 0.8223\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4935 - accuracy: 0.8494 - val_loss: 0.5680 - val_accuracy: 0.8221\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4980 - accuracy: 0.8494 - val_loss: 0.5688 - val_accuracy: 0.8220\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5105 - accuracy: 0.8473 - val_loss: 0.5673 - val_accuracy: 0.8223\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.4980 - accuracy: 0.8527 - val_loss: 0.5675 - val_accuracy: 0.8226\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.5010 - accuracy: 0.8470 - val_loss: 0.5660 - val_accuracy: 0.8224\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5018 - accuracy: 0.8500 - val_loss: 0.5659 - val_accuracy: 0.8224\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.4855 - accuracy: 0.8549 - val_loss: 0.5669 - val_accuracy: 0.8216\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4912 - accuracy: 0.8526 - val_loss: 0.5667 - val_accuracy: 0.8222\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.4958 - accuracy: 0.8523 - val_loss: 0.5661 - val_accuracy: 0.8224\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for l in mm4.layers[:len(mm4.layers)-2]:\n",
    "    l.trainable=False\n",
    "#     print(l)\n",
    "\n",
    "mm4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.0002),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Without finetune\n",
    "batch_size = 256\n",
    "mm4_history=mm4.fit([X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=([X_val,X_val,X_val,X_val], Y_val))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPTm9YeeSB+3Gf0CIynn7z/",
   "collapsed_sections": [],
   "name": "TCN of 4 students_cifar10.ipynb",
   "provenance": [
    {
     "file_id": "1cOPFNhK21MmKbwbCAO4yjv7kV8H67NCK",
     "timestamp": 1615396059816
    },
    {
     "file_id": "1Cm9yNETjuUpv4daBA58tZg9SD4XBSgmd",
     "timestamp": 1615379925623
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
