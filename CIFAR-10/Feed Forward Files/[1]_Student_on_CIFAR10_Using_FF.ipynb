{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[1] Student on CIFAR10 Using FF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "imgZBevn_klO"
      },
      "source": [
        "# %tensorflow_version 1.x\n",
        "# !pip install --upgrade opencv-python==3.4.2.17\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.backend as K\n",
        "# import os\n",
        "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
        "# import keras.backend as K\n",
        "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras.utils import Progbar\n",
        "from keras.initializers import RandomNormal\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from keras.utils import np_utils\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-DYwB8kiFk"
      },
      "source": [
        "nb_classes = 10\n",
        "batch_size = 128\n",
        "maxepoches = 250\n",
        "learning_rate = 0.1\n",
        "lr_decay = 1e-6\n",
        "lr_drop = 20\n",
        "def lr_scheduler(epoch):\n",
        "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04yi6rW_qJg",
        "outputId": "12ec5b1b-2a50-4ca4-abad-636ef28383ed"
      },
      "source": [
        "#Loading and splitting the dataset into train, validation and test\n",
        "\n",
        "\n",
        "(X_Train, y_Train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
        "# convert y_train and y_test to categorical binary values \n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
        "y_test = np_utils.to_categorical(y_test, nb_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj_XM_dfmqnV",
        "outputId": "7142dd39-0643-4a71-ec1a-8188cc710e84"
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "443_UL2p_qyQ"
      },
      "source": [
        "# Reshape them to batch_size, width,height,#channels\n",
        "X_train = X_train.reshape(40000, 32, 32, 3)\n",
        "X_val = X_val.reshape(10000, 32, 32, 3)\n",
        "X_test = X_test.reshape(10000, 32, 32, 3)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize the values\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQn2hUFNVDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e1ec34-e369-4300-8eb0-1dd7d61b21a2"
      },
      "source": [
        "init=RandomNormal(mean=0,stddev=0.02)\n",
        "input_shape = (32, 32, 3) # Input shape of each image\n",
        "weight_decay = 0.0005\n",
        "def build_model():\n",
        "    # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay), name='dense_1'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, name='dense_2'))\n",
        "    model.add(Activation('softmax'))\n",
        "    return model\n",
        "teacher = build_model()\n",
        "\n",
        "sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "\n",
        "teacher.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp4il80HMRFn"
      },
      "source": [
        "# teacher.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1,callbacks=[reduce_lr],validation_data=(X_val,Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU8uZIWuQWKA"
      },
      "source": [
        "teacher.load_weights(\"Cifar10_Teacher.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBZO-MXLmml_",
        "outputId": "e50939c1-acc5-49e5-c358-b3ac99fdb8d5"
      },
      "source": [
        "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "loss, acc =teacher.evaluate(X_test, y_test, verbose=1)\n",
        "loss, acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8247 - accuracy: 0.8996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.834343671798706, 0.8992000222206116)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPVxVj6L_sCz"
      },
      "source": [
        "#Collect the dense vector from the previous layer output and store it in a different model\n",
        "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhcEQ0Z-_scF"
      },
      "source": [
        "#Extracting dense representation from the teacher network\n",
        "train_dense = teacher_WO_Softmax.predict(X_train)\n",
        "val_dense = teacher_WO_Softmax.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG0WGCpM_suF"
      },
      "source": [
        "#Splitting the training dense vector among N students(in this case 2)\n",
        "s1Train=train_dense[:,:256]\n",
        "s1Val=val_dense[:,:256]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKx8VcoJxwH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5344260-5864-4546-ebd7-7c9e7749e8b0"
      },
      "source": [
        "def define_model(name):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3), name=name))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu', kernel_initializer='he_uniform',name='req'+name))\n",
        "\n",
        "    model.compile(optimizer='nadam', loss='mse', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "student1 = define_model('s1')\n",
        "student1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "s1 (Conv2D)                  (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                262208    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "reqs1 (Dense)                (None, 256)               16640     \n",
            "=================================================================\n",
            "Total params: 1,358,816\n",
            "Trainable params: 1,358,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY_42UFKHaZO"
      },
      "source": [
        "TCN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6twSYZC8Y6Y"
      },
      "source": [
        "# Testing with LR\n",
        "s1=define_model(\"s1\")\n",
        "\n",
        "opt=Adam(lr=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnS8TS5u8Y6Z",
        "outputId": "731f24fe-e9ed-40d5-bc4c-b0a74fd4f890"
      },
      "source": [
        "s1.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "s1.fit(X_train,s1Train,\n",
        "          batch_size=256,\n",
        "          epochs=80,\n",
        "          verbose=1,\n",
        "          validation_data=(X_val,s1Val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "157/157 [==============================] - 3s 15ms/step - loss: 1.7760 - val_loss: 1.5999\n",
            "Epoch 2/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.5822 - val_loss: 1.5609\n",
            "Epoch 3/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.5335 - val_loss: 1.5122\n",
            "Epoch 4/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.4935 - val_loss: 1.4719\n",
            "Epoch 5/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.4664 - val_loss: 1.4405\n",
            "Epoch 6/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.4447 - val_loss: 1.4194\n",
            "Epoch 7/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.4272 - val_loss: 1.4062\n",
            "Epoch 8/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4168 - val_loss: 1.3989\n",
            "Epoch 9/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.4060 - val_loss: 1.3892\n",
            "Epoch 10/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.4023 - val_loss: 1.3835\n",
            "Epoch 11/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.3891 - val_loss: 1.3696\n",
            "Epoch 12/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.3840 - val_loss: 1.3589\n",
            "Epoch 13/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.3740 - val_loss: 1.3450\n",
            "Epoch 14/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.3640 - val_loss: 1.3319\n",
            "Epoch 15/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.3553 - val_loss: 1.3268\n",
            "Epoch 16/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.3471 - val_loss: 1.3140\n",
            "Epoch 17/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.3385 - val_loss: 1.3027\n",
            "Epoch 18/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.3225 - val_loss: 1.2957\n",
            "Epoch 19/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.3168 - val_loss: 1.2767\n",
            "Epoch 20/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.3067 - val_loss: 1.2665\n",
            "Epoch 21/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.2907 - val_loss: 1.2541\n",
            "Epoch 22/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.2848 - val_loss: 1.2370\n",
            "Epoch 23/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2722 - val_loss: 1.2250\n",
            "Epoch 24/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.2648 - val_loss: 1.2061\n",
            "Epoch 25/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.2559 - val_loss: 1.1951\n",
            "Epoch 26/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.2345 - val_loss: 1.1867\n",
            "Epoch 27/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.2301 - val_loss: 1.1774\n",
            "Epoch 28/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.2205 - val_loss: 1.1597\n",
            "Epoch 29/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.2104 - val_loss: 1.1502\n",
            "Epoch 30/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.2018 - val_loss: 1.1474\n",
            "Epoch 31/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1932 - val_loss: 1.1401\n",
            "Epoch 32/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1851 - val_loss: 1.1409\n",
            "Epoch 33/80\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.1802 - val_loss: 1.1168\n",
            "Epoch 34/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1727 - val_loss: 1.1042\n",
            "Epoch 35/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1605 - val_loss: 1.1098\n",
            "Epoch 36/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1512 - val_loss: 1.0944\n",
            "Epoch 37/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1446 - val_loss: 1.0826\n",
            "Epoch 38/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1474 - val_loss: 1.0732\n",
            "Epoch 39/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1377 - val_loss: 1.0805\n",
            "Epoch 40/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.1300 - val_loss: 1.0649\n",
            "Epoch 41/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.1213 - val_loss: 1.0592\n",
            "Epoch 42/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.1161 - val_loss: 1.0509\n",
            "Epoch 43/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.1120 - val_loss: 1.0493\n",
            "Epoch 44/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.1027 - val_loss: 1.0392\n",
            "Epoch 45/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.1019 - val_loss: 1.0380\n",
            "Epoch 46/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.0984 - val_loss: 1.0285\n",
            "Epoch 47/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0944 - val_loss: 1.0261\n",
            "Epoch 48/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0797 - val_loss: 1.0185\n",
            "Epoch 49/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0833 - val_loss: 1.0219\n",
            "Epoch 50/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0753 - val_loss: 1.0155\n",
            "Epoch 51/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0740 - val_loss: 1.0115\n",
            "Epoch 52/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0731 - val_loss: 1.0070\n",
            "Epoch 53/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0641 - val_loss: 1.0006\n",
            "Epoch 54/80\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 1.0643 - val_loss: 0.9997\n",
            "Epoch 55/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0605 - val_loss: 1.0073\n",
            "Epoch 56/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0548 - val_loss: 0.9919\n",
            "Epoch 57/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0529 - val_loss: 0.9901\n",
            "Epoch 58/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0529 - val_loss: 0.9930\n",
            "Epoch 59/80\n",
            "157/157 [==============================] - 3s 16ms/step - loss: 1.0499 - val_loss: 0.9908\n",
            "Epoch 60/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0473 - val_loss: 0.9835\n",
            "Epoch 61/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0406 - val_loss: 0.9806\n",
            "Epoch 62/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0432 - val_loss: 0.9814\n",
            "Epoch 63/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0368 - val_loss: 0.9783\n",
            "Epoch 64/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0377 - val_loss: 0.9786\n",
            "Epoch 65/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0325 - val_loss: 0.9773\n",
            "Epoch 66/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0324 - val_loss: 0.9700\n",
            "Epoch 67/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0257 - val_loss: 0.9671\n",
            "Epoch 68/80\n",
            "157/157 [==============================] - 2s 16ms/step - loss: 1.0286 - val_loss: 0.9677\n",
            "Epoch 69/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0262 - val_loss: 0.9636\n",
            "Epoch 70/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0196 - val_loss: 0.9614\n",
            "Epoch 71/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0195 - val_loss: 0.9618\n",
            "Epoch 72/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0142 - val_loss: 0.9678\n",
            "Epoch 73/80\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.0195 - val_loss: 0.9666\n",
            "Epoch 74/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0116 - val_loss: 0.9605\n",
            "Epoch 75/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0186 - val_loss: 0.9529\n",
            "Epoch 76/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0118 - val_loss: 0.9530\n",
            "Epoch 77/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0139 - val_loss: 0.9531\n",
            "Epoch 78/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0080 - val_loss: 0.9512\n",
            "Epoch 79/80\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 1.0029 - val_loss: 0.9469\n",
            "Epoch 80/80\n",
            "157/157 [==============================] - 2s 15ms/step - loss: 1.0050 - val_loss: 0.9483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f94e07ab4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMTpeLnwINEn"
      },
      "source": [
        "output=s1.get_layer(\"reqs1\").output\n",
        "\n",
        "output=Activation('relu')(output)\n",
        "output2=Dropout(0.5)(output) # For reguralization\n",
        "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
        "\n",
        "mm=Model(s1.get_layer(\"s1\").input, output3)\n",
        "my_weights=teacher.get_layer('dense_2').get_weights()\n",
        "mm.get_layer('d1').set_weights(my_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8bMaMg4LSpu",
        "outputId": "f7d52f3f-412d-4927-fd34-69341ee200a4"
      },
      "source": [
        "i=0\n",
        "for l in mm.layers[:len(mm.layers)-2]:\n",
        "    l.trainable=False\n",
        "#     print(l)\n",
        "\n",
        "mm.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0002),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Without finetune\n",
        "batch_size = 256\n",
        "mm_history=mm.fit([X_train], Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          validation_data=([X_val], Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "157/157 [==============================] - 2s 9ms/step - loss: 1.4346 - accuracy: 0.7275 - val_loss: 1.0192 - val_accuracy: 0.8067\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 1.1096 - accuracy: 0.7642 - val_loss: 0.8819 - val_accuracy: 0.8121\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 1.0334 - accuracy: 0.7646 - val_loss: 0.7984 - val_accuracy: 0.8132\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.9726 - accuracy: 0.7635 - val_loss: 0.7389 - val_accuracy: 0.8136\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.9231 - accuracy: 0.7607 - val_loss: 0.7023 - val_accuracy: 0.8129\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.9009 - accuracy: 0.7614 - val_loss: 0.6702 - val_accuracy: 0.8140\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8630 - accuracy: 0.7620 - val_loss: 0.6552 - val_accuracy: 0.8124\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.8497 - accuracy: 0.7637 - val_loss: 0.6441 - val_accuracy: 0.8124\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.8350 - accuracy: 0.7615 - val_loss: 0.6350 - val_accuracy: 0.8125\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.8273 - accuracy: 0.7680 - val_loss: 0.6261 - val_accuracy: 0.8125\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.8034 - accuracy: 0.7689 - val_loss: 0.6190 - val_accuracy: 0.8131\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.8125 - accuracy: 0.7689 - val_loss: 0.6156 - val_accuracy: 0.8128\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.7867 - accuracy: 0.7699 - val_loss: 0.6115 - val_accuracy: 0.8129\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7880 - accuracy: 0.7693 - val_loss: 0.6063 - val_accuracy: 0.8128\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.7863 - accuracy: 0.7663 - val_loss: 0.6065 - val_accuracy: 0.8121\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.7786 - accuracy: 0.7736 - val_loss: 0.6019 - val_accuracy: 0.8126\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.7670 - accuracy: 0.7721 - val_loss: 0.6021 - val_accuracy: 0.8118\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.7744 - accuracy: 0.7712 - val_loss: 0.5949 - val_accuracy: 0.8138\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7616 - accuracy: 0.7725 - val_loss: 0.5951 - val_accuracy: 0.8128\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.7374 - accuracy: 0.7787 - val_loss: 0.5929 - val_accuracy: 0.8134\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.7452 - accuracy: 0.7757 - val_loss: 0.5898 - val_accuracy: 0.8135\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 2s 10ms/step - loss: 0.7341 - accuracy: 0.7818 - val_loss: 0.5898 - val_accuracy: 0.8135\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.7372 - accuracy: 0.7801 - val_loss: 0.5908 - val_accuracy: 0.8130\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7325 - accuracy: 0.7812 - val_loss: 0.5895 - val_accuracy: 0.8131\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.7250 - accuracy: 0.7815 - val_loss: 0.5865 - val_accuracy: 0.8141\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.7216 - accuracy: 0.7856 - val_loss: 0.5844 - val_accuracy: 0.8139\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7164 - accuracy: 0.7852 - val_loss: 0.5831 - val_accuracy: 0.8141\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7091 - accuracy: 0.7855 - val_loss: 0.5850 - val_accuracy: 0.8139\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7182 - accuracy: 0.7840 - val_loss: 0.5843 - val_accuracy: 0.8137\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.7226 - accuracy: 0.7836 - val_loss: 0.5850 - val_accuracy: 0.8123\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.7073 - accuracy: 0.7862 - val_loss: 0.5812 - val_accuracy: 0.8146\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.7091 - accuracy: 0.7854 - val_loss: 0.5809 - val_accuracy: 0.8138\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.7058 - accuracy: 0.7845 - val_loss: 0.5824 - val_accuracy: 0.8136\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7056 - accuracy: 0.7887 - val_loss: 0.5849 - val_accuracy: 0.8138\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6997 - accuracy: 0.7844 - val_loss: 0.5802 - val_accuracy: 0.8137\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6984 - accuracy: 0.7844 - val_loss: 0.5825 - val_accuracy: 0.8130\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6938 - accuracy: 0.7893 - val_loss: 0.5800 - val_accuracy: 0.8124\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.7085 - accuracy: 0.7841 - val_loss: 0.5804 - val_accuracy: 0.8134\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6979 - accuracy: 0.7874 - val_loss: 0.5816 - val_accuracy: 0.8136\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6940 - accuracy: 0.7888 - val_loss: 0.5804 - val_accuracy: 0.8137\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6951 - accuracy: 0.7886 - val_loss: 0.5802 - val_accuracy: 0.8136\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6999 - accuracy: 0.7868 - val_loss: 0.5807 - val_accuracy: 0.8132\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6830 - accuracy: 0.7904 - val_loss: 0.5785 - val_accuracy: 0.8136\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6897 - accuracy: 0.7909 - val_loss: 0.5799 - val_accuracy: 0.8133\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6905 - accuracy: 0.7879 - val_loss: 0.5804 - val_accuracy: 0.8136\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.6953 - accuracy: 0.7865 - val_loss: 0.5801 - val_accuracy: 0.8134\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 1s 7ms/step - loss: 0.6897 - accuracy: 0.7910 - val_loss: 0.5772 - val_accuracy: 0.8139\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6876 - accuracy: 0.7906 - val_loss: 0.5794 - val_accuracy: 0.8139\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.6834 - accuracy: 0.7910 - val_loss: 0.5769 - val_accuracy: 0.8140\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 1s 10ms/step - loss: 0.6942 - accuracy: 0.7884 - val_loss: 0.5789 - val_accuracy: 0.8140\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}