{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imgZBevn_klO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v0-DYwB8kiFk"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "batch_size = 128\n",
    "maxepoches = 250\n",
    "learning_rate = 0.1\n",
    "lr_decay = 1e-6\n",
    "lr_drop = 20\n",
    "def lr_scheduler(epoch):\n",
    "    return learning_rate * (0.5 ** (epoch // lr_drop))\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6634,
     "status": "ok",
     "timestamp": 1615381546649,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "e04yi6rW_qJg",
    "outputId": "aef45165-6a2b-49e6-e48d-57f5395972f3"
   },
   "outputs": [],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "(X_Train, y_Train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "# convert y_train and y_test to categorical binary values \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6567,
     "status": "ok",
     "timestamp": 1615381546651,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "Lj_XM_dfmqnV",
    "outputId": "79546445-241c-471d-887b-e1d8b90b0620"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "443_UL2p_qyQ"
   },
   "outputs": [],
   "source": [
    "# Reshape them to batch_size, width,height,#channels\n",
    "X_train = X_train.reshape(40000, 32, 32, 3)\n",
    "X_val = X_val.reshape(10000, 32, 32, 3)\n",
    "X_test = X_test.reshape(10000, 32, 32, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5aQn2hUFNVDY"
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "init=RandomNormal(mean=0,stddev=0.02)\n",
    "input_shape = (32, 32, 3) # Input shape of each image\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# Network Creation\n",
    "def build_model():\n",
    "    # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,kernel_regularizer=regularizers.l2(weight_decay), name='dense_1'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, name='dense_2'))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "teacher = build_model()\n",
    "sgd = SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
    "teacher.compile(loss='categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  You can download the weights here, filename = Cifar10_Teacher\n",
    "url = \"https://drive.google.com/file/d/175vv6228njC1EfpH9jeAAoroG1U9BB46/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mp4il80HMRFn"
   },
   "outputs": [],
   "source": [
    "# teacher.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1,callbacks=[reduce_lr],validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1615381722530,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "SUP-wIXJQHNB",
    "outputId": "62a1c3d4-2a3b-4d7d-feb5-08c0aee38e28"
   },
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Cifar10_Teacher.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37106,
     "status": "ok",
     "timestamp": 1615381869043,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "zBZO-MXLmml_",
    "outputId": "2c208712-c6c2-4119-8fb8-fb9dc07d06b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 8ms/step - loss: 0.8247 - accuracy: 0.8996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.834343671798706, 0.8992000222206116)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "loss, acc =teacher.evaluate(X_test, y_test, verbose=1)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bPVxVj6L_sCz"
   },
   "outputs": [],
   "source": [
    "#Collect the dense vector from the previous layer output and store it in a different model\n",
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GhcEQ0Z-_scF"
   },
   "outputs": [],
   "source": [
    "#Extracting dense representation from the teacher network\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XG0WGCpM_suF"
   },
   "outputs": [],
   "source": [
    "#Splitting the training dense vector among N students\n",
    "s1Train=train_dense[:,:64]\n",
    "s2Train=train_dense[:,64:128]\n",
    "s3Train=train_dense[:,128:192]\n",
    "s4Train=train_dense[:,192:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MKx8VcoJxwH0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "s1 (Conv2D)                  (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                32784     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reqs1 (Dense)                (None, 64)                1088      \n",
      "=================================================================\n",
      "Total params: 320,880\n",
      "Trainable params: 320,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_model(name):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3), name=name))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform',name='req'+name))\n",
    "\n",
    "    # compile model\n",
    "    # opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "student1 = define_model('s1')\n",
    "student1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5Bf51HQeYB19"
   },
   "outputs": [],
   "source": [
    "# import np.random import random\n",
    "BATCH_SIZE=32\n",
    "def smooth_real_labels(y):\n",
    "    return y - 0.3+(np.random.random(y.shape)*0.5)\n",
    "def smooth_fake_labels(y):\n",
    "    return y + (0.3 * np.random.random(y.shape))\n",
    "def build_gan(gen,disc): \n",
    "    disc.trainable = False\n",
    "    input= Input(shape=input_shape)\n",
    "    output = gen(input)\n",
    "    output2= disc(output)\n",
    "    gan=Model(input,output2)\n",
    "\n",
    "    gan.compile(Adam(lr=0.0002),loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7DN9rlsCXBHl"
   },
   "outputs": [],
   "source": [
    "def build_sdiscriminator():\n",
    "    \n",
    "    input2 = Input(shape=(64,),name='input')\n",
    "    inp=Dense(128)(input2)\n",
    "\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(inp)\n",
    "    \n",
    "    conv3 = Dense(128,activation='relu')(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv3 = Dense(128,activation='relu')(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv3 = Dense(128,activation='relu')(b_n)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(256,activation='relu')(b_n)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(256,activation='relu')(b_n)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    # conv4 = Dense(512)(leaky_relu)\n",
    "    # b_n = BatchNormalization()(conv4)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "\n",
    "    dense = Dense(1,activation='sigmoid')(b_n)\n",
    "\n",
    "    output2=Dense(64)(b_n)\n",
    "\n",
    "    \n",
    "    disc = Model(input2,[dense,output2])          \n",
    "    disc.compile(optd,loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HP0r1sO5ACHS"
   },
   "outputs": [],
   "source": [
    "def training(generator,discriminator,gan,features,epo=20):\n",
    "    # Setup Models here\n",
    "    BATCH_SIZE = 128\n",
    "    discriminator.trainable = True\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    all_class_loss=[]\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(epo):\n",
    "        \n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        epoch_class_loss= []\n",
    "        for i,index in enumerate(indices):\n",
    "        \n",
    "            # Write your code here\n",
    "            inputs=X_train[index:index+BATCH_SIZE]\n",
    "            real_image = features[index:index+BATCH_SIZE]\n",
    "            y_train = features[index:index+BATCH_SIZE]\n",
    "\n",
    "            y_real = np.ones((BATCH_SIZE,1))\n",
    "            y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "            #Generator Training\n",
    "            fake_images = generator.predict_on_batch(inputs)\n",
    "\n",
    "            #Disrciminator Training\n",
    "            disc_real_loss1,_,disc_real_loss2,_,_= discriminator.train_on_batch(real_image,[y_real,y_train])\n",
    "            disc_fake_loss1,_,disc_fake_loss2,_,_= discriminator.train_on_batch(fake_images,[y_fake,y_train])\n",
    "\n",
    "            #Gans Training\n",
    "            discriminator.trainable = False\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,y_train])\n",
    "\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            disc_loss = (disc_fake_loss1 + disc_real_loss1)/2\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            progress_bar.update(i+1)\n",
    "\n",
    "            epoch_gen_loss.append((gan_loss))\n",
    "\n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f | \" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807078,
     "status": "ok",
     "timestamp": 1615384783344,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "fMuyg_3pACVM",
    "outputId": "6dd97019-2ed9-4612-c68d-4e1307f2e625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 30s 91ms/step\n",
      "Epoch: 1 | Discriminator Loss: 1.723542 | Generator Loss: 2.065445 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 2 | Discriminator Loss: 1.329637 | Generator Loss: 1.875053 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 3 | Discriminator Loss: 1.277050 | Generator Loss: 1.865875 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 4 | Discriminator Loss: 1.203630 | Generator Loss: 1.760023 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 5 | Discriminator Loss: 1.117797 | Generator Loss: 1.618527 | \n",
      "312/312 [==============================] - 26s 85ms/step\n",
      "Epoch: 6 | Discriminator Loss: 1.058487 | Generator Loss: 1.526602 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 7 | Discriminator Loss: 1.016091 | Generator Loss: 1.454672 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.984249 | Generator Loss: 1.382715 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.957391 | Generator Loss: 1.336991 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.937484 | Generator Loss: 1.294339 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.919255 | Generator Loss: 1.258345 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.903603 | Generator Loss: 1.234042 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.890272 | Generator Loss: 1.202542 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.878789 | Generator Loss: 1.183396 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.866660 | Generator Loss: 1.157181 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.858271 | Generator Loss: 1.146040 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.849577 | Generator Loss: 1.133320 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.841735 | Generator Loss: 1.120879 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.834634 | Generator Loss: 1.111234 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.827365 | Generator Loss: 1.105696 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.822222 | Generator Loss: 1.092248 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.816226 | Generator Loss: 1.081773 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.810876 | Generator Loss: 1.072512 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.807026 | Generator Loss: 1.064955 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.803293 | Generator Loss: 1.058947 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.798527 | Generator Loss: 1.045006 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.794819 | Generator Loss: 1.041187 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.791464 | Generator Loss: 1.041922 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.788143 | Generator Loss: 1.031576 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.783958 | Generator Loss: 1.022736 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.781673 | Generator Loss: 1.026172 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.778446 | Generator Loss: 1.019903 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.776134 | Generator Loss: 1.014185 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.773770 | Generator Loss: 1.002437 | \n",
      "312/312 [==============================] - 30s 96ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.771491 | Generator Loss: 1.005373 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.769189 | Generator Loss: 0.997764 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.767267 | Generator Loss: 0.986268 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.764445 | Generator Loss: 0.980797 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.762745 | Generator Loss: 0.980128 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.762137 | Generator Loss: 0.980884 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.760558 | Generator Loss: 0.974235 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.758315 | Generator Loss: 0.972580 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.757323 | Generator Loss: 0.972863 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.755861 | Generator Loss: 0.963803 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.754854 | Generator Loss: 0.963544 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.754031 | Generator Loss: 0.956433 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.752696 | Generator Loss: 0.955559 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.751754 | Generator Loss: 0.950831 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.750022 | Generator Loss: 0.949128 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.749699 | Generator Loss: 0.947473 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.748690 | Generator Loss: 0.944349 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.747678 | Generator Loss: 0.944825 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.746980 | Generator Loss: 0.945419 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.746321 | Generator Loss: 0.939138 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.745454 | Generator Loss: 0.936427 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.745559 | Generator Loss: 0.941722 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.744622 | Generator Loss: 0.938907 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.744042 | Generator Loss: 0.942629 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 59 | Discriminator Loss: 0.743524 | Generator Loss: 0.936944 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 60 | Discriminator Loss: 0.742947 | Generator Loss: 0.936758 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 61 | Discriminator Loss: 0.742308 | Generator Loss: 0.938608 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 62 | Discriminator Loss: 0.742171 | Generator Loss: 0.932471 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 63 | Discriminator Loss: 0.741373 | Generator Loss: 0.930945 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 64 | Discriminator Loss: 0.741162 | Generator Loss: 0.930709 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 65 | Discriminator Loss: 0.740387 | Generator Loss: 0.926630 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 66 | Discriminator Loss: 0.740469 | Generator Loss: 0.926517 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 67 | Discriminator Loss: 0.739500 | Generator Loss: 0.925534 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 68 | Discriminator Loss: 0.739472 | Generator Loss: 0.925934 | \n",
      "312/312 [==============================] - 28s 88ms/step\n",
      "Epoch: 69 | Discriminator Loss: 0.738627 | Generator Loss: 0.922582 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 70 | Discriminator Loss: 0.738448 | Generator Loss: 0.920760 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 71 | Discriminator Loss: 0.737674 | Generator Loss: 0.915143 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 72 | Discriminator Loss: 0.737078 | Generator Loss: 0.911959 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 73 | Discriminator Loss: 0.737018 | Generator Loss: 0.917738 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 74 | Discriminator Loss: 0.737043 | Generator Loss: 0.919020 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 75 | Discriminator Loss: 0.736404 | Generator Loss: 0.917544 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 76 | Discriminator Loss: 0.735580 | Generator Loss: 0.919292 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 77 | Discriminator Loss: 0.735456 | Generator Loss: 0.916141 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 78 | Discriminator Loss: 0.734959 | Generator Loss: 0.906561 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 79 | Discriminator Loss: 0.734773 | Generator Loss: 0.908654 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 80 | Discriminator Loss: 0.735021 | Generator Loss: 0.910614 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 81 | Discriminator Loss: 0.734565 | Generator Loss: 0.910004 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 82 | Discriminator Loss: 0.733930 | Generator Loss: 0.912084 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 83 | Discriminator Loss: 0.733971 | Generator Loss: 0.908108 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 84 | Discriminator Loss: 0.733578 | Generator Loss: 0.908644 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 85 | Discriminator Loss: 0.733409 | Generator Loss: 0.910176 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 86 | Discriminator Loss: 0.733363 | Generator Loss: 0.908070 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 87 | Discriminator Loss: 0.732961 | Generator Loss: 0.908696 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 88 | Discriminator Loss: 0.733001 | Generator Loss: 0.904078 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 89 | Discriminator Loss: 0.732658 | Generator Loss: 0.904803 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 90 | Discriminator Loss: 0.732382 | Generator Loss: 0.906373 | \n"
     ]
    }
   ],
   "source": [
    "optd = Adam(lr=0.0002)\n",
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "discriminator1 = build_sdiscriminator()\n",
    "s1=define_model(\"s1\")\n",
    "gan1 = build_gan(s1,discriminator1)\n",
    "s1 = training(s1,discriminator1,gan1,s1Train,epo=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2779798,
     "status": "ok",
     "timestamp": 1615387563173,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "P_D1-gy3RO7Y",
    "outputId": "cbcfc982-c924-4195-96ff-6ddd5dae57a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 29s 88ms/step\n",
      "Epoch: 1 | Discriminator Loss: 1.485832 | Generator Loss: 2.047434 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 2 | Discriminator Loss: 1.325212 | Generator Loss: 1.949951 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 3 | Discriminator Loss: 1.259877 | Generator Loss: 1.860443 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 4 | Discriminator Loss: 1.173141 | Generator Loss: 1.736685 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 5 | Discriminator Loss: 1.100926 | Generator Loss: 1.594568 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 6 | Discriminator Loss: 1.045795 | Generator Loss: 1.510896 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 7 | Discriminator Loss: 1.008466 | Generator Loss: 1.451452 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.977248 | Generator Loss: 1.380469 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.952114 | Generator Loss: 1.346422 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.930824 | Generator Loss: 1.297570 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.913887 | Generator Loss: 1.258647 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.899712 | Generator Loss: 1.239860 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.886877 | Generator Loss: 1.208590 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.875488 | Generator Loss: 1.197423 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.866582 | Generator Loss: 1.172254 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.858523 | Generator Loss: 1.152247 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.850578 | Generator Loss: 1.128543 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.842347 | Generator Loss: 1.122025 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.833818 | Generator Loss: 1.101019 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.828978 | Generator Loss: 1.094598 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.822852 | Generator Loss: 1.081505 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.817134 | Generator Loss: 1.071672 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.810741 | Generator Loss: 1.065593 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.806446 | Generator Loss: 1.055079 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.801401 | Generator Loss: 1.043473 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.797636 | Generator Loss: 1.038806 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.793415 | Generator Loss: 1.029771 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.790788 | Generator Loss: 1.023287 | \n",
      "312/312 [==============================] - 30s 97ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.786648 | Generator Loss: 1.014013 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.783698 | Generator Loss: 1.011155 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.780828 | Generator Loss: 0.996191 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.777444 | Generator Loss: 1.001031 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.775281 | Generator Loss: 0.987358 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.772757 | Generator Loss: 0.984078 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.770361 | Generator Loss: 0.982212 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.768666 | Generator Loss: 0.972816 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.767161 | Generator Loss: 0.970600 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.765213 | Generator Loss: 0.961930 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.763173 | Generator Loss: 0.957920 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.761861 | Generator Loss: 0.953034 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.760285 | Generator Loss: 0.947440 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.758486 | Generator Loss: 0.941960 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.756769 | Generator Loss: 0.937390 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.755422 | Generator Loss: 0.943442 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.754985 | Generator Loss: 0.944079 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.754004 | Generator Loss: 0.934927 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.753312 | Generator Loss: 0.939314 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.752386 | Generator Loss: 0.934784 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.750341 | Generator Loss: 0.932995 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.749802 | Generator Loss: 0.931815 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.748516 | Generator Loss: 0.923867 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.747599 | Generator Loss: 0.925523 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.746539 | Generator Loss: 0.922006 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.746372 | Generator Loss: 0.923813 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.745878 | Generator Loss: 0.916049 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.745200 | Generator Loss: 0.917179 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.744644 | Generator Loss: 0.917337 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.744046 | Generator Loss: 0.912790 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 59 | Discriminator Loss: 0.744025 | Generator Loss: 0.913828 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 60 | Discriminator Loss: 0.742924 | Generator Loss: 0.909249 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 61 | Discriminator Loss: 0.742385 | Generator Loss: 0.910953 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 62 | Discriminator Loss: 0.741493 | Generator Loss: 0.910579 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 63 | Discriminator Loss: 0.740729 | Generator Loss: 0.906965 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 64 | Discriminator Loss: 0.740432 | Generator Loss: 0.906374 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 65 | Discriminator Loss: 0.740080 | Generator Loss: 0.908865 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 66 | Discriminator Loss: 0.739715 | Generator Loss: 0.901903 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 67 | Discriminator Loss: 0.739014 | Generator Loss: 0.899230 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 68 | Discriminator Loss: 0.738775 | Generator Loss: 0.900242 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 69 | Discriminator Loss: 0.738234 | Generator Loss: 0.900112 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 70 | Discriminator Loss: 0.737914 | Generator Loss: 0.901246 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 71 | Discriminator Loss: 0.737534 | Generator Loss: 0.899939 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 72 | Discriminator Loss: 0.737163 | Generator Loss: 0.897434 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 73 | Discriminator Loss: 0.736960 | Generator Loss: 0.897643 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 74 | Discriminator Loss: 0.736791 | Generator Loss: 0.895391 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 75 | Discriminator Loss: 0.736106 | Generator Loss: 0.895233 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 76 | Discriminator Loss: 0.735607 | Generator Loss: 0.894319 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 77 | Discriminator Loss: 0.735348 | Generator Loss: 0.891890 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 78 | Discriminator Loss: 0.734927 | Generator Loss: 0.894190 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 79 | Discriminator Loss: 0.734447 | Generator Loss: 0.892672 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 80 | Discriminator Loss: 0.734287 | Generator Loss: 0.888720 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 81 | Discriminator Loss: 0.734226 | Generator Loss: 0.890718 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 82 | Discriminator Loss: 0.733877 | Generator Loss: 0.887609 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 83 | Discriminator Loss: 0.733268 | Generator Loss: 0.887338 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 84 | Discriminator Loss: 0.733267 | Generator Loss: 0.884663 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 85 | Discriminator Loss: 0.732731 | Generator Loss: 0.884812 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 86 | Discriminator Loss: 0.732103 | Generator Loss: 0.886489 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 87 | Discriminator Loss: 0.732054 | Generator Loss: 0.882228 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 88 | Discriminator Loss: 0.731981 | Generator Loss: 0.883255 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 89 | Discriminator Loss: 0.731421 | Generator Loss: 0.882078 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 90 | Discriminator Loss: 0.731532 | Generator Loss: 0.889079 | \n"
     ]
    }
   ],
   "source": [
    "discriminator2 = build_sdiscriminator()\n",
    "s2=define_model(\"s2\")\n",
    "gan2 = build_gan(s2,discriminator2)\n",
    "s2 = training(s2,discriminator2,gan2,s2Train,epo=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2882119,
     "status": "ok",
     "timestamp": 1615391050037,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "HdnMTN1FojhT",
    "outputId": "5fd4fae0-cee9-4a9c-e784-39b93e13b2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 30s 91ms/step\n",
      "Epoch: 1 | Discriminator Loss: 1.435402 | Generator Loss: 1.954411 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 2 | Discriminator Loss: 1.219973 | Generator Loss: 1.813947 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 3 | Discriminator Loss: 1.122541 | Generator Loss: 1.654982 | \n",
      "312/312 [==============================] - 28s 88ms/step\n",
      "Epoch: 4 | Discriminator Loss: 1.059449 | Generator Loss: 1.534969 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 5 | Discriminator Loss: 1.016224 | Generator Loss: 1.447071 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.980814 | Generator Loss: 1.379157 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.955618 | Generator Loss: 1.344197 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.932322 | Generator Loss: 1.294256 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.911696 | Generator Loss: 1.249561 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.895605 | Generator Loss: 1.222826 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.882913 | Generator Loss: 1.192932 | \n",
      "312/312 [==============================] - 27s 87ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.870171 | Generator Loss: 1.171859 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.859277 | Generator Loss: 1.158741 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.850864 | Generator Loss: 1.141645 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.841125 | Generator Loss: 1.132865 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.834566 | Generator Loss: 1.113051 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.827224 | Generator Loss: 1.097018 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.819879 | Generator Loss: 1.086730 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.814016 | Generator Loss: 1.076744 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.808668 | Generator Loss: 1.071550 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.802907 | Generator Loss: 1.061764 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.798897 | Generator Loss: 1.052983 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.795265 | Generator Loss: 1.052745 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.791113 | Generator Loss: 1.046903 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.786937 | Generator Loss: 1.037680 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.783201 | Generator Loss: 1.030663 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.780598 | Generator Loss: 1.018162 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.777884 | Generator Loss: 1.011112 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.774511 | Generator Loss: 1.013252 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.773144 | Generator Loss: 1.010121 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.770410 | Generator Loss: 1.000576 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.768591 | Generator Loss: 0.986046 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.766096 | Generator Loss: 0.974988 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.764265 | Generator Loss: 0.974036 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.761944 | Generator Loss: 0.968769 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.760940 | Generator Loss: 0.961821 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.758863 | Generator Loss: 0.962945 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.757275 | Generator Loss: 0.954717 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.755330 | Generator Loss: 0.951347 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.753868 | Generator Loss: 0.949285 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.752886 | Generator Loss: 0.942381 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.750515 | Generator Loss: 0.935687 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.749540 | Generator Loss: 0.934774 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.749151 | Generator Loss: 0.929966 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.747463 | Generator Loss: 0.931905 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.746697 | Generator Loss: 0.932789 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.746490 | Generator Loss: 0.933096 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.745347 | Generator Loss: 0.932949 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.744174 | Generator Loss: 0.935800 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.744026 | Generator Loss: 0.930932 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.743726 | Generator Loss: 0.927997 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.742307 | Generator Loss: 0.925348 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.741278 | Generator Loss: 0.917820 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.740647 | Generator Loss: 0.924021 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.739727 | Generator Loss: 0.916060 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.739113 | Generator Loss: 0.912057 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.738371 | Generator Loss: 0.910723 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.737281 | Generator Loss: 0.905239 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 59 | Discriminator Loss: 0.737212 | Generator Loss: 0.901448 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 60 | Discriminator Loss: 0.736874 | Generator Loss: 0.903361 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 61 | Discriminator Loss: 0.736248 | Generator Loss: 0.897324 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 62 | Discriminator Loss: 0.735792 | Generator Loss: 0.903259 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 63 | Discriminator Loss: 0.736059 | Generator Loss: 0.893092 | \n",
      "312/312 [==============================] - 28s 88ms/step\n",
      "Epoch: 64 | Discriminator Loss: 0.735181 | Generator Loss: 0.898153 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 65 | Discriminator Loss: 0.734733 | Generator Loss: 0.894536 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 66 | Discriminator Loss: 0.734233 | Generator Loss: 0.889883 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 67 | Discriminator Loss: 0.733937 | Generator Loss: 0.889411 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 68 | Discriminator Loss: 0.733766 | Generator Loss: 0.886357 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 69 | Discriminator Loss: 0.733087 | Generator Loss: 0.884298 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 70 | Discriminator Loss: 0.733076 | Generator Loss: 0.879803 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 71 | Discriminator Loss: 0.732507 | Generator Loss: 0.881069 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 72 | Discriminator Loss: 0.732001 | Generator Loss: 0.877252 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 73 | Discriminator Loss: 0.731620 | Generator Loss: 0.875031 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 74 | Discriminator Loss: 0.731075 | Generator Loss: 0.872453 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 75 | Discriminator Loss: 0.731042 | Generator Loss: 0.871906 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 76 | Discriminator Loss: 0.730712 | Generator Loss: 0.867458 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 77 | Discriminator Loss: 0.730591 | Generator Loss: 0.871414 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 78 | Discriminator Loss: 0.730121 | Generator Loss: 0.875915 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 79 | Discriminator Loss: 0.730192 | Generator Loss: 0.870868 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 80 | Discriminator Loss: 0.729915 | Generator Loss: 0.865455 | \n",
      "312/312 [==============================] - 27s 88ms/step\n",
      "Epoch: 81 | Discriminator Loss: 0.729826 | Generator Loss: 0.870029 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 82 | Discriminator Loss: 0.729242 | Generator Loss: 0.868375 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 83 | Discriminator Loss: 0.729127 | Generator Loss: 0.868998 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 84 | Discriminator Loss: 0.728910 | Generator Loss: 0.865226 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 85 | Discriminator Loss: 0.728695 | Generator Loss: 0.867534 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 86 | Discriminator Loss: 0.728500 | Generator Loss: 0.865711 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 87 | Discriminator Loss: 0.728226 | Generator Loss: 0.865973 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 88 | Discriminator Loss: 0.727987 | Generator Loss: 0.866430 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 89 | Discriminator Loss: 0.727891 | Generator Loss: 0.864706 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 90 | Discriminator Loss: 0.727715 | Generator Loss: 0.867602 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 91 | Discriminator Loss: 0.727465 | Generator Loss: 0.865537 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 92 | Discriminator Loss: 0.727272 | Generator Loss: 0.868185 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 93 | Discriminator Loss: 0.727533 | Generator Loss: 0.871821 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 94 | Discriminator Loss: 0.727043 | Generator Loss: 0.869090 | \n"
     ]
    }
   ],
   "source": [
    "discriminator3 = build_sdiscriminator()\n",
    "s3=define_model(\"s3\")\n",
    "gan3 = build_gan(s3,discriminator3)\n",
    "s3 = training(s3,discriminator3,gan3,s3Train,epo=94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2942745,
     "status": "ok",
     "timestamp": 1615395267318,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "KVisfbtxo5_V",
    "outputId": "e5a1cf4f-56be-4773-f473-19f22af6bf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 29s 89ms/step\n",
      "Epoch: 1 | Discriminator Loss: 1.397794 | Generator Loss: 1.952409 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 2 | Discriminator Loss: 1.224723 | Generator Loss: 1.770108 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 3 | Discriminator Loss: 1.108148 | Generator Loss: 1.582597 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 4 | Discriminator Loss: 1.038260 | Generator Loss: 1.467807 | \n",
      "312/312 [==============================] - 28s 88ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.995034 | Generator Loss: 1.379297 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.965544 | Generator Loss: 1.328288 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.940301 | Generator Loss: 1.287927 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.918699 | Generator Loss: 1.251841 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.899056 | Generator Loss: 1.225969 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.883664 | Generator Loss: 1.206722 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.870276 | Generator Loss: 1.188051 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.859974 | Generator Loss: 1.174029 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.849927 | Generator Loss: 1.156012 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.841534 | Generator Loss: 1.142111 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.832475 | Generator Loss: 1.113865 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.825116 | Generator Loss: 1.095340 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.818981 | Generator Loss: 1.081471 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.813792 | Generator Loss: 1.075482 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.807119 | Generator Loss: 1.058058 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.802223 | Generator Loss: 1.048920 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.798692 | Generator Loss: 1.036931 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.794718 | Generator Loss: 1.035546 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.790416 | Generator Loss: 1.030580 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.787332 | Generator Loss: 1.025120 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.784314 | Generator Loss: 1.021129 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.780823 | Generator Loss: 1.010504 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.778593 | Generator Loss: 1.007545 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.775204 | Generator Loss: 0.999636 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.772438 | Generator Loss: 0.993335 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.770132 | Generator Loss: 0.988657 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.767887 | Generator Loss: 0.980991 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.765534 | Generator Loss: 0.975060 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.763526 | Generator Loss: 0.972689 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.761337 | Generator Loss: 0.961900 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.759279 | Generator Loss: 0.959978 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.757852 | Generator Loss: 0.958185 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.755909 | Generator Loss: 0.953698 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.755084 | Generator Loss: 0.945443 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.753188 | Generator Loss: 0.943442 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.751243 | Generator Loss: 0.938901 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.750437 | Generator Loss: 0.939052 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.749593 | Generator Loss: 0.933849 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.748256 | Generator Loss: 0.929292 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.747407 | Generator Loss: 0.926808 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.746083 | Generator Loss: 0.923772 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.744578 | Generator Loss: 0.923445 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.743968 | Generator Loss: 0.923808 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.742958 | Generator Loss: 0.919125 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.741745 | Generator Loss: 0.914643 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.741931 | Generator Loss: 0.917606 | \n",
      "312/312 [==============================] - 29s 94ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.741037 | Generator Loss: 0.913447 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.740239 | Generator Loss: 0.906029 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.739609 | Generator Loss: 0.907102 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.738864 | Generator Loss: 0.903415 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.738291 | Generator Loss: 0.901994 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.737875 | Generator Loss: 0.894460 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.737472 | Generator Loss: 0.896171 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.736460 | Generator Loss: 0.892736 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 59 | Discriminator Loss: 0.736459 | Generator Loss: 0.894641 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 60 | Discriminator Loss: 0.735991 | Generator Loss: 0.895380 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 61 | Discriminator Loss: 0.735225 | Generator Loss: 0.889140 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 62 | Discriminator Loss: 0.735333 | Generator Loss: 0.889838 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 63 | Discriminator Loss: 0.734590 | Generator Loss: 0.885456 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 64 | Discriminator Loss: 0.734041 | Generator Loss: 0.883880 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 65 | Discriminator Loss: 0.733813 | Generator Loss: 0.881637 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 66 | Discriminator Loss: 0.733488 | Generator Loss: 0.879665 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 67 | Discriminator Loss: 0.732851 | Generator Loss: 0.878912 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 68 | Discriminator Loss: 0.732689 | Generator Loss: 0.877637 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 69 | Discriminator Loss: 0.732239 | Generator Loss: 0.878063 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 70 | Discriminator Loss: 0.731771 | Generator Loss: 0.878029 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 71 | Discriminator Loss: 0.731372 | Generator Loss: 0.873773 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 72 | Discriminator Loss: 0.731094 | Generator Loss: 0.873577 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 73 | Discriminator Loss: 0.731076 | Generator Loss: 0.870717 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 74 | Discriminator Loss: 0.730483 | Generator Loss: 0.871588 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 75 | Discriminator Loss: 0.730296 | Generator Loss: 0.868676 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 76 | Discriminator Loss: 0.730403 | Generator Loss: 0.867021 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 77 | Discriminator Loss: 0.729782 | Generator Loss: 0.863328 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 78 | Discriminator Loss: 0.729467 | Generator Loss: 0.861967 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 79 | Discriminator Loss: 0.729249 | Generator Loss: 0.866042 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 80 | Discriminator Loss: 0.729006 | Generator Loss: 0.860802 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 81 | Discriminator Loss: 0.728587 | Generator Loss: 0.860787 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 82 | Discriminator Loss: 0.728631 | Generator Loss: 0.862829 | \n",
      "312/312 [==============================] - 30s 95ms/step\n",
      "Epoch: 83 | Discriminator Loss: 0.728470 | Generator Loss: 0.866617 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 84 | Discriminator Loss: 0.728146 | Generator Loss: 0.865203 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 85 | Discriminator Loss: 0.727706 | Generator Loss: 0.861875 | \n",
      "312/312 [==============================] - 28s 91ms/step\n",
      "Epoch: 86 | Discriminator Loss: 0.728025 | Generator Loss: 0.862045 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 87 | Discriminator Loss: 0.727597 | Generator Loss: 0.861075 | \n",
      "312/312 [==============================] - 29s 93ms/step\n",
      "Epoch: 88 | Discriminator Loss: 0.727300 | Generator Loss: 0.860717 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 89 | Discriminator Loss: 0.727262 | Generator Loss: 0.858428 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 90 | Discriminator Loss: 0.726743 | Generator Loss: 0.862499 | \n",
      "312/312 [==============================] - 29s 92ms/step\n",
      "Epoch: 91 | Discriminator Loss: 0.726837 | Generator Loss: 0.858629 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 92 | Discriminator Loss: 0.726768 | Generator Loss: 0.856454 | \n",
      "312/312 [==============================] - 28s 89ms/step\n",
      "Epoch: 93 | Discriminator Loss: 0.726396 | Generator Loss: 0.858092 | \n",
      "312/312 [==============================] - 28s 90ms/step\n",
      "Epoch: 94 | Discriminator Loss: 0.726506 | Generator Loss: 0.858191 | \n",
      "312/312 [==============================] - 29s 91ms/step\n",
      "Epoch: 95 | Discriminator Loss: 0.726412 | Generator Loss: 0.858250 | \n"
     ]
    }
   ],
   "source": [
    "discriminator4 = build_sdiscriminator()\n",
    "s4=define_model(\"s4\")\n",
    "gan4 = build_gan(s4,discriminator4)\n",
    "s4 = training(s4,discriminator4,gan4,s4Train,epo=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQlldHWBPJMn"
   },
   "source": [
    "**4 Students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "R8dmofSbg5ko"
   },
   "outputs": [],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "o2=s2.get_layer(\"reqs2\").output\n",
    "o3=s3.get_layer(\"reqs3\").output\n",
    "o4=s4.get_layer(\"reqs4\").output\n",
    "\n",
    "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4])\n",
    "\n",
    "output=Activation('relu')(output)\n",
    "output=Dropout(0.5)(output) # For reguralization\n",
    "output=Dense(10,activation=\"softmax\", name=\"d1\")(output)\n",
    "\n",
    "compressed=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input,\n",
    "           s3.get_layer(\"s3\").input,s4.get_layer(\"s4\").input], output)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()\n",
    "compressed.get_layer('d1').set_weights(my_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s1_input (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s2_input (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s3_input (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s4_input (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s1 (Conv2D)                     (None, 32, 32, 32)   896         s1_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s2 (Conv2D)                     (None, 32, 32, 32)   896         s2_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s3 (Conv2D)                     (None, 32, 32, 32)   896         s3_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s4 (Conv2D)                     (None, 32, 32, 32)   896         s4_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 32)   9248        s1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 32)   9248        s2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 32)   9248        s3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 32)   9248        s4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 16, 16, 32)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18496       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18496       dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 64)   18496       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 64)   18496       dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 8, 8, 64)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 128)    73856       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 8, 128)    73856       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 128)    73856       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 128)    73856       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 128)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 4, 4, 128)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 4, 4, 128)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 4, 4, 128)    0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 4, 4, 128)    0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 4, 4, 128)    0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 4, 4, 128)    0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 4, 4, 128)    0           max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2048)         0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2048)         0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2048)         0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           32784       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 16)           32784       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 16)           32784       flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 16)           32784       flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16)           0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16)           0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reqs1 (Dense)                   (None, 64)           1088        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs2 (Dense)                   (None, 64)           1088        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs3 (Dense)                   (None, 64)           1088        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs4 (Dense)                   (None, 64)           1088        dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           reqs1[0][0]                      \n",
      "                                                                 reqs2[0][0]                      \n",
      "                                                                 reqs3[0][0]                      \n",
      "                                                                 reqs4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 256)          0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "d1 (Dense)                      (None, 10)           2570        dropout_32[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,286,090\n",
      "Trainable params: 2,570\n",
      "Non-trainable params: 1,283,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "compressed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NaSX8xHNg5kx"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for l in compressed.layers[:len(compressed.layers)-2]:\n",
    "    l.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fLz1Oz6dg5ky"
   },
   "outputs": [],
   "source": [
    "compressed.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.0002),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78629,
     "status": "ok",
     "timestamp": 1615395910680,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "bylsRHBzg5kz",
    "outputId": "0ae88fdc-4d84-4a5a-ea57-7bf0cfcc0959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 5s 27ms/step - loss: 10.7644 - accuracy: 0.1802 - val_loss: 4.4440 - val_accuracy: 0.3795\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 5.8315 - accuracy: 0.3345 - val_loss: 1.6645 - val_accuracy: 0.5930\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 3.2294 - accuracy: 0.5082 - val_loss: 0.8100 - val_accuracy: 0.8181\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 1.8891 - accuracy: 0.6462 - val_loss: 0.7260 - val_accuracy: 0.8557\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 1.2628 - accuracy: 0.7381 - val_loss: 0.7245 - val_accuracy: 0.8642\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.9372 - accuracy: 0.7967 - val_loss: 0.7356 - val_accuracy: 0.8675\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.7660 - accuracy: 0.8335 - val_loss: 0.7460 - val_accuracy: 0.8693\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.6521 - accuracy: 0.8592 - val_loss: 0.7537 - val_accuracy: 0.8709\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5555 - accuracy: 0.8808 - val_loss: 0.7611 - val_accuracy: 0.8717\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.5138 - accuracy: 0.8903 - val_loss: 0.7670 - val_accuracy: 0.8721\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.4762 - accuracy: 0.9008 - val_loss: 0.7693 - val_accuracy: 0.8720\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.4361 - accuracy: 0.9103 - val_loss: 0.7680 - val_accuracy: 0.8731\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.4291 - accuracy: 0.9139 - val_loss: 0.7697 - val_accuracy: 0.8738\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.3898 - accuracy: 0.9214 - val_loss: 0.7676 - val_accuracy: 0.8740\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3667 - accuracy: 0.9250 - val_loss: 0.7647 - val_accuracy: 0.8744\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.3438 - accuracy: 0.9314 - val_loss: 0.7611 - val_accuracy: 0.8740\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3582 - accuracy: 0.9300 - val_loss: 0.7563 - val_accuracy: 0.8744\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3424 - accuracy: 0.9344 - val_loss: 0.7531 - val_accuracy: 0.8743\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.3341 - accuracy: 0.9364 - val_loss: 0.7451 - val_accuracy: 0.8745\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.3008 - accuracy: 0.9429 - val_loss: 0.7357 - val_accuracy: 0.8747\n"
     ]
    }
   ],
   "source": [
    "# Without finetune\n",
    "batch_size = 256\n",
    "mm4_history=compressed.fit([X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=([X_val,X_val,X_val,X_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "157/157 [==============================] - 3s 21ms/step - loss: 0.1813 - accuracy: 0.9588 - val_loss: 0.4652 - val_accuracy: 0.8760\n",
      "Epoch 2/20\n",
      "157/157 [==============================] - 3s 20ms/step - loss: 0.1786 - accuracy: 0.9586 - val_loss: 0.4621 - val_accuracy: 0.8761\n",
      "Epoch 3/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.1729 - accuracy: 0.9598 - val_loss: 0.4613 - val_accuracy: 0.8768\n",
      "Epoch 4/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1746 - accuracy: 0.9595 - val_loss: 0.4605 - val_accuracy: 0.8765\n",
      "Epoch 5/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1716 - accuracy: 0.9613 - val_loss: 0.4591 - val_accuracy: 0.8764\n",
      "Epoch 6/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1732 - accuracy: 0.9599 - val_loss: 0.4565 - val_accuracy: 0.8766\n",
      "Epoch 7/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.1751 - accuracy: 0.9592 - val_loss: 0.4542 - val_accuracy: 0.8767\n",
      "Epoch 8/20\n",
      "157/157 [==============================] - 3s 19ms/step - loss: 0.1717 - accuracy: 0.9598 - val_loss: 0.4540 - val_accuracy: 0.8777\n",
      "Epoch 9/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1698 - accuracy: 0.9600 - val_loss: 0.4556 - val_accuracy: 0.8762\n",
      "Epoch 10/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1732 - accuracy: 0.9597 - val_loss: 0.4535 - val_accuracy: 0.8758\n",
      "Epoch 11/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1715 - accuracy: 0.9604 - val_loss: 0.4509 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1720 - accuracy: 0.9600 - val_loss: 0.4484 - val_accuracy: 0.8766\n",
      "Epoch 13/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1699 - accuracy: 0.9613 - val_loss: 0.4473 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1673 - accuracy: 0.9605 - val_loss: 0.4471 - val_accuracy: 0.8771\n",
      "Epoch 15/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1698 - accuracy: 0.9600 - val_loss: 0.4443 - val_accuracy: 0.8770\n",
      "Epoch 16/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1653 - accuracy: 0.9617 - val_loss: 0.4449 - val_accuracy: 0.8767\n",
      "Epoch 17/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1658 - accuracy: 0.9605 - val_loss: 0.4428 - val_accuracy: 0.8779\n",
      "Epoch 18/20\n",
      "157/157 [==============================] - 3s 18ms/step - loss: 0.1660 - accuracy: 0.9603 - val_loss: 0.4435 - val_accuracy: 0.8770\n",
      "Epoch 19/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1654 - accuracy: 0.9607 - val_loss: 0.4401 - val_accuracy: 0.8772\n",
      "Epoch 20/20\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.1683 - accuracy: 0.9606 - val_loss: 0.4401 - val_accuracy: 0.8776\n"
     ]
    }
   ],
   "source": [
    "# Without finetune\n",
    "batch_size = 256\n",
    "mm4_history=compressed.fit([X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=([X_val,X_val,X_val,X_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5741,
     "status": "ok",
     "timestamp": 1615395995931,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "IqFAAug_hqBz",
    "outputId": "e6066879-1986-4910-b44c-ff2443a3e4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7953 - accuracy: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7953414916992188, 0.8704000115394592)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,a = compressed.evaluate([X_test,X_test,X_test,X_test], y_test)\n",
    "l, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4668 - accuracy: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4667777419090271, 0.8726999759674072)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,a = compressed.evaluate([X_test,X_test,X_test,X_test], y_test)\n",
    "l, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 1836,
     "status": "ok",
     "timestamp": 1615395817537,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "Jt5_Vmlwh3r5",
    "outputId": "5945600a-7ee0-4cf0-9659-d1a020e89a23"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mm4_history.history['accuracy'])\n",
    "plt.plot(mm4_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(mm4_history.history['loss'])\n",
    "plt.plot(mm4_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPpx-XYoh7hY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPfp1bS0DJ+x7S0l4VfnBIV",
   "collapsed_sections": [],
   "name": "4 Students Gan_cifar10.ipynb",
   "provenance": [
    {
     "file_id": "1Cm9yNETjuUpv4daBA58tZg9SD4XBSgmd",
     "timestamp": 1615379925623
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
