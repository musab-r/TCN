{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPdE7Fs3VdXY"
   },
   "source": [
    "# Distilling Knowledge in Multiple Students  using Generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xlC_N0QVomM"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ce2GSoOKWFKP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyzL58V7WNdL"
   },
   "source": [
    "### Teacher's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20712,
     "status": "ok",
     "timestamp": 1613652674507,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "lyIJv1WRNo7G",
    "outputId": "aef3e3c5-b57d-44a1-e2c6-db851ca0e3b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,446,730\n",
      "Trainable params: 2,446,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "nb_classes = 10\n",
    "\n",
    "(X_Train, y_Train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "\n",
    "X_train = X_train.reshape(48000, 28, 28, 1)\n",
    "X_val = X_val.reshape(12000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "\n",
    "\n",
    "#Creating a teacher network\n",
    "input_shape = (28, 28, 1) # Input shape of each image\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "teacher.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "teacher.add(Dropout(0.25)) # For reguralization\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(256, activation='relu'))\n",
    "teacher.add(Dense(256, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "teacher.add(Dropout(0.5)) # For reguralization\n",
    "\n",
    "teacher.add(Dense(nb_classes, name = 'dense_2'))\n",
    "teacher.add(Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
    "\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(teacher.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the teacher model as usual\n",
    "epochs = 0\n",
    "batch_size = 256\n",
    "teacher.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8jy5iVRWGuE"
   },
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v6mBfSS7No7Q"
   },
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Teacher_MNIST_98.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HhwY-3bONo7M"
   },
   "outputs": [],
   "source": [
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7l50L-8hRG6y"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "# Normalize the values\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1613652677603,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "EoLx2I_dNo7N",
    "outputId": "a1183477-5b27-4136-953f-a0d65e4c1b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 3ms/step - loss: 0.0484 - accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03833923488855362, 0.9894999861717224]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka0RmVsXWW_h"
   },
   "source": [
    "### Dense Vector split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eIlRbRObW-kc"
   },
   "outputs": [],
   "source": [
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)\n",
    "val_dense = teacher_WO_Softmax.predict(X_val)\n",
    "\n",
    "# 4 Students case\n",
    "# ---------------------------------------------\n",
    "s1Train=train_dense[:,:64]\n",
    "s2Train=train_dense[:,64:128]\n",
    "s3Train=train_dense[:,128:192]\n",
    "s4Train=train_dense[:,192:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BLAAcCSb70h"
   },
   "source": [
    "## GANs' Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5Bf51HQeYB19"
   },
   "outputs": [],
   "source": [
    "# import np.random import random\n",
    "BATCH_SIZE=32\n",
    "def smooth_real_labels(y):\n",
    "    return y - 0.3+(np.random.random(y.shape)*0.5)\n",
    "def smooth_fake_labels(y):\n",
    "    return y + (0.3 * np.random.random(y.shape))\n",
    "def build_gan(gen,disc): \n",
    "    disc.trainable = False\n",
    "    input= Input(shape=input_shape)\n",
    "    output = gen(input)\n",
    "    output2= disc(output)\n",
    "    gan=Model(input,output2)\n",
    "\n",
    "    gan.compile(Adam(lr=0.0002),loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Fu6K6TmFQBM"
   },
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7DN9rlsCXBHl"
   },
   "outputs": [],
   "source": [
    "def build_sdiscriminator():\n",
    "    \n",
    "    input2 = Input(shape=(64,),name='input')\n",
    "    inp=Dense(64)(input2)\n",
    "\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(inp)\n",
    "    \n",
    "    conv3 = Dense(128)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(256)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(512)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(1024)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "\n",
    "    dense = Dense(1,activation='sigmoid',name='dense')(leaky_relu)\n",
    "\n",
    "    output2=Dense(64)(leaky_relu)\n",
    "\n",
    "    \n",
    "    disc = Model(input2,[dense,output2])          \n",
    "    disc.compile(optd,loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s12vr0BvNo7X"
   },
   "outputs": [],
   "source": [
    "optd = Adam(lr=0.0002)\n",
    "opt = Adam(lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1613660158283,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "TUcuHmtYNo7W",
    "outputId": "4f328e32-0955-49ab-c725-f6b088cda273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128)          0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          33024       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          131584      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1024)         525312      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024)         4096        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 1024)         0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           65600       leaky_re_lu_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 776,705\n",
      "Trainable params: 772,865\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d1= build_sdiscriminator()\n",
    "d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtXOpFGFEYrH"
   },
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ElnQTkvSXE7h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "req (Dense)                  (None, 64)                2112      \n",
      "=================================================================\n",
      "Total params: 17,456\n",
      "Trainable params: 17,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_sgenerator(name):\n",
    "\n",
    "    student1 = Sequential()\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1),kernel_initializer='normal', name=name))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Dropout(0.25)) # For reguralization\n",
    "    student1.add(Flatten())\n",
    "    student1.add(Dense(32, activation='relu'))\n",
    "    student1.add(Dropout(0.3))\n",
    "    student1.add(Dense(64,name='req'+name))\n",
    "\n",
    "    student1.compile(opt,loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    return student1\n",
    "\n",
    "build_sgenerator('').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "edsqBRYpNo7e"
   },
   "outputs": [],
   "source": [
    "def training(generator,discriminator,gan,features,epo=20):\n",
    "    # Setup Models here\n",
    "    BATCH_SIZE = 128\n",
    "    discriminator.trainable = True\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    all_class_loss=[]\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(epo):\n",
    "        \n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        epoch_class_loss= []\n",
    "        for i,index in enumerate(indices):\n",
    "        \n",
    "            # Split\n",
    "            inputs=X_train[index:index+BATCH_SIZE]\n",
    "            sXtrain = features[index:index+BATCH_SIZE]\n",
    "\n",
    "            y_real = np.ones((BATCH_SIZE,1))\n",
    "            y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "            #Generator Training\n",
    "            fake_images = generator.predict_on_batch(inputs)\n",
    "\n",
    "            #Disrciminator Training\n",
    "            disc_real_loss1,_,disc_real_loss2,_,_= discriminator.train_on_batch(sXtrain,[y_real,sXtrain])\n",
    "            disc_fake_loss1,_,disc_fake_loss2,_,_= discriminator.train_on_batch(fake_images,[y_fake,sXtrain])\n",
    "\n",
    "            #Gans Training\n",
    "            discriminator.trainable = False\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,sXtrain])\n",
    "\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            disc_loss = (disc_fake_loss1 + disc_real_loss1)/2\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            progress_bar.update(i+1)\n",
    "\n",
    "            epoch_gen_loss.append((gan_loss))\n",
    "\n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f | \" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W3HwYXRFYPf"
   },
   "source": [
    "You can initialize multiple instances here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "X9oy60_SNo7k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator1 = build_sdiscriminator()\n",
    "discriminator2 = build_sdiscriminator()\n",
    "discriminator3 = build_sdiscriminator()\n",
    "discriminator4 = build_sdiscriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MomgOJRaNo7l"
   },
   "outputs": [],
   "source": [
    "s1=build_sgenerator(\"s1\")\n",
    "s2=build_sgenerator('s2')\n",
    "s3=build_sgenerator(\"s3\")\n",
    "s4=build_sgenerator('s4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JivZOb38No7l"
   },
   "outputs": [],
   "source": [
    "gan1 = build_gan(s1,discriminator1)\n",
    "gan2 = build_gan(s2,discriminator2)\n",
    "gan3 = build_gan(s3,discriminator3)\n",
    "gan4 = build_gan(s4,discriminator4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3590314,
     "status": "ok",
     "timestamp": 1613663781923,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "e8wjg4vrNo7l",
    "outputId": "48289479-1e6d-4b60-8bc2-b09996f7c40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 14s 35ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.650496 | Generator Loss: 2.020718 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.241798 | Generator Loss: 1.187068 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.183888 | Generator Loss: 1.074136 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.159349 | Generator Loss: 1.023960 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.146112 | Generator Loss: 0.978296 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.136542 | Generator Loss: 0.915169 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.129256 | Generator Loss: 0.866664 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.123043 | Generator Loss: 0.841741 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.118176 | Generator Loss: 0.793359 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.113930 | Generator Loss: 0.765818 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.110675 | Generator Loss: 0.742490 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.107342 | Generator Loss: 0.718255 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.103784 | Generator Loss: 0.683319 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.100844 | Generator Loss: 0.655178 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.098080 | Generator Loss: 0.638274 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.095536 | Generator Loss: 0.623140 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.093624 | Generator Loss: 0.603462 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.091799 | Generator Loss: 0.585504 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.090194 | Generator Loss: 0.573435 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.088387 | Generator Loss: 0.557233 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.087536 | Generator Loss: 0.552569 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.086216 | Generator Loss: 0.541207 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.085157 | Generator Loss: 0.533262 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.084221 | Generator Loss: 0.528064 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.083222 | Generator Loss: 0.522939 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.082802 | Generator Loss: 0.519518 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.082549 | Generator Loss: 0.508889 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.081330 | Generator Loss: 0.502424 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.080419 | Generator Loss: 0.497383 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.079619 | Generator Loss: 0.487525 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.078793 | Generator Loss: 0.483126 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.077805 | Generator Loss: 0.473709 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.077268 | Generator Loss: 0.463133 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.076169 | Generator Loss: 0.458395 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.075604 | Generator Loss: 0.457836 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.075346 | Generator Loss: 0.455036 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.074584 | Generator Loss: 0.453288 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.073906 | Generator Loss: 0.448429 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.073422 | Generator Loss: 0.446212 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.072808 | Generator Loss: 0.445200 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.429299 | Generator Loss: 1.736331 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.201666 | Generator Loss: 1.152151 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.165460 | Generator Loss: 1.018003 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.146540 | Generator Loss: 0.941534 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.132998 | Generator Loss: 0.886203 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.123995 | Generator Loss: 0.833493 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.116298 | Generator Loss: 0.781321 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.110062 | Generator Loss: 0.742464 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.106949 | Generator Loss: 0.711390 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.103254 | Generator Loss: 0.688231 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.098921 | Generator Loss: 0.666405 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.096512 | Generator Loss: 0.650728 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.094028 | Generator Loss: 0.625729 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.091680 | Generator Loss: 0.607721 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.089227 | Generator Loss: 0.574095 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.087201 | Generator Loss: 0.558317 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.085244 | Generator Loss: 0.544757 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.083768 | Generator Loss: 0.533024 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.082271 | Generator Loss: 0.524231 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.081032 | Generator Loss: 0.519207 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.079392 | Generator Loss: 0.511615 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.078468 | Generator Loss: 0.500211 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.077615 | Generator Loss: 0.492264 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.076251 | Generator Loss: 0.484130 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.075167 | Generator Loss: 0.479200 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.074386 | Generator Loss: 0.474459 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.073657 | Generator Loss: 0.464438 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.072835 | Generator Loss: 0.463146 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.072160 | Generator Loss: 0.460358 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.071721 | Generator Loss: 0.455983 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.070976 | Generator Loss: 0.452352 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.070514 | Generator Loss: 0.452883 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.069978 | Generator Loss: 0.452424 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.069496 | Generator Loss: 0.447319 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.069191 | Generator Loss: 0.443307 | \n",
      "375/375 [==============================] - 14s 34ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.407177 | Generator Loss: 1.691994 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.194192 | Generator Loss: 1.095350 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.161239 | Generator Loss: 0.994638 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.145508 | Generator Loss: 0.941580 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.137142 | Generator Loss: 0.922026 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.130207 | Generator Loss: 0.889563 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.125844 | Generator Loss: 0.853654 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.120904 | Generator Loss: 0.798468 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.115112 | Generator Loss: 0.760984 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.111765 | Generator Loss: 0.717786 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.108106 | Generator Loss: 0.683486 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.104710 | Generator Loss: 0.652394 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.101860 | Generator Loss: 0.620231 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.099101 | Generator Loss: 0.598256 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.096830 | Generator Loss: 0.584332 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.094381 | Generator Loss: 0.563359 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.092896 | Generator Loss: 0.551928 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.090564 | Generator Loss: 0.537589 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.088810 | Generator Loss: 0.524649 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.087187 | Generator Loss: 0.516469 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.085770 | Generator Loss: 0.506586 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.084289 | Generator Loss: 0.501405 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.083350 | Generator Loss: 0.496788 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.082430 | Generator Loss: 0.490286 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.081729 | Generator Loss: 0.484505 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.080771 | Generator Loss: 0.472795 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.080562 | Generator Loss: 0.467115 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.079732 | Generator Loss: 0.461797 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.079454 | Generator Loss: 0.454103 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.079053 | Generator Loss: 0.447806 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.078621 | Generator Loss: 0.443466 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.078052 | Generator Loss: 0.438236 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.077786 | Generator Loss: 0.433989 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.077695 | Generator Loss: 0.431986 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.077330 | Generator Loss: 0.428992 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.076888 | Generator Loss: 0.427509 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.076661 | Generator Loss: 0.423328 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.076515 | Generator Loss: 0.423815 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.076247 | Generator Loss: 0.423621 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.075936 | Generator Loss: 0.420885 | \n",
      "375/375 [==============================] - 13s 32ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.467166 | Generator Loss: 1.868336 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.208671 | Generator Loss: 1.177018 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.164164 | Generator Loss: 1.000480 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.141722 | Generator Loss: 0.895118 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.128540 | Generator Loss: 0.829822 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.118981 | Generator Loss: 0.776738 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.112723 | Generator Loss: 0.743575 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.107318 | Generator Loss: 0.703758 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.103291 | Generator Loss: 0.667803 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.099884 | Generator Loss: 0.643306 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.096996 | Generator Loss: 0.624376 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.094109 | Generator Loss: 0.604089 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.091117 | Generator Loss: 0.589339 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.088849 | Generator Loss: 0.577198 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.087160 | Generator Loss: 0.562387 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.084517 | Generator Loss: 0.542401 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.083160 | Generator Loss: 0.524197 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.081602 | Generator Loss: 0.514448 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.080624 | Generator Loss: 0.505962 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.079684 | Generator Loss: 0.500217 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.078971 | Generator Loss: 0.496055 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.077780 | Generator Loss: 0.483998 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.077206 | Generator Loss: 0.475597 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.076390 | Generator Loss: 0.465818 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.075890 | Generator Loss: 0.460642 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.075342 | Generator Loss: 0.459785 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.074392 | Generator Loss: 0.451570 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.073746 | Generator Loss: 0.450762 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.073043 | Generator Loss: 0.444342 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.072062 | Generator Loss: 0.437520 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.071877 | Generator Loss: 0.435831 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.071426 | Generator Loss: 0.430836 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.071158 | Generator Loss: 0.423850 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.070725 | Generator Loss: 0.423673 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.070312 | Generator Loss: 0.419661 | \n"
     ]
    }
   ],
   "source": [
    "s1 = training(s1,discriminator1,gan1,s1Train,epo=40)\n",
    "s2 = training(s2,discriminator2,gan2,s2Train,epo=35)\n",
    "s3 = training(s3,discriminator3,gan3,s3Train,epo=40)\n",
    "s4 = training(s4,discriminator4,gan4,s4Train,epo=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgKdRFNFShtt"
   },
   "source": [
    "## **4 Students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1430,
     "status": "ok",
     "timestamp": 1613663783843,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "QvsGpSuiNo7v",
    "outputId": "7aaa8f15-d1fd-427c-98f9-6788e0b9b8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n"
     ]
    }
   ],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "o2=s2.get_layer(\"reqs2\").output\n",
    "o3=s3.get_layer(\"reqs3\").output\n",
    "o4=s4.get_layer(\"reqs4\").output\n",
    "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4])\n",
    "print (output.shape)\n",
    "output=Activation('relu')(output)\n",
    "output2=Dropout(0.5)(output) # For reguralization\n",
    "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
    "mm4=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input,s3.get_layer(\"s3\").input,s4.get_layer(\"s4\").input],output3)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()\n",
    "mm4.get_layer('d1').set_weights(my_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "E4_9eYYqbLxS"
   },
   "outputs": [],
   "source": [
    "for l in mm4.layers[:len(mm4.layers)-1]:\n",
    "    l.trainable=False\n",
    "\n",
    "mm4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "executionInfo": {
     "elapsed": 101153,
     "status": "error",
     "timestamp": 1613663883630,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "Y75ac5rlbLs2",
    "outputId": "7e724833-7a69-404c-e5cb-90ff358c2867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 1.9193 - accuracy: 0.7193 - val_loss: 0.1309 - val_accuracy: 0.9753\n",
      "Epoch 2/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2856 - accuracy: 0.9417 - val_loss: 0.1242 - val_accuracy: 0.9773\n",
      "Epoch 3/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.2145 - accuracy: 0.9553 - val_loss: 0.1088 - val_accuracy: 0.9779\n",
      "Epoch 4/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1729 - accuracy: 0.9611 - val_loss: 0.0980 - val_accuracy: 0.9780\n",
      "Epoch 5/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1475 - accuracy: 0.9636 - val_loss: 0.0864 - val_accuracy: 0.9789\n",
      "Epoch 6/70\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1362 - accuracy: 0.9652 - val_loss: 0.0816 - val_accuracy: 0.9790\n",
      "Epoch 7/70\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1121 - accuracy: 0.9695 - val_loss: 0.0781 - val_accuracy: 0.9803\n",
      "Epoch 8/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1211 - accuracy: 0.9670 - val_loss: 0.0735 - val_accuracy: 0.9793\n",
      "Epoch 9/70\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1122 - accuracy: 0.9682 - val_loss: 0.0709 - val_accuracy: 0.9792\n",
      "Epoch 10/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1170 - accuracy: 0.9673 - val_loss: 0.0710 - val_accuracy: 0.9798\n",
      "Epoch 11/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1106 - accuracy: 0.9692 - val_loss: 0.0720 - val_accuracy: 0.9787\n",
      "Epoch 12/70\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1061 - accuracy: 0.9682 - val_loss: 0.0704 - val_accuracy: 0.9797\n",
      "Epoch 13/70\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0991 - accuracy: 0.9710 - val_loss: 0.0704 - val_accuracy: 0.9791\n",
      "Epoch 14/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1046 - accuracy: 0.9700 - val_loss: 0.0704 - val_accuracy: 0.9794\n",
      "Epoch 15/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1075 - accuracy: 0.9693 - val_loss: 0.0697 - val_accuracy: 0.9792\n",
      "Epoch 16/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1036 - accuracy: 0.9705 - val_loss: 0.0693 - val_accuracy: 0.9795\n",
      "Epoch 17/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1084 - accuracy: 0.9690 - val_loss: 0.0726 - val_accuracy: 0.9790\n",
      "Epoch 18/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1001 - accuracy: 0.9701 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
      "Epoch 19/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1075 - accuracy: 0.9685 - val_loss: 0.0691 - val_accuracy: 0.9800\n",
      "Epoch 20/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1028 - accuracy: 0.9712 - val_loss: 0.0705 - val_accuracy: 0.9801\n",
      "Epoch 21/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0972 - accuracy: 0.9719 - val_loss: 0.0692 - val_accuracy: 0.9793\n",
      "Epoch 22/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1013 - accuracy: 0.9707 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
      "Epoch 23/70\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1083 - accuracy: 0.9681 - val_loss: 0.0694 - val_accuracy: 0.9793\n",
      "Epoch 24/70\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1066 - accuracy: 0.9689 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
      "Epoch 25/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1054 - accuracy: 0.9693 - val_loss: 0.0698 - val_accuracy: 0.9797\n",
      "Epoch 26/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1092 - accuracy: 0.9685 - val_loss: 0.0719 - val_accuracy: 0.9795\n",
      "Epoch 27/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1099 - accuracy: 0.9689 - val_loss: 0.0701 - val_accuracy: 0.9792\n",
      "Epoch 28/70\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1051 - accuracy: 0.9698 - val_loss: 0.0689 - val_accuracy: 0.9801\n",
      "Epoch 29/70\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1015 - accuracy: 0.9696 - val_loss: 0.0690 - val_accuracy: 0.9799\n",
      "Epoch 30/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1000 - accuracy: 0.9715 - val_loss: 0.0703 - val_accuracy: 0.9790\n",
      "Epoch 31/70\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.1011 - accuracy: 0.9691 - val_loss: 0.0700 - val_accuracy: 0.9798\n",
      "Epoch 32/70\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1058 - accuracy: 0.9705 - val_loss: 0.0698 - val_accuracy: 0.9796\n",
      "Epoch 33/70\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1096 - accuracy: 0.9701 - val_loss: 0.0684 - val_accuracy: 0.9803\n",
      "Epoch 34/70\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0997 - accuracy: 0.9706 - val_loss: 0.0708 - val_accuracy: 0.9790\n",
      "Epoch 35/70\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1033 - accuracy: 0.9687 - val_loss: 0.0692 - val_accuracy: 0.9796\n",
      "Epoch 36/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1047 - accuracy: 0.9701 - val_loss: 0.0684 - val_accuracy: 0.9800\n",
      "Epoch 37/70\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1002 - accuracy: 0.9700 - val_loss: 0.0688 - val_accuracy: 0.9801\n",
      "Epoch 38/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1051 - accuracy: 0.9705 - val_loss: 0.0690 - val_accuracy: 0.9799\n",
      "Epoch 39/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1100 - accuracy: 0.9687 - val_loss: 0.0679 - val_accuracy: 0.9797\n",
      "Epoch 40/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1005 - accuracy: 0.9704 - val_loss: 0.0665 - val_accuracy: 0.9804\n",
      "Epoch 41/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1027 - accuracy: 0.9688 - val_loss: 0.0690 - val_accuracy: 0.9795\n",
      "Epoch 42/70\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1106 - accuracy: 0.9690 - val_loss: 0.0689 - val_accuracy: 0.9795\n",
      "Epoch 43/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1034 - accuracy: 0.9703 - val_loss: 0.0675 - val_accuracy: 0.9798\n",
      "Epoch 44/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0975 - accuracy: 0.9715 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
      "Epoch 45/70\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1038 - accuracy: 0.9699 - val_loss: 0.0686 - val_accuracy: 0.9797\n",
      "Epoch 46/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0998 - accuracy: 0.9716 - val_loss: 0.0704 - val_accuracy: 0.9798\n",
      "Epoch 47/70\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1092 - accuracy: 0.9696 - val_loss: 0.0682 - val_accuracy: 0.9805\n",
      "Epoch 48/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1041 - accuracy: 0.9703 - val_loss: 0.0689 - val_accuracy: 0.9793\n",
      "Epoch 49/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1067 - accuracy: 0.9710 - val_loss: 0.0680 - val_accuracy: 0.9797\n",
      "Epoch 50/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1035 - accuracy: 0.9709 - val_loss: 0.0682 - val_accuracy: 0.9797\n",
      "Epoch 51/70\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1107 - accuracy: 0.9688 - val_loss: 0.0699 - val_accuracy: 0.9793\n",
      "Epoch 52/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1009 - accuracy: 0.9705 - val_loss: 0.0676 - val_accuracy: 0.9798\n",
      "Epoch 53/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1048 - accuracy: 0.9696 - val_loss: 0.0676 - val_accuracy: 0.9797\n",
      "Epoch 54/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1069 - accuracy: 0.9687 - val_loss: 0.0721 - val_accuracy: 0.9803\n",
      "Epoch 55/70\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.1035 - accuracy: 0.9701 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
      "Epoch 56/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1034 - accuracy: 0.9696 - val_loss: 0.0701 - val_accuracy: 0.9795\n",
      "Epoch 57/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1018 - accuracy: 0.9705 - val_loss: 0.0709 - val_accuracy: 0.9797\n",
      "Epoch 58/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0980 - accuracy: 0.9713 - val_loss: 0.0700 - val_accuracy: 0.9797\n",
      "Epoch 59/70\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0984 - accuracy: 0.9721 - val_loss: 0.0701 - val_accuracy: 0.9795\n",
      "Epoch 60/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1014 - accuracy: 0.9707 - val_loss: 0.0701 - val_accuracy: 0.9796\n",
      "Epoch 61/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1095 - accuracy: 0.9682 - val_loss: 0.0704 - val_accuracy: 0.9801\n",
      "Epoch 62/70\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1026 - accuracy: 0.9706 - val_loss: 0.0718 - val_accuracy: 0.9797\n",
      "Epoch 63/70\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1035 - accuracy: 0.9704 - val_loss: 0.0705 - val_accuracy: 0.9787\n",
      "Epoch 64/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1039 - accuracy: 0.9707 - val_loss: 0.0712 - val_accuracy: 0.9789\n",
      "Epoch 65/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1032 - accuracy: 0.9697 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
      "Epoch 66/70\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1054 - accuracy: 0.9703 - val_loss: 0.0675 - val_accuracy: 0.9795\n",
      "Epoch 67/70\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1098 - accuracy: 0.9696 - val_loss: 0.0692 - val_accuracy: 0.9794\n",
      "Epoch 68/70\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1031 - accuracy: 0.9703 - val_loss: 0.0730 - val_accuracy: 0.9792\n",
      "Epoch 69/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1120 - accuracy: 0.9677 - val_loss: 0.0695 - val_accuracy: 0.9792\n",
      "Epoch 70/70\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1008 - accuracy: 0.9727 - val_loss: 0.0701 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mm2_history=mm4.fit([X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=70,\n",
    "          verbose=1, validation_data=([X_val,X_val,X_val,X_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2601,
     "status": "ok",
     "timestamp": 1613663893809,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "h9cFOtEQbLoa",
    "outputId": "4c45eb3b-12cc-4d85-9a16-4fb4f492473f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 6.8226 - accuracy: 0.9837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.822558403015137, 0.9836999773979187)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = mm4.evaluate([X_test,X_test,X_test,X_test], Y_test, verbose=1)\n",
    "loss, acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[1,2,4,8] Students Configuration On MNIST Using GANs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
