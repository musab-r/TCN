{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPdE7Fs3VdXY"
   },
   "source": [
    "# Distilling Knowledge in Multiple Students  using Generative models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2xlC_N0QVomM"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ce2GSoOKWFKP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyzL58V7WNdL"
   },
   "source": [
    "### Teacher's Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20712,
     "status": "ok",
     "timestamp": 1613652674507,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "lyIJv1WRNo7G",
    "outputId": "aef3e3c5-b57d-44a1-e2c6-db851ca0e3b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,446,730\n",
      "Trainable params: 2,446,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "nb_classes = 10\n",
    "\n",
    "(X_Train, y_Train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "\n",
    "X_train = X_train.reshape(48000, 28, 28, 1)\n",
    "X_val = X_val.reshape(12000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "\n",
    "\n",
    "#Creating a teacher network\n",
    "input_shape = (28, 28, 1) # Input shape of each image\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "teacher.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "teacher.add(Dropout(0.25)) # For reguralization\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(256, activation='relu'))\n",
    "teacher.add(Dense(256, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "teacher.add(Dropout(0.5)) # For reguralization\n",
    "\n",
    "teacher.add(Dense(nb_classes, name = 'dense_2'))\n",
    "teacher.add(Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
    "\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(teacher.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v6mBfSS7No7Q"
   },
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Teacher_MNIST_98.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab60127630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the teacher model as usual\n",
    "epochs = 0\n",
    "batch_size = 256\n",
    "teacher.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8jy5iVRWGuE"
   },
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HhwY-3bONo7M"
   },
   "outputs": [],
   "source": [
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7l50L-8hRG6y"
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1613652677603,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "EoLx2I_dNo7N",
    "outputId": "a1183477-5b27-4136-953f-a0d65e4c1b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 4ms/step - loss: 0.0541 - accuracy: 0.9869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03862640634179115, 0.9898999929428101]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka0RmVsXWW_h"
   },
   "source": [
    "### Dense Vector split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eIlRbRObW-kc"
   },
   "outputs": [],
   "source": [
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)\n",
    "val_dense = teacher_WO_Softmax.predict(X_val)\n",
    "\n",
    "# 8 Students case\n",
    "# ---------------------------------------------\n",
    "s1Train=train_dense[:,:32]\n",
    "s2Train=train_dense[:,32:64]\n",
    "s3Train=train_dense[:,64:96]\n",
    "s4Train=train_dense[:,96:128]\n",
    "s5Train=train_dense[:,128:160]\n",
    "s6Train=train_dense[:,160:192]\n",
    "s7Train=train_dense[:,192:224]\n",
    "s8Train=train_dense[:,224:]\n",
    "\n",
    "s1Val=val_dense[:,:32]\n",
    "s2Val=val_dense[:,32:64]\n",
    "s3Val=val_dense[:,64:96]\n",
    "s4Val=val_dense[:,96:128]\n",
    "s5Val=val_dense[:,128:160]\n",
    "s6Val=val_dense[:,160:192]\n",
    "s7Val=val_dense[:,192:224]\n",
    "s8Val=val_dense[:,224:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtXOpFGFEYrH"
   },
   "source": [
    "### Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ElnQTkvSXE7h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ss1 (Conv2D)                 (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                3084      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "reqss1 (Dense)               (None, 32)                416       \n",
      "=================================================================\n",
      "Total params: 10,620\n",
      "Trainable params: 10,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def define_student(name):\n",
    "\n",
    "    student1 = Sequential()\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1),kernel_initializer='normal', name=name))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Dropout(0.25)) # For reguralization\n",
    "    student1.add(Flatten())\n",
    "    student1.add(Dense(12, activation='relu'))\n",
    "    student1.add(Dropout(0.3))\n",
    "    student1.add(Dense(32,name='req'+name))\n",
    "\n",
    "    student1.compile('adam',loss='mean_squared_error',metrics=['accuracy'])\n",
    "    \n",
    "    return student1\n",
    "\n",
    "ss1=define_student(\"ss1\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MomgOJRaNo7l"
   },
   "outputs": [],
   "source": [
    "s1=define_student(\"s1\")\n",
    "s2=define_student('s2')\n",
    "s3=define_student(\"s3\")\n",
    "s4=define_student('s4')\n",
    "s5=define_student(\"s5\")\n",
    "s6=define_student('s6')\n",
    "s7=define_student(\"s7\")\n",
    "s8=define_student('s8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.8928 - accuracy: 0.1102 - val_loss: 0.6864 - val_accuracy: 0.5080\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.9235 - accuracy: 0.4090 - val_loss: 0.5006 - val_accuracy: 0.5428\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7805 - accuracy: 0.4382 - val_loss: 0.4191 - val_accuracy: 0.5871\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.7296 - accuracy: 0.4660 - val_loss: 0.4218 - val_accuracy: 0.5911\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7026 - accuracy: 0.4709 - val_loss: 0.3958 - val_accuracy: 0.5934\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6693 - accuracy: 0.4770 - val_loss: 0.3543 - val_accuracy: 0.6054\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6530 - accuracy: 0.4785 - val_loss: 0.3627 - val_accuracy: 0.6000\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6434 - accuracy: 0.4861 - val_loss: 0.3577 - val_accuracy: 0.6037\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6423 - accuracy: 0.4800 - val_loss: 0.3696 - val_accuracy: 0.6039\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6312 - accuracy: 0.4821 - val_loss: 0.3835 - val_accuracy: 0.6053\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6314 - accuracy: 0.4870 - val_loss: 0.3637 - val_accuracy: 0.6071\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6253 - accuracy: 0.4947 - val_loss: 0.3551 - val_accuracy: 0.6026\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6309 - accuracy: 0.4869 - val_loss: 0.3753 - val_accuracy: 0.6044\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6262 - accuracy: 0.4930 - val_loss: 0.3577 - val_accuracy: 0.6017\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6299 - accuracy: 0.4921 - val_loss: 0.3621 - val_accuracy: 0.6013\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6280 - accuracy: 0.4880 - val_loss: 0.3557 - val_accuracy: 0.6047\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6298 - accuracy: 0.4855 - val_loss: 0.3555 - val_accuracy: 0.5993\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6266 - accuracy: 0.4876 - val_loss: 0.3581 - val_accuracy: 0.6068\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6152 - accuracy: 0.4881 - val_loss: 0.3679 - val_accuracy: 0.6054\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6224 - accuracy: 0.4858 - val_loss: 0.3533 - val_accuracy: 0.6093\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 1.9449 - accuracy: 0.0817 - val_loss: 0.6756 - val_accuracy: 0.4704\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9207 - accuracy: 0.3934 - val_loss: 0.4652 - val_accuracy: 0.4926\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7766 - accuracy: 0.4264 - val_loss: 0.4012 - val_accuracy: 0.5100\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.7143 - accuracy: 0.4311 - val_loss: 0.3746 - val_accuracy: 0.5120\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6802 - accuracy: 0.4369 - val_loss: 0.3470 - val_accuracy: 0.5242\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6659 - accuracy: 0.4486 - val_loss: 0.3625 - val_accuracy: 0.5251\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6483 - accuracy: 0.4539 - val_loss: 0.3421 - val_accuracy: 0.5224\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6368 - accuracy: 0.4599 - val_loss: 0.3514 - val_accuracy: 0.5248\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6348 - accuracy: 0.4620 - val_loss: 0.3402 - val_accuracy: 0.5264\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6291 - accuracy: 0.4663 - val_loss: 0.3551 - val_accuracy: 0.5387\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6305 - accuracy: 0.4724 - val_loss: 0.3230 - val_accuracy: 0.5476\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6259 - accuracy: 0.4653 - val_loss: 0.3522 - val_accuracy: 0.5550\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6293 - accuracy: 0.4674 - val_loss: 0.3239 - val_accuracy: 0.5574\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6280 - accuracy: 0.4706 - val_loss: 0.3322 - val_accuracy: 0.5520\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6161 - accuracy: 0.4692 - val_loss: 0.3279 - val_accuracy: 0.5555\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6211 - accuracy: 0.4623 - val_loss: 0.3920 - val_accuracy: 0.5546\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6175 - accuracy: 0.4690 - val_loss: 0.3509 - val_accuracy: 0.5571\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6251 - accuracy: 0.4649 - val_loss: 0.3325 - val_accuracy: 0.5601\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6196 - accuracy: 0.4657 - val_loss: 0.3412 - val_accuracy: 0.5574\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6202 - accuracy: 0.4675 - val_loss: 0.3231 - val_accuracy: 0.5546\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.9075 - accuracy: 0.0959 - val_loss: 0.7696 - val_accuracy: 0.2727\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.9747 - accuracy: 0.2241 - val_loss: 0.5782 - val_accuracy: 0.3505\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8383 - accuracy: 0.2754 - val_loss: 0.5202 - val_accuracy: 0.3692\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8026 - accuracy: 0.2952 - val_loss: 0.4882 - val_accuracy: 0.4380\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7389 - accuracy: 0.3470 - val_loss: 0.4648 - val_accuracy: 0.4561\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7102 - accuracy: 0.3716 - val_loss: 0.4328 - val_accuracy: 0.4599\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7093 - accuracy: 0.3795 - val_loss: 0.4172 - val_accuracy: 0.4688\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6969 - accuracy: 0.3879 - val_loss: 0.4294 - val_accuracy: 0.4663\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6919 - accuracy: 0.3900 - val_loss: 0.4100 - val_accuracy: 0.4678\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6748 - accuracy: 0.4013 - val_loss: 0.4043 - val_accuracy: 0.4829\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6694 - accuracy: 0.4054 - val_loss: 0.3606 - val_accuracy: 0.4828\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6618 - accuracy: 0.3943 - val_loss: 0.3791 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6703 - accuracy: 0.3909 - val_loss: 0.3998 - val_accuracy: 0.4818\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6655 - accuracy: 0.3955 - val_loss: 0.4103 - val_accuracy: 0.5028\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6640 - accuracy: 0.3919 - val_loss: 0.3753 - val_accuracy: 0.4968\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6569 - accuracy: 0.4002 - val_loss: 0.3914 - val_accuracy: 0.4823\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6584 - accuracy: 0.4002 - val_loss: 0.3766 - val_accuracy: 0.4921\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6661 - accuracy: 0.3968 - val_loss: 0.3818 - val_accuracy: 0.4763\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6630 - accuracy: 0.3974 - val_loss: 0.3838 - val_accuracy: 0.4952\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6572 - accuracy: 0.4015 - val_loss: 0.3976 - val_accuracy: 0.4911\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.5652 - accuracy: 0.1210 - val_loss: 0.6995 - val_accuracy: 0.3601\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8327 - accuracy: 0.3243 - val_loss: 0.4824 - val_accuracy: 0.5155\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7195 - accuracy: 0.3853 - val_loss: 0.4363 - val_accuracy: 0.5227\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6618 - accuracy: 0.4089 - val_loss: 0.3782 - val_accuracy: 0.5336\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6265 - accuracy: 0.4159 - val_loss: 0.3949 - val_accuracy: 0.5409\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6058 - accuracy: 0.4207 - val_loss: 0.3516 - val_accuracy: 0.5437\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5966 - accuracy: 0.4206 - val_loss: 0.3478 - val_accuracy: 0.5452\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5895 - accuracy: 0.4163 - val_loss: 0.3474 - val_accuracy: 0.5440\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5808 - accuracy: 0.4216 - val_loss: 0.3388 - val_accuracy: 0.5449\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5777 - accuracy: 0.4185 - val_loss: 0.3505 - val_accuracy: 0.5386\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5733 - accuracy: 0.4198 - val_loss: 0.3388 - val_accuracy: 0.5394\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5719 - accuracy: 0.4207 - val_loss: 0.3343 - val_accuracy: 0.5511\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5712 - accuracy: 0.4314 - val_loss: 0.3422 - val_accuracy: 0.5642\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5748 - accuracy: 0.4399 - val_loss: 0.3150 - val_accuracy: 0.5638\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5674 - accuracy: 0.4379 - val_loss: 0.3356 - val_accuracy: 0.5600\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5684 - accuracy: 0.4430 - val_loss: 0.3441 - val_accuracy: 0.5629\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5613 - accuracy: 0.4425 - val_loss: 0.3293 - val_accuracy: 0.5637\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5643 - accuracy: 0.4433 - val_loss: 0.3298 - val_accuracy: 0.5713\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5530 - accuracy: 0.4455 - val_loss: 0.3176 - val_accuracy: 0.5727\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5588 - accuracy: 0.4428 - val_loss: 0.3130 - val_accuracy: 0.5765\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 1.6681 - accuracy: 0.1493 - val_loss: 0.7054 - val_accuracy: 0.3677\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.8785 - accuracy: 0.3207 - val_loss: 0.4672 - val_accuracy: 0.4047\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.7074 - accuracy: 0.3580 - val_loss: 0.3799 - val_accuracy: 0.4152\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6516 - accuracy: 0.3713 - val_loss: 0.3726 - val_accuracy: 0.4457\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6302 - accuracy: 0.3708 - val_loss: 0.3582 - val_accuracy: 0.4473\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6164 - accuracy: 0.3784 - val_loss: 0.3469 - val_accuracy: 0.4485\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5987 - accuracy: 0.3824 - val_loss: 0.3449 - val_accuracy: 0.4576\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5897 - accuracy: 0.3887 - val_loss: 0.3318 - val_accuracy: 0.4624\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5935 - accuracy: 0.3897 - val_loss: 0.3463 - val_accuracy: 0.4561\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5860 - accuracy: 0.3870 - val_loss: 0.3264 - val_accuracy: 0.4679\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5795 - accuracy: 0.3921 - val_loss: 0.3348 - val_accuracy: 0.4513\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5804 - accuracy: 0.3905 - val_loss: 0.3153 - val_accuracy: 0.4543\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5780 - accuracy: 0.3967 - val_loss: 0.3467 - val_accuracy: 0.4457\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5759 - accuracy: 0.3918 - val_loss: 0.3338 - val_accuracy: 0.4529\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5823 - accuracy: 0.3927 - val_loss: 0.3195 - val_accuracy: 0.4504\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5767 - accuracy: 0.3932 - val_loss: 0.3415 - val_accuracy: 0.4468\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5723 - accuracy: 0.3954 - val_loss: 0.3342 - val_accuracy: 0.4400\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5691 - accuracy: 0.4019 - val_loss: 0.3394 - val_accuracy: 0.4424\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5753 - accuracy: 0.4068 - val_loss: 0.3388 - val_accuracy: 0.4539\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5715 - accuracy: 0.4048 - val_loss: 0.3236 - val_accuracy: 0.4585\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 1.5971 - accuracy: 0.0771 - val_loss: 0.6396 - val_accuracy: 0.2438\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8134 - accuracy: 0.1846 - val_loss: 0.4804 - val_accuracy: 0.2921\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6992 - accuracy: 0.2457 - val_loss: 0.4115 - val_accuracy: 0.3232\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6486 - accuracy: 0.2698 - val_loss: 0.4182 - val_accuracy: 0.3579\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6241 - accuracy: 0.3024 - val_loss: 0.3772 - val_accuracy: 0.4030\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6089 - accuracy: 0.3250 - val_loss: 0.3812 - val_accuracy: 0.4262\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5906 - accuracy: 0.3315 - val_loss: 0.3549 - val_accuracy: 0.4481\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5917 - accuracy: 0.3401 - val_loss: 0.3591 - val_accuracy: 0.4437\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5842 - accuracy: 0.3380 - val_loss: 0.3456 - val_accuracy: 0.4383\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.5823 - accuracy: 0.3368 - val_loss: 0.3745 - val_accuracy: 0.4402\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5830 - accuracy: 0.3379 - val_loss: 0.3692 - val_accuracy: 0.4448\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5878 - accuracy: 0.3338 - val_loss: 0.3584 - val_accuracy: 0.4429\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5846 - accuracy: 0.3407 - val_loss: 0.3692 - val_accuracy: 0.4349\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5775 - accuracy: 0.3372 - val_loss: 0.3484 - val_accuracy: 0.4371\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5819 - accuracy: 0.3365 - val_loss: 0.3576 - val_accuracy: 0.4466\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5811 - accuracy: 0.3331 - val_loss: 0.3465 - val_accuracy: 0.4484\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5771 - accuracy: 0.3345 - val_loss: 0.3523 - val_accuracy: 0.4425\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5742 - accuracy: 0.3360 - val_loss: 0.3535 - val_accuracy: 0.4468\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5746 - accuracy: 0.3374 - val_loss: 0.3600 - val_accuracy: 0.4433\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5724 - accuracy: 0.3374 - val_loss: 0.3401 - val_accuracy: 0.4532\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 1.5849 - accuracy: 0.0976 - val_loss: 0.7172 - val_accuracy: 0.3252\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.8399 - accuracy: 0.2832 - val_loss: 0.4240 - val_accuracy: 0.4493\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.6611 - accuracy: 0.3501 - val_loss: 0.4050 - val_accuracy: 0.4783\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6223 - accuracy: 0.3664 - val_loss: 0.3574 - val_accuracy: 0.4987\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5810 - accuracy: 0.3889 - val_loss: 0.3308 - val_accuracy: 0.5396\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.5640 - accuracy: 0.4054 - val_loss: 0.3444 - val_accuracy: 0.5347\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5478 - accuracy: 0.4186 - val_loss: 0.3373 - val_accuracy: 0.5430\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5435 - accuracy: 0.4195 - val_loss: 0.3279 - val_accuracy: 0.5402\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5379 - accuracy: 0.4291 - val_loss: 0.3201 - val_accuracy: 0.5516\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5424 - accuracy: 0.4250 - val_loss: 0.3003 - val_accuracy: 0.5491\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5327 - accuracy: 0.4313 - val_loss: 0.3146 - val_accuracy: 0.5522\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5305 - accuracy: 0.4279 - val_loss: 0.2879 - val_accuracy: 0.5493\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5328 - accuracy: 0.4291 - val_loss: 0.3062 - val_accuracy: 0.5431\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5351 - accuracy: 0.4309 - val_loss: 0.3242 - val_accuracy: 0.5518\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5297 - accuracy: 0.4339 - val_loss: 0.3158 - val_accuracy: 0.5452\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5291 - accuracy: 0.4328 - val_loss: 0.3036 - val_accuracy: 0.5522\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5344 - accuracy: 0.4335 - val_loss: 0.3129 - val_accuracy: 0.5508\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5341 - accuracy: 0.4350 - val_loss: 0.3066 - val_accuracy: 0.5434\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5296 - accuracy: 0.4355 - val_loss: 0.3161 - val_accuracy: 0.5492\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5274 - accuracy: 0.4414 - val_loss: 0.2974 - val_accuracy: 0.5550\n",
      "Epoch 1/20\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.7814 - accuracy: 0.0773 - val_loss: 0.7958 - val_accuracy: 0.2941\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.9618 - accuracy: 0.2304 - val_loss: 0.5233 - val_accuracy: 0.3368\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7944 - accuracy: 0.2576 - val_loss: 0.4612 - val_accuracy: 0.3411\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.7348 - accuracy: 0.2751 - val_loss: 0.4506 - val_accuracy: 0.3392\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7102 - accuracy: 0.2827 - val_loss: 0.4209 - val_accuracy: 0.3489\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6892 - accuracy: 0.2893 - val_loss: 0.4349 - val_accuracy: 0.3731\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6821 - accuracy: 0.3167 - val_loss: 0.3895 - val_accuracy: 0.4143\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6750 - accuracy: 0.3211 - val_loss: 0.4050 - val_accuracy: 0.4189\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6743 - accuracy: 0.3183 - val_loss: 0.4206 - val_accuracy: 0.4296\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6718 - accuracy: 0.3216 - val_loss: 0.4296 - val_accuracy: 0.4281\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6668 - accuracy: 0.3244 - val_loss: 0.4074 - val_accuracy: 0.4305\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6582 - accuracy: 0.3248 - val_loss: 0.3857 - val_accuracy: 0.4349\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6604 - accuracy: 0.3231 - val_loss: 0.4224 - val_accuracy: 0.4275\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6642 - accuracy: 0.3218 - val_loss: 0.3900 - val_accuracy: 0.4383\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6637 - accuracy: 0.3224 - val_loss: 0.3954 - val_accuracy: 0.4338\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6586 - accuracy: 0.3262 - val_loss: 0.3997 - val_accuracy: 0.4391\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6546 - accuracy: 0.3265 - val_loss: 0.4098 - val_accuracy: 0.4337\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6618 - accuracy: 0.3215 - val_loss: 0.4055 - val_accuracy: 0.4388\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6619 - accuracy: 0.3240 - val_loss: 0.3776 - val_accuracy: 0.4342\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.6541 - accuracy: 0.3268 - val_loss: 0.4046 - val_accuracy: 0.4407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab8a7fdfd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.fit([X_train], s1Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s1Val))\n",
    "s2.fit([X_train], s2Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s2Val))\n",
    "s3.fit([X_train], s3Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s3Val))\n",
    "s4.fit([X_train], s4Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s4Val))\n",
    "s5.fit([X_train], s5Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s5Val))\n",
    "s6.fit([X_train], s6Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s6Val))\n",
    "s7.fit([X_train], s7Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s7Val))\n",
    "s8.fit([X_train], s8Train, batch_size=128, epochs=20, verbose=1, \n",
    "       validation_data=([X_val], s8Val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4up5WvQSodk"
   },
   "source": [
    "## **8 Students**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Zy44O0FFNo7w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n"
     ]
    }
   ],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "o2=s2.get_layer(\"reqs2\").output\n",
    "o3=s3.get_layer(\"reqs3\").output\n",
    "o4=s4.get_layer(\"reqs4\").output\n",
    "\n",
    "o5=s5.get_layer(\"reqs5\").output\n",
    "o6=s6.get_layer(\"reqs6\").output\n",
    "o7=s7.get_layer(\"reqs7\").output\n",
    "o8=s8.get_layer(\"reqs8\").output\n",
    "\n",
    "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4, o5,o6,o7,o8])\n",
    "print (output.shape)\n",
    "output=Activation('relu')(output)\n",
    "output2=Dropout(0.5)(output) # For reguralization\n",
    "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
    "mm8=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input,s3.get_layer(\"s3\").input,s4.get_layer(\"s4\").input,\n",
    "                  s5.get_layer(\"s5\").input, s6.get_layer(\"s6\").input,s7.get_layer(\"s7\").input,s8.get_layer(\"s8\").input],output3)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BLMOpCMNo70"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qrlNsqfMNo71"
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "for l in mm8.layers[:len(mm8.layers)-1]:\n",
    "    l.trainable=False\n",
    "\n",
    "mm8.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PY8jzu06No74",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 9s 21ms/step - loss: 0.9941 - accuracy: 0.7135 - val_loss: 0.0487 - val_accuracy: 0.9853\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.1156 - accuracy: 0.9664 - val_loss: 0.0457 - val_accuracy: 0.9851\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.0931 - accuracy: 0.9728 - val_loss: 0.0457 - val_accuracy: 0.9861\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0833 - accuracy: 0.9747 - val_loss: 0.0447 - val_accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 0.0445 - val_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0814 - accuracy: 0.9767 - val_loss: 0.0441 - val_accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.0711 - accuracy: 0.9798 - val_loss: 0.0441 - val_accuracy: 0.9867\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0743 - accuracy: 0.9781 - val_loss: 0.0435 - val_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.0700 - accuracy: 0.9799 - val_loss: 0.0435 - val_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0683 - accuracy: 0.9804 - val_loss: 0.0431 - val_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mm8_history=mm8.fit([X_train,X_train,X_train,X_train,X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1, validation_data=([X_val, X_val, X_val, X_val,X_val, X_val, X_val, X_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e_b2fM7yNo76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0346 - accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03456930071115494, 0.9898999929428101)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = mm8.evaluate([X_test,X_test,X_test,X_test,X_test,X_test,X_test,X_test], Y_test, verbose=1)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nkwBvZ-KNo8J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "s1_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s2_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s3_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s4_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s5_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s6_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s7_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s8_input (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s1 (Conv2D)                     (None, 26, 26, 16)   160         s1_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s2 (Conv2D)                     (None, 26, 26, 16)   160         s2_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s3 (Conv2D)                     (None, 26, 26, 16)   160         s3_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s4 (Conv2D)                     (None, 26, 26, 16)   160         s4_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s5 (Conv2D)                     (None, 26, 26, 16)   160         s5_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s6 (Conv2D)                     (None, 26, 26, 16)   160         s6_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s7 (Conv2D)                     (None, 26, 26, 16)   160         s7_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "s8 (Conv2D)                     (None, 26, 26, 16)   160         s8_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 24, 16)   2320        s1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 24, 24, 16)   2320        s2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 24, 24, 16)   2320        s3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 24, 24, 16)   2320        s4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 24, 24, 16)   2320        s5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 24, 24, 16)   2320        s6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 24, 24, 16)   2320        s7[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 24, 24, 16)   2320        s8[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 12, 12, 16)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 16)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 16)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 16)   2320        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 16)   2320        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 10, 10, 16)   2320        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 16)     2320        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 16)     2320        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 16)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 16)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 16)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 16)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 4, 4, 16)     0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 4, 4, 16)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 4, 4, 16)     0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 4, 4, 16)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 16)     0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4, 4, 16)     0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4, 4, 16)     0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 4, 4, 16)     0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 256)          0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 256)          0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 256)          0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 256)          0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 256)          0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 256)          0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           3084        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           3084        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           3084        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 12)           3084        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 12)           3084        flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           3084        flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 12)           3084        flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 12)           3084        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 12)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 12)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 12)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 12)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 12)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 12)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reqs1 (Dense)                   (None, 32)           416         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reqs2 (Dense)                   (None, 32)           416         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reqs3 (Dense)                   (None, 32)           416         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reqs4 (Dense)                   (None, 32)           416         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs5 (Dense)                   (None, 32)           416         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs6 (Dense)                   (None, 32)           416         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs7 (Dense)                   (None, 32)           416         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reqs8 (Dense)                   (None, 32)           416         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           reqs1[0][0]                      \n",
      "                                                                 reqs2[0][0]                      \n",
      "                                                                 reqs3[0][0]                      \n",
      "                                                                 reqs4[0][0]                      \n",
      "                                                                 reqs5[0][0]                      \n",
      "                                                                 reqs6[0][0]                      \n",
      "                                                                 reqs7[0][0]                      \n",
      "                                                                 reqs8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 256)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "d1 (Dense)                      (None, 10)           2570        dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 87,530\n",
      "Trainable params: 2,570\n",
      "Non-trainable params: 84,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mm8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[1,2,4,8] Students Configuration On MNIST Using GANs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
