{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcYlxyy2dj0s"
   },
   "source": [
    "# Distilling Knowledge in Multiple Students Using Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ce2GSoOKWFKP"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# !pip install --upgrade opencv-python==3.4.2.17\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "# import os\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21258,
     "status": "ok",
     "timestamp": 1613835780197,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "lyIJv1WRNo7G",
    "outputId": "feb02b96-e14b-4e57-cc3a-7561223cdef6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,446,730\n",
      "Trainable params: 2,446,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "nb_classes = 10\n",
    "\n",
    "(X_Train, y_Train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "# convert y_train and y_test to categorical binary values \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "\n",
    "X_train = X_train.reshape(48000, 28, 28, 1)\n",
    "X_val = X_val.reshape(12000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "\n",
    "\n",
    "#Creating a teacher network\n",
    "input_shape = (28, 28, 1) # Input shape of each image\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "teacher.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "teacher.add(Dropout(0.25)) # For reguralization\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(256, activation='relu'))\n",
    "teacher.add(Dense(256, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "teacher.add(Dropout(0.5)) # For reguralization\n",
    "\n",
    "teacher.add(Dense(nb_classes, name = 'dense_2'))\n",
    "teacher.add(Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
    "\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(teacher.summary())\n",
    "\n",
    "# Train the teacher model as usual\n",
    "# epochs = 0\n",
    "# batch_size = 256\n",
    "# teacher.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Teacher_FMNIST_92.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 2ms/step - loss: 0.3734 - accuracy: 0.9195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.351641982793808, 0.9239000082015991]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "teacher.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eIlRbRObW-kc"
   },
   "outputs": [],
   "source": [
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)\n",
    "val_dense = teacher_WO_Softmax.predict(X_val)\n",
    "\n",
    "\n",
    "# 4 Students case\n",
    "# ---------------------------------------------\n",
    "s1Train=train_dense[:,:64]\n",
    "s2Train=train_dense[:,64:128]\n",
    "s3Train=train_dense[:,128:192]\n",
    "s4Train=train_dense[:,192:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYAK5r6yeH-3"
   },
   "source": [
    "## GANs' Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Bf51HQeYB19"
   },
   "outputs": [],
   "source": [
    "# import np.random import random\n",
    "BATCH_SIZE=32\n",
    "def smooth_real_labels(y):\n",
    "    return y - 0.3+(np.random.random(y.shape)*0.5)\n",
    "def smooth_fake_labels(y):\n",
    "    return y + (0.3 * np.random.random(y.shape))\n",
    "def build_gan(gen,disc): \n",
    "    disc.trainable = False\n",
    "    input= Input(shape=input_shape)\n",
    "    output = gen(input)\n",
    "    output2= disc(output)\n",
    "    gan=Model(input,output2)\n",
    "\n",
    "    gan.compile(Adam(lr=0.0002),loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7DN9rlsCXBHl"
   },
   "outputs": [],
   "source": [
    "def build_sdiscriminator():\n",
    "    \n",
    "    input2 = Input(shape=(64,),name='input')\n",
    "    inp=Dense(64,use_bias=False)(input2)\n",
    "\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(inp)\n",
    "    \n",
    "    conv3 = Dense(128)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(256)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(512)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    # conv4 = Dense(1024)(leaky_relu)\n",
    "    # b_n = BatchNormalization()(conv4)\n",
    "    # leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "\n",
    "    dense = Dense(1,activation='sigmoid',name='dense')(leaky_relu)\n",
    "    output2=Dense(64)(leaky_relu)\n",
    "    disc = Model(input2,[dense,output2])          \n",
    "    disc.compile(optd,loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "s12vr0BvNo7X"
   },
   "outputs": [],
   "source": [
    "optd = Adam(lr=0.0002)\n",
    "opt = Adam(lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ElnQTkvSXE7h"
   },
   "outputs": [],
   "source": [
    "def build_sgenerator(name):\n",
    "\n",
    "    student1 = Sequential()\n",
    "    student1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1),kernel_initializer='normal', name=name))\n",
    "    student1.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Dropout(0.25)) # For reguralization\n",
    "    student1.add(Flatten())\n",
    "    student1.add(Dense(16, activation='relu'))\n",
    "    student1.add(Dropout(0.3))\n",
    "    student1.add(Dense(64,name='req'+name))\n",
    "\n",
    "    student1.compile(opt,loss='mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "    return student1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "edsqBRYpNo7e"
   },
   "outputs": [],
   "source": [
    "def training(generator,discriminator,gan,features,epo=20):\n",
    "    BATCH_SIZE = 128\n",
    "    discriminator.trainable = True\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    all_class_loss=[]\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(epo):\n",
    "        \n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        epoch_class_loss= []\n",
    "        for i,index in enumerate(indices):\n",
    "        \n",
    "            inputs=X_train[index:index+BATCH_SIZE]\n",
    "            strain = features[index:index+BATCH_SIZE]\n",
    "            y_real = np.ones((BATCH_SIZE,1))\n",
    "            y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "            #Generator Training\n",
    "            fake_images = generator.predict_on_batch(inputs)\n",
    "\n",
    "            #Disrciminator Training\n",
    "            disc_real_loss1,_,disc_real_loss2,_,_= discriminator.train_on_batch(strain,[y_real,strain])\n",
    "            disc_fake_loss1,_,disc_fake_loss2,_,_= discriminator.train_on_batch(fake_images,[y_fake,strain])\n",
    "\n",
    "            #Gans Training\n",
    "            discriminator.trainable = False\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,strain])\n",
    "\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            disc_loss = (disc_fake_loss1 + disc_real_loss1)/2\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            progress_bar.update(i+1)\n",
    "\n",
    "            epoch_gen_loss.append((gan_loss))\n",
    "\n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f | \" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "X9oy60_SNo7k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator1 = build_sdiscriminator()\n",
    "discriminator2 = build_sdiscriminator()\n",
    "discriminator3 = build_sdiscriminator()\n",
    "discriminator4 = build_sdiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MomgOJRaNo7l"
   },
   "outputs": [],
   "source": [
    "s1=build_sgenerator(\"s1\")\n",
    "s2=build_sgenerator('s2')\n",
    "s3=build_sgenerator(\"s3\")\n",
    "s4=build_sgenerator('s4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JivZOb38No7l"
   },
   "outputs": [],
   "source": [
    "gan1 = build_gan(s1,discriminator1)\n",
    "gan2 = build_gan(s2,discriminator2)\n",
    "gan3 = build_gan(s3,discriminator3)\n",
    "gan4 = build_gan(s4,discriminator4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3406661,
     "status": "ok",
     "timestamp": 1613848509655,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "e8wjg4vrNo7l",
    "outputId": "fd9f9112-3240-49ba-81f6-1eb97888c056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 14s 34ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.656007 | Generator Loss: 1.407748 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.280069 | Generator Loss: 1.007795 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.209719 | Generator Loss: 0.849852 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.178830 | Generator Loss: 0.779656 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.158482 | Generator Loss: 0.707628 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.145496 | Generator Loss: 0.660817 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.137045 | Generator Loss: 0.631385 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.131711 | Generator Loss: 0.600597 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.127941 | Generator Loss: 0.583947 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.125854 | Generator Loss: 0.573195 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.122605 | Generator Loss: 0.565228 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.118970 | Generator Loss: 0.551913 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.117097 | Generator Loss: 0.550048 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.114626 | Generator Loss: 0.529190 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.112341 | Generator Loss: 0.513568 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.109898 | Generator Loss: 0.494658 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.107744 | Generator Loss: 0.482567 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.105548 | Generator Loss: 0.471697 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.103668 | Generator Loss: 0.461859 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.101652 | Generator Loss: 0.446188 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.099501 | Generator Loss: 0.440415 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.097789 | Generator Loss: 0.430396 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.095976 | Generator Loss: 0.422368 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.094082 | Generator Loss: 0.414574 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.092664 | Generator Loss: 0.406594 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.091709 | Generator Loss: 0.398154 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.090129 | Generator Loss: 0.390887 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.089064 | Generator Loss: 0.382621 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.087697 | Generator Loss: 0.377356 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.086580 | Generator Loss: 0.369639 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.085531 | Generator Loss: 0.366996 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.084669 | Generator Loss: 0.362689 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.083622 | Generator Loss: 0.359203 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.083047 | Generator Loss: 0.354877 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.081856 | Generator Loss: 0.355173 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.081128 | Generator Loss: 0.352196 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.080442 | Generator Loss: 0.349370 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.079501 | Generator Loss: 0.345585 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.079078 | Generator Loss: 0.343215 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.078575 | Generator Loss: 0.340160 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.078118 | Generator Loss: 0.339292 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.077648 | Generator Loss: 0.334719 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.077144 | Generator Loss: 0.331543 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.076781 | Generator Loss: 0.327414 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.076484 | Generator Loss: 0.326256 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.076323 | Generator Loss: 0.325222 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.075956 | Generator Loss: 0.321809 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.075476 | Generator Loss: 0.322866 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.075194 | Generator Loss: 0.319368 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.074525 | Generator Loss: 0.319478 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.074091 | Generator Loss: 0.319863 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.073709 | Generator Loss: 0.317636 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.073443 | Generator Loss: 0.316975 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.073083 | Generator Loss: 0.314182 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.072492 | Generator Loss: 0.315093 | \n",
      "375/375 [==============================] - 13s 32ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.455622 | Generator Loss: 1.567260 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.237287 | Generator Loss: 1.111640 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.198250 | Generator Loss: 0.980001 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.176480 | Generator Loss: 0.912800 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.164688 | Generator Loss: 0.859959 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.157151 | Generator Loss: 0.836419 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.152628 | Generator Loss: 0.838513 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.148550 | Generator Loss: 0.798375 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.144036 | Generator Loss: 0.797238 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.140759 | Generator Loss: 0.760348 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.134450 | Generator Loss: 0.713732 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.131013 | Generator Loss: 0.691630 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.129005 | Generator Loss: 0.660737 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.126475 | Generator Loss: 0.644632 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.124123 | Generator Loss: 0.628102 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.122058 | Generator Loss: 0.610338 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.120598 | Generator Loss: 0.594216 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.120438 | Generator Loss: 0.585266 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.119374 | Generator Loss: 0.575567 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.118518 | Generator Loss: 0.559994 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.116875 | Generator Loss: 0.550982 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.115569 | Generator Loss: 0.533313 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.114212 | Generator Loss: 0.519137 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.112546 | Generator Loss: 0.507992 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.110795 | Generator Loss: 0.500290 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.109223 | Generator Loss: 0.489953 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.107464 | Generator Loss: 0.484144 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.106137 | Generator Loss: 0.482324 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.104360 | Generator Loss: 0.475712 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.103137 | Generator Loss: 0.472427 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.102233 | Generator Loss: 0.467307 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.101124 | Generator Loss: 0.466234 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.100771 | Generator Loss: 0.456328 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.100965 | Generator Loss: 0.448822 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.099716 | Generator Loss: 0.441960 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.099224 | Generator Loss: 0.440369 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.098639 | Generator Loss: 0.443571 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.097226 | Generator Loss: 0.439952 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.096344 | Generator Loss: 0.435026 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.095584 | Generator Loss: 0.435132 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.094695 | Generator Loss: 0.432306 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.093688 | Generator Loss: 0.425662 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.092972 | Generator Loss: 0.423678 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.092458 | Generator Loss: 0.422204 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.091683 | Generator Loss: 0.418693 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.091125 | Generator Loss: 0.414444 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.090690 | Generator Loss: 0.408797 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.089589 | Generator Loss: 0.405618 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.088937 | Generator Loss: 0.397266 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.088177 | Generator Loss: 0.398118 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.087468 | Generator Loss: 0.395347 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.087376 | Generator Loss: 0.392706 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.086889 | Generator Loss: 0.389041 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.086471 | Generator Loss: 0.387308 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.086015 | Generator Loss: 0.383074 | \n",
      "375/375 [==============================] - 14s 33ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.439429 | Generator Loss: 1.443949 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.222908 | Generator Loss: 0.944067 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.186670 | Generator Loss: 0.826465 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.172294 | Generator Loss: 0.769118 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.162492 | Generator Loss: 0.717741 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.154797 | Generator Loss: 0.674437 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.149893 | Generator Loss: 0.644740 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.144626 | Generator Loss: 0.619525 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.140738 | Generator Loss: 0.597103 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.136601 | Generator Loss: 0.579442 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.132633 | Generator Loss: 0.569907 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.130162 | Generator Loss: 0.560756 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.127353 | Generator Loss: 0.547015 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.124299 | Generator Loss: 0.534023 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.122386 | Generator Loss: 0.522194 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.121067 | Generator Loss: 0.509096 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.118755 | Generator Loss: 0.494449 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.115874 | Generator Loss: 0.479415 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.113651 | Generator Loss: 0.466774 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.111265 | Generator Loss: 0.453989 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.109552 | Generator Loss: 0.449166 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.108029 | Generator Loss: 0.438326 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.106757 | Generator Loss: 0.433189 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.105432 | Generator Loss: 0.428245 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.104132 | Generator Loss: 0.424159 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.103188 | Generator Loss: 0.420735 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.102151 | Generator Loss: 0.416169 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.101067 | Generator Loss: 0.409719 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.100016 | Generator Loss: 0.406323 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.099241 | Generator Loss: 0.404226 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.098235 | Generator Loss: 0.401408 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.097400 | Generator Loss: 0.395673 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.096192 | Generator Loss: 0.389691 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.095345 | Generator Loss: 0.388260 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.094864 | Generator Loss: 0.384743 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.093760 | Generator Loss: 0.379803 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.092989 | Generator Loss: 0.377244 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.092358 | Generator Loss: 0.376482 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.091670 | Generator Loss: 0.375821 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.091174 | Generator Loss: 0.374659 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.090213 | Generator Loss: 0.369642 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.089871 | Generator Loss: 0.368858 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.089482 | Generator Loss: 0.364423 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.088610 | Generator Loss: 0.368754 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.088038 | Generator Loss: 0.365724 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.087550 | Generator Loss: 0.365715 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.087084 | Generator Loss: 0.363535 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.086658 | Generator Loss: 0.362044 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.085940 | Generator Loss: 0.362894 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.085686 | Generator Loss: 0.359663 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.085134 | Generator Loss: 0.360049 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.084913 | Generator Loss: 0.362227 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.084587 | Generator Loss: 0.361352 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.084415 | Generator Loss: 0.361848 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.084174 | Generator Loss: 0.361492 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.083940 | Generator Loss: 0.357833 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.083103 | Generator Loss: 0.357530 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.082685 | Generator Loss: 0.353452 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 59 | Discriminator Loss: 0.082274 | Generator Loss: 0.357481 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 60 | Discriminator Loss: 0.081854 | Generator Loss: 0.356396 | \n",
      "375/375 [==============================] - 14s 35ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.519003 | Generator Loss: 1.676615 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.251638 | Generator Loss: 1.166993 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.212652 | Generator Loss: 1.087662 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.190519 | Generator Loss: 0.976407 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.186852 | Generator Loss: 0.990488 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.177561 | Generator Loss: 0.917354 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.164638 | Generator Loss: 0.832121 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.156076 | Generator Loss: 0.797152 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.149940 | Generator Loss: 0.793110 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.146426 | Generator Loss: 0.782134 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.143635 | Generator Loss: 0.768054 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.138903 | Generator Loss: 0.733454 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.135772 | Generator Loss: 0.701887 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.131661 | Generator Loss: 0.670986 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.128353 | Generator Loss: 0.632183 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.124339 | Generator Loss: 0.611794 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.121344 | Generator Loss: 0.594417 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.119097 | Generator Loss: 0.579605 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.117337 | Generator Loss: 0.559416 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.115166 | Generator Loss: 0.540405 | \n",
      "375/375 [==============================] - 12s 31ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.113983 | Generator Loss: 0.529505 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.112284 | Generator Loss: 0.521864 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.111099 | Generator Loss: 0.520069 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.110264 | Generator Loss: 0.515581 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.109681 | Generator Loss: 0.518991 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.109196 | Generator Loss: 0.512457 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.109461 | Generator Loss: 0.506083 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.109065 | Generator Loss: 0.500599 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.107823 | Generator Loss: 0.488064 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.106130 | Generator Loss: 0.479574 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.105748 | Generator Loss: 0.477465 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.104460 | Generator Loss: 0.461942 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.103690 | Generator Loss: 0.453367 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.102364 | Generator Loss: 0.448531 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.102031 | Generator Loss: 0.437173 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.100921 | Generator Loss: 0.438824 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.134342 | Generator Loss: 0.797418 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.121409 | Generator Loss: 0.788640 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.113063 | Generator Loss: 0.657825 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.109569 | Generator Loss: 0.586770 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.106213 | Generator Loss: 0.567461 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.104515 | Generator Loss: 0.545317 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.102264 | Generator Loss: 0.538384 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.101089 | Generator Loss: 0.521348 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.099700 | Generator Loss: 0.503022 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.098658 | Generator Loss: 0.490122 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.097883 | Generator Loss: 0.477661 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.097457 | Generator Loss: 0.459706 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.096909 | Generator Loss: 0.446969 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.095910 | Generator Loss: 0.438070 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.094951 | Generator Loss: 0.429800 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.093708 | Generator Loss: 0.423482 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.092810 | Generator Loss: 0.416846 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.092235 | Generator Loss: 0.410599 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.091626 | Generator Loss: 0.409951 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 56 | Discriminator Loss: 0.090904 | Generator Loss: 0.403712 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 57 | Discriminator Loss: 0.090211 | Generator Loss: 0.400985 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 58 | Discriminator Loss: 0.089579 | Generator Loss: 0.397936 | \n"
     ]
    }
   ],
   "source": [
    "s1 = training(s1,discriminator1,gan1,s1Train,epo=55)\n",
    "s2 = training(s2,discriminator2,gan2,s2Train,epo=55)\n",
    "s3 = training(s3,discriminator3,gan3,s3Train,epo=60)\n",
    "s4 = training(s4,discriminator4,gan4,s4Train,epo=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZSyVNV6UY_Z"
   },
   "source": [
    "### **4 Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1613849904985,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "QvsGpSuiNo7v",
    "outputId": "0a99c2e1-053f-4c18-c977-0f0487e62363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n"
     ]
    }
   ],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "o2=s2.get_layer(\"reqs2\").output\n",
    "o3=s3.get_layer(\"reqs3\").output\n",
    "o4=s4.get_layer(\"reqs4\").output\n",
    "output=tensorflow.keras.layers.concatenate([o1,o2,o3,o4])\n",
    "print (output.shape)\n",
    "output=Activation('relu')(output)\n",
    "output2=Dropout(0.5)(output) # For reguralization\n",
    "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
    "mm4=Model([s1.get_layer(\"s1\").input,s2.get_layer(\"s2\").input,s3.get_layer(\"s3\").input,s4.get_layer(\"s4\").input],output3)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()\n",
    "mm4.get_layer('d1').set_weights(my_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "E4_9eYYqbLxS"
   },
   "outputs": [],
   "source": [
    "for l in mm4.layers[:len(mm4.layers)-1]:\n",
    "    l.trainable=False\n",
    "\n",
    "mm4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74458,
     "status": "ok",
     "timestamp": 1613850010776,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "Y75ac5rlbLs2",
    "outputId": "ddbc3622-d1dc-4727-f34c-680a3efc7918"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 1.5774 - accuracy: 0.6385 - val_loss: 0.4311 - val_accuracy: 0.8640\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6953 - accuracy: 0.7788 - val_loss: 0.3972 - val_accuracy: 0.8678\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5522 - accuracy: 0.8118 - val_loss: 0.3761 - val_accuracy: 0.8690\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5016 - accuracy: 0.8208 - val_loss: 0.3686 - val_accuracy: 0.8696\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4734 - accuracy: 0.8276 - val_loss: 0.3617 - val_accuracy: 0.8698\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4649 - accuracy: 0.8287 - val_loss: 0.3610 - val_accuracy: 0.8742\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4612 - accuracy: 0.8288 - val_loss: 0.3606 - val_accuracy: 0.8699\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4609 - accuracy: 0.8311 - val_loss: 0.3598 - val_accuracy: 0.8723\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4551 - accuracy: 0.8311 - val_loss: 0.3558 - val_accuracy: 0.8742\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.4573 - accuracy: 0.8288 - val_loss: 0.3609 - val_accuracy: 0.8690\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4466 - accuracy: 0.8340 - val_loss: 0.3569 - val_accuracy: 0.8734\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4470 - accuracy: 0.8338 - val_loss: 0.3562 - val_accuracy: 0.8735\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.4567 - accuracy: 0.8315 - val_loss: 0.3568 - val_accuracy: 0.8718\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4495 - accuracy: 0.8354 - val_loss: 0.3594 - val_accuracy: 0.8735\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4461 - accuracy: 0.8326 - val_loss: 0.3565 - val_accuracy: 0.8721\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4524 - accuracy: 0.8333 - val_loss: 0.3583 - val_accuracy: 0.8736\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4489 - accuracy: 0.8347 - val_loss: 0.3587 - val_accuracy: 0.8725\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4474 - accuracy: 0.8329 - val_loss: 0.3588 - val_accuracy: 0.8738\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4494 - accuracy: 0.8331 - val_loss: 0.3593 - val_accuracy: 0.8722\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4501 - accuracy: 0.8328 - val_loss: 0.3622 - val_accuracy: 0.8697\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4477 - accuracy: 0.8319 - val_loss: 0.3581 - val_accuracy: 0.8702\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4526 - accuracy: 0.8308 - val_loss: 0.3573 - val_accuracy: 0.8720\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4517 - accuracy: 0.8323 - val_loss: 0.3616 - val_accuracy: 0.8721\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4465 - accuracy: 0.8327 - val_loss: 0.3596 - val_accuracy: 0.8717\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4476 - accuracy: 0.8346 - val_loss: 0.3628 - val_accuracy: 0.8737\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4516 - accuracy: 0.8306 - val_loss: 0.3611 - val_accuracy: 0.8700\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4517 - accuracy: 0.8335 - val_loss: 0.3576 - val_accuracy: 0.8717\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4514 - accuracy: 0.8324 - val_loss: 0.3566 - val_accuracy: 0.8723\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4429 - accuracy: 0.8363 - val_loss: 0.3602 - val_accuracy: 0.8701\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4499 - accuracy: 0.8330 - val_loss: 0.3634 - val_accuracy: 0.8720\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mm2_history=mm4.fit([X_train,X_train,X_train,X_train], Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=30,\n",
    "          verbose=1, validation_data=([X_val,X_val,X_val,X_val], Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74103,
     "status": "ok",
     "timestamp": 1613850012155,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "h9cFOtEQbLoa",
    "outputId": "0b165a91-083e-43c0-ae52-ccaedc881f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3835 - accuracy: 0.8626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3835180997848511, 0.8626000285148621)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = mm4.evaluate([X_test,X_test,X_test,X_test], Y_test, verbose=1)\n",
    "loss, acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[1,2,4,8] Students Configurations on FashionMNIST using GANs.ipynb",
   "provenance": [
    {
     "file_id": "1xZFzUDe8M-ikd-rsFrmtDLECCWSq3dzF",
     "timestamp": 1613663948275
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
