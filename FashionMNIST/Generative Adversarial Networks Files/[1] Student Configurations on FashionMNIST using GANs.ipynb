{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcYlxyy2dj0s"
   },
   "source": [
    "# Distilling Knowledge in Multiple Students Using Generative Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ce2GSoOKWFKP"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.x\n",
    "# !pip install --upgrade opencv-python==3.4.2.17\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "# import os\n",
    "from tensorflow.keras.datasets import fashion_mnist,mnist,cifar10\n",
    "# import keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D,Activation,BatchNormalization,UpSampling2D,Embedding,ZeroPadding2D, Input, Flatten, Dense, Reshape, LeakyReLU, Dropout,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from keras.initializers import RandomNormal\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21258,
     "status": "ok",
     "timestamp": 1613835780197,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "lyIJv1WRNo7G",
    "outputId": "feb02b96-e14b-4e57-cc3a-7561223cdef6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,446,730\n",
      "Trainable params: 2,446,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Loading and splitting the dataset into train, validation and test\n",
    "nb_classes = 10\n",
    "\n",
    "(X_Train, y_Train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_Train, y_Train, test_size=0.20)\n",
    "# convert y_train and y_test to categorical binary values \n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "\n",
    "X_train = X_train.reshape(48000, 28, 28, 1)\n",
    "X_val = X_val.reshape(12000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "\n",
    "# Normalize the values\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "\n",
    "\n",
    "#Creating a teacher network\n",
    "input_shape = (28, 28, 1) # Input shape of each image\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "teacher.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "teacher.add(Dropout(0.25)) # For reguralization\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(256, activation='relu'))\n",
    "teacher.add(Dense(256, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "teacher.add(Dropout(0.5)) # For reguralization\n",
    "\n",
    "teacher.add(Dense(nb_classes, name = 'dense_2'))\n",
    "teacher.add(Activation('softmax')) # Note that we add a normal softmax layer to begin with\n",
    "\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(teacher.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.load_weights(\"Teacher_FMNIST_92.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the teacher model as usual\n",
    "epochs = 1\n",
    "batch_size = 256\n",
    "teacher.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1613838372449,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "EoLx2I_dNo7N",
    "outputId": "8b734d09-b493-471c-9319-6db08429be32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44798123836517334, 0.9211000204086304]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking teachers test accuracy\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255 \n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "teacher.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eIlRbRObW-kc"
   },
   "outputs": [],
   "source": [
    "teacher_WO_Softmax = Model(teacher.input, teacher.get_layer('dense_1').output)\n",
    "train_dense = teacher_WO_Softmax.predict(X_train)\n",
    "val_dense = teacher_WO_Softmax.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "# 1 Student case\n",
    "# ---------------------------------------------\n",
    "s1Train=train_dense[:,:256]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYAK5r6yeH-3"
   },
   "source": [
    "## GANs' Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Bf51HQeYB19"
   },
   "outputs": [],
   "source": [
    "# import np.random import random\n",
    "BATCH_SIZE=32\n",
    "def smooth_real_labels(y):\n",
    "    return y - 0.3+(np.random.random(y.shape)*0.5)\n",
    "def smooth_fake_labels(y):\n",
    "    return y + (0.3 * np.random.random(y.shape))\n",
    "def build_gan(gen,disc): \n",
    "    disc.trainable = False\n",
    "    input= Input(shape=input_shape)\n",
    "    output = gen(input)\n",
    "    output2= disc(output)\n",
    "    gan=Model(input,output2)\n",
    "\n",
    "    gan.compile(Adam(lr=0.0002),loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7DN9rlsCXBHl"
   },
   "outputs": [],
   "source": [
    "def build_sdiscriminator():\n",
    "    \n",
    "    input2 = Input(shape=(256,),name='input')\n",
    "    inp=Dense(64,use_bias=False)(input2)\n",
    "\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(inp)\n",
    "    \n",
    "    conv3 = Dense(128)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv3)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(256)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(512)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "    conv4 = Dense(1024)(leaky_relu)\n",
    "    b_n = BatchNormalization()(conv4)\n",
    "    leaky_relu = LeakyReLU(alpha=0.2)(b_n)\n",
    "\n",
    "    dense = Dense(1,activation='sigmoid',name='dense')(leaky_relu)\n",
    "    output2=Dense(256)(leaky_relu)\n",
    "    disc = Model(input2,[dense,output2])          \n",
    "    disc.compile(optd,loss=['binary_crossentropy','mse'],metrics=['accuracy'])\n",
    "\n",
    "    return disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "s12vr0BvNo7X"
   },
   "outputs": [],
   "source": [
    "optd = Adam(lr=0.0002)\n",
    "opt = Adam(lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ElnQTkvSXE7h"
   },
   "outputs": [],
   "source": [
    "def build_sgenerator(name):\n",
    "\n",
    "    student1 = Sequential()\n",
    "    student1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1),kernel_initializer='normal', name=name))\n",
    "    student1.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Conv2D(16, kernel_size=(3, 3),activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(Conv2D(16, (3, 3), activation='relu',kernel_initializer='normal'))\n",
    "    student1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    student1.add(Dropout(0.25)) # For reguralization\n",
    "    student1.add(Flatten())\n",
    "    student1.add(Dense(64, activation='relu'))\n",
    "    student1.add(Dropout(0.3))\n",
    "    student1.add(Dense(256,name='req'+name))\n",
    "\n",
    "    student1.compile(opt,loss='mse',metrics=['accuracy'])\n",
    "    student1.summary()\n",
    "    return student1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "edsqBRYpNo7e"
   },
   "outputs": [],
   "source": [
    "def training(generator,discriminator,gan,features,epo=20):\n",
    "    BATCH_SIZE = 128\n",
    "    discriminator.trainable = True\n",
    "    total_size = X_train.shape[0]\n",
    "    indices = np.arange(0,total_size ,BATCH_SIZE)\n",
    "    all_disc_loss = []\n",
    "    all_gen_loss = []\n",
    "    all_class_loss=[]\n",
    "    if total_size % BATCH_SIZE:\n",
    "        indices = indices[:-1]\n",
    "    for e in range(epo):\n",
    "        \n",
    "        progress_bar = Progbar(target=len(indices))\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_gen_loss = []\n",
    "        epoch_disc_loss = []\n",
    "        epoch_class_loss= []\n",
    "        for i,index in enumerate(indices):\n",
    "        \n",
    "            inputs=X_train[index:index+BATCH_SIZE]\n",
    "            strain = features[index:index+BATCH_SIZE]\n",
    "            y_real = np.ones((BATCH_SIZE,1))\n",
    "            y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "            #Generator Training\n",
    "            fake_images = generator.predict_on_batch(inputs)\n",
    "\n",
    "            #Disrciminator Training\n",
    "            disc_real_loss1,_,disc_real_loss2,_,_= discriminator.train_on_batch(strain,[y_real,strain])\n",
    "            disc_fake_loss1,_,disc_fake_loss2,_,_= discriminator.train_on_batch(fake_images,[y_fake,strain])\n",
    "\n",
    "            #Gans Training\n",
    "            discriminator.trainable = False\n",
    "            gan_loss,_,gan_loss2,_,_ = gan.train_on_batch(inputs, [y_real,strain])\n",
    "\n",
    "            discriminator.trainable = True\n",
    "\n",
    "            disc_loss = (disc_fake_loss1 + disc_real_loss1)/2\n",
    "            epoch_disc_loss.append(disc_loss)\n",
    "            progress_bar.update(i+1)\n",
    "\n",
    "            epoch_gen_loss.append((gan_loss))\n",
    "\n",
    "        avg_epoch_disc_loss = np.array(epoch_disc_loss).mean()\n",
    "        avg_epoch_gen_loss = np.array(epoch_gen_loss).mean()\n",
    "        all_disc_loss.append(avg_epoch_disc_loss)\n",
    "        all_gen_loss.append(avg_epoch_gen_loss)\n",
    "        print(\"Epoch: %d | Discriminator Loss: %f | Generator Loss: %f | \" % (e+1,avg_epoch_disc_loss,avg_epoch_gen_loss))\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "X9oy60_SNo7k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator1 = build_sdiscriminator()\n",
    "# discriminator2 = build_sdiscriminator()\n",
    "# discriminator3 = build_sdiscriminator()\n",
    "# discriminator4 = build_sdiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "MomgOJRaNo7l",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "s1 (Conv2D)                  (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 10, 10, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "reqs1 (Dense)                (None, 256)               16640     \n",
      "=================================================================\n",
      "Total params: 49,600\n",
      "Trainable params: 49,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "s1=build_sgenerator(\"s1\")\n",
    "# s2=build_sgenerator('s2')\n",
    "# s3=build_sgenerator(\"s3\")\n",
    "# s4=build_sgenerator('s4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "JivZOb38No7l"
   },
   "outputs": [],
   "source": [
    "gan1 = build_gan(s1,discriminator1)\n",
    "# gan2 = build_gan(s2,discriminator2)\n",
    "# gan3 = build_gan(s3,discriminator3)\n",
    "# gan4 = build_gan(s4,discriminator4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3406661,
     "status": "ok",
     "timestamp": 1613848509655,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "e8wjg4vrNo7l",
    "outputId": "fd9f9112-3240-49ba-81f6-1eb97888c056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 15s 37ms/step\n",
      "Epoch: 1 | Discriminator Loss: 0.560325 | Generator Loss: 1.592662 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 2 | Discriminator Loss: 0.291414 | Generator Loss: 0.926031 | \n",
      "375/375 [==============================] - 14s 36ms/step\n",
      "Epoch: 3 | Discriminator Loss: 0.249491 | Generator Loss: 0.876279 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 4 | Discriminator Loss: 0.231559 | Generator Loss: 0.874988 | \n",
      "375/375 [==============================] - 14s 36ms/step\n",
      "Epoch: 5 | Discriminator Loss: 0.219904 | Generator Loss: 0.805115 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 6 | Discriminator Loss: 0.209813 | Generator Loss: 0.746718 | \n",
      "375/375 [==============================] - 14s 38ms/step\n",
      "Epoch: 7 | Discriminator Loss: 0.200672 | Generator Loss: 0.716862 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 8 | Discriminator Loss: 0.194452 | Generator Loss: 0.689449 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 9 | Discriminator Loss: 0.188921 | Generator Loss: 0.669279 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 10 | Discriminator Loss: 0.183594 | Generator Loss: 0.638445 | \n",
      "375/375 [==============================] - 14s 37ms/step\n",
      "Epoch: 11 | Discriminator Loss: 0.179294 | Generator Loss: 0.615687 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 12 | Discriminator Loss: 0.174618 | Generator Loss: 0.593662 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 13 | Discriminator Loss: 0.170096 | Generator Loss: 0.569834 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 14 | Discriminator Loss: 0.164677 | Generator Loss: 0.557598 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 15 | Discriminator Loss: 0.160442 | Generator Loss: 0.537051 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 16 | Discriminator Loss: 0.157858 | Generator Loss: 0.519963 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 17 | Discriminator Loss: 0.154662 | Generator Loss: 0.503420 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 18 | Discriminator Loss: 0.151476 | Generator Loss: 0.487455 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 19 | Discriminator Loss: 0.148570 | Generator Loss: 0.474050 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 20 | Discriminator Loss: 0.146026 | Generator Loss: 0.457673 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 21 | Discriminator Loss: 0.142923 | Generator Loss: 0.445180 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 22 | Discriminator Loss: 0.140855 | Generator Loss: 0.438141 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 23 | Discriminator Loss: 0.139020 | Generator Loss: 0.433233 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 24 | Discriminator Loss: 0.136061 | Generator Loss: 0.428683 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 25 | Discriminator Loss: 0.134893 | Generator Loss: 0.423283 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 26 | Discriminator Loss: 0.133217 | Generator Loss: 0.421074 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 27 | Discriminator Loss: 0.131425 | Generator Loss: 0.416312 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 28 | Discriminator Loss: 0.130602 | Generator Loss: 0.414926 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 29 | Discriminator Loss: 0.128887 | Generator Loss: 0.411064 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 30 | Discriminator Loss: 0.127275 | Generator Loss: 0.407799 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 31 | Discriminator Loss: 0.125910 | Generator Loss: 0.400560 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 32 | Discriminator Loss: 0.124109 | Generator Loss: 0.393105 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 33 | Discriminator Loss: 0.123108 | Generator Loss: 0.392633 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 34 | Discriminator Loss: 0.121953 | Generator Loss: 0.383208 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 35 | Discriminator Loss: 0.120759 | Generator Loss: 0.377868 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 36 | Discriminator Loss: 0.119376 | Generator Loss: 0.373854 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 37 | Discriminator Loss: 0.117968 | Generator Loss: 0.366813 | \n",
      "375/375 [==============================] - 13s 36ms/step\n",
      "Epoch: 38 | Discriminator Loss: 0.116844 | Generator Loss: 0.360510 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 39 | Discriminator Loss: 0.115583 | Generator Loss: 0.358203 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 40 | Discriminator Loss: 0.114522 | Generator Loss: 0.352247 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 41 | Discriminator Loss: 0.113520 | Generator Loss: 0.349452 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 42 | Discriminator Loss: 0.112756 | Generator Loss: 0.345965 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 43 | Discriminator Loss: 0.112145 | Generator Loss: 0.341782 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 44 | Discriminator Loss: 0.111517 | Generator Loss: 0.340688 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 45 | Discriminator Loss: 0.110219 | Generator Loss: 0.337034 | \n",
      "375/375 [==============================] - 13s 35ms/step\n",
      "Epoch: 46 | Discriminator Loss: 0.109523 | Generator Loss: 0.336911 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 47 | Discriminator Loss: 0.108525 | Generator Loss: 0.333420 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 48 | Discriminator Loss: 0.108068 | Generator Loss: 0.330856 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 49 | Discriminator Loss: 0.107430 | Generator Loss: 0.331694 | \n",
      "375/375 [==============================] - 13s 33ms/step\n",
      "Epoch: 50 | Discriminator Loss: 0.106813 | Generator Loss: 0.330021 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 51 | Discriminator Loss: 0.106360 | Generator Loss: 0.329984 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 52 | Discriminator Loss: 0.105792 | Generator Loss: 0.328543 | \n",
      "375/375 [==============================] - 12s 33ms/step\n",
      "Epoch: 53 | Discriminator Loss: 0.105500 | Generator Loss: 0.332054 | \n",
      "375/375 [==============================] - 13s 34ms/step\n",
      "Epoch: 54 | Discriminator Loss: 0.105206 | Generator Loss: 0.332978 | \n",
      "375/375 [==============================] - 12s 32ms/step\n",
      "Epoch: 55 | Discriminator Loss: 0.104471 | Generator Loss: 0.331461 | \n"
     ]
    }
   ],
   "source": [
    "s1 = training(s1,discriminator1,gan1,s1Train,epo=55)\n",
    "# s2 = training(s2,discriminator2,gan2,s2Train,epo=55)\n",
    "# s3 = training(s3,discriminator3,gan3,s3Train,epo=60)\n",
    "# s4 = training(s4,discriminator4,gan4,s4Train,epo=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7EP66u3UQBn"
   },
   "source": [
    "### **1 Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "T-kKVdyHNo7r"
   },
   "outputs": [],
   "source": [
    "o1=s1.get_layer(\"reqs1\").output\n",
    "output=Activation('relu')(o1)\n",
    "output2=Dropout(0.5)(output)\n",
    "output3=Dense(10,activation=\"softmax\", name=\"d1\")(output2)\n",
    "mm1=Model(s1.get_layer('s1').input, output3)\n",
    "my_weights=teacher.get_layer('dense_2').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "kA1_fLX1No7s"
   },
   "outputs": [],
   "source": [
    "mm1.get_layer('d1').set_weights(my_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rJcMVvWJNo7s"
   },
   "outputs": [],
   "source": [
    "for l in mm1.layers[:len(mm1.layers)-1]:\n",
    "    l.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Njs_UlNENo7t"
   },
   "outputs": [],
   "source": [
    "mm1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14100,
     "status": "ok",
     "timestamp": 1613842154864,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "yoeFAkcqebjM",
    "outputId": "47d162ce-3818-475f-d694-1efd66c7d18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 3.4529 - accuracy: 0.5112 - val_loss: 0.4900 - val_accuracy: 0.8622\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1.0235 - accuracy: 0.7492 - val_loss: 0.4219 - val_accuracy: 0.8658\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7258 - accuracy: 0.7856 - val_loss: 0.3987 - val_accuracy: 0.8646\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6132 - accuracy: 0.7982 - val_loss: 0.3845 - val_accuracy: 0.8691\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5478 - accuracy: 0.8124 - val_loss: 0.3794 - val_accuracy: 0.8677\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5394 - accuracy: 0.8131 - val_loss: 0.3762 - val_accuracy: 0.8711\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5086 - accuracy: 0.8188 - val_loss: 0.3708 - val_accuracy: 0.8690\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.5055 - accuracy: 0.8181 - val_loss: 0.3798 - val_accuracy: 0.8665\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4974 - accuracy: 0.8199 - val_loss: 0.3742 - val_accuracy: 0.8686\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5036 - accuracy: 0.8212 - val_loss: 0.3704 - val_accuracy: 0.8719\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5021 - accuracy: 0.8202 - val_loss: 0.3739 - val_accuracy: 0.8701\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4911 - accuracy: 0.8234 - val_loss: 0.3695 - val_accuracy: 0.8685\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4944 - accuracy: 0.8201 - val_loss: 0.3768 - val_accuracy: 0.8659\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4919 - accuracy: 0.8236 - val_loss: 0.3794 - val_accuracy: 0.8654\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4880 - accuracy: 0.8245 - val_loss: 0.3757 - val_accuracy: 0.8685\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4923 - accuracy: 0.8204 - val_loss: 0.3743 - val_accuracy: 0.8663\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4879 - accuracy: 0.8224 - val_loss: 0.3756 - val_accuracy: 0.8677\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4888 - accuracy: 0.8204 - val_loss: 0.3796 - val_accuracy: 0.8637\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4863 - accuracy: 0.8236 - val_loss: 0.3772 - val_accuracy: 0.8663\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4876 - accuracy: 0.8217 - val_loss: 0.3731 - val_accuracy: 0.8707\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4860 - accuracy: 0.8219 - val_loss: 0.3741 - val_accuracy: 0.8660\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4950 - accuracy: 0.8228 - val_loss: 0.3788 - val_accuracy: 0.8641\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.8241 - val_loss: 0.3730 - val_accuracy: 0.8700\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4920 - accuracy: 0.8232 - val_loss: 0.3735 - val_accuracy: 0.8660\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4874 - accuracy: 0.8234 - val_loss: 0.3741 - val_accuracy: 0.8686\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4786 - accuracy: 0.8251 - val_loss: 0.3730 - val_accuracy: 0.8699\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4817 - accuracy: 0.8260 - val_loss: 0.3725 - val_accuracy: 0.8704\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4900 - accuracy: 0.8225 - val_loss: 0.3732 - val_accuracy: 0.8692\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4865 - accuracy: 0.8223 - val_loss: 0.3745 - val_accuracy: 0.8698\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4881 - accuracy: 0.8228 - val_loss: 0.3700 - val_accuracy: 0.8705\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4789 - accuracy: 0.8241 - val_loss: 0.3731 - val_accuracy: 0.8691\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4847 - accuracy: 0.8233 - val_loss: 0.3772 - val_accuracy: 0.8658\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4806 - accuracy: 0.8232 - val_loss: 0.3757 - val_accuracy: 0.8697\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4780 - accuracy: 0.8257 - val_loss: 0.3829 - val_accuracy: 0.8651\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4893 - accuracy: 0.8200 - val_loss: 0.3734 - val_accuracy: 0.8698\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4833 - accuracy: 0.8240 - val_loss: 0.3763 - val_accuracy: 0.8667\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4896 - accuracy: 0.8232 - val_loss: 0.3751 - val_accuracy: 0.8665\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4907 - accuracy: 0.8215 - val_loss: 0.3720 - val_accuracy: 0.8698\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4852 - accuracy: 0.8232 - val_loss: 0.3806 - val_accuracy: 0.8655\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4867 - accuracy: 0.8231 - val_loss: 0.3808 - val_accuracy: 0.8614\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.8232 - val_loss: 0.3720 - val_accuracy: 0.8680\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.8245 - val_loss: 0.3749 - val_accuracy: 0.8677\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4868 - accuracy: 0.8215 - val_loss: 0.3761 - val_accuracy: 0.8662\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4878 - accuracy: 0.8226 - val_loss: 0.3742 - val_accuracy: 0.8687\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4941 - accuracy: 0.8210 - val_loss: 0.3738 - val_accuracy: 0.8671\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4888 - accuracy: 0.8193 - val_loss: 0.3726 - val_accuracy: 0.8690\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4867 - accuracy: 0.8238 - val_loss: 0.3834 - val_accuracy: 0.8650\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4955 - accuracy: 0.8220 - val_loss: 0.3742 - val_accuracy: 0.8684\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4857 - accuracy: 0.8238 - val_loss: 0.3729 - val_accuracy: 0.8679\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.4800 - accuracy: 0.8235 - val_loss: 0.3786 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd29cd985f8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mm1.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50,\n",
    "          verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1613842089233,
     "user": {
      "displayName": "Musab R.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggo6kK28_a_Swx27ReDE7W6SlcMcsOsRyiTC_xFvA=s64",
      "userId": "11675938905762231877"
     },
     "user_tz": -300
    },
    "id": "fWGGV28ENo7u",
    "outputId": "0562498c-c223-418d-af63-117c43a19f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3951 - accuracy: 0.8588\n"
     ]
    }
   ],
   "source": [
    "loss, acc = mm1.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[1,2,4,8] Students Configurations on FashionMNIST using GANs.ipynb",
   "provenance": [
    {
     "file_id": "1xZFzUDe8M-ikd-rsFrmtDLECCWSq3dzF",
     "timestamp": 1613663948275
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
